# This is a basic workflow to help you get started with GitHub Actions
name: TESTS Talk2KnowledgeGraphs

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events
  pull_request:
    branches: [ main ]
    paths:
      - 'aiagents4pharma/talk2knowledgegraphs/**'

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

env:
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

# This workflow contains jobs covering linting and code coverage (along with testing).
jobs:
  # pylint job for windows, ubuntu, and macos
  pylint-windows-ubuntu-macos:
    # The type of runner that the job will run on
    name: pylint
    runs-on: ${{ matrix.os }}

    strategy:
        matrix:
            os: [windows-latest, ubuntu-latest, macos-13]

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.12

      - name: Cache files
        uses: actions/cache@v4
        id: cache
        with:
          path: |
            ${{ github.workspace }}/venv/*
          key: ${{ runner.os }}-pip-pylint

      # install requirements for ubuntu and macos
      - name: Install the requirements (ubuntu and macos)
        if: steps.cache.outputs.cache-hit != 'true' && matrix.os != 'windows-latest'
        working-directory: ${{ github.workspace }}
        run: |
          python3 -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          pip3 install --break-system-packages -r requirements.txt
      
      # install requirements for windows
      - name: Install the requirements (windows)
        if: steps.cache.outputs.cache-hit != 'true' && matrix.os == 'windows-latest'
        working-directory: ${{ github.workspace }}
        run: |
          python3 -m venv venv
          venv\Scripts\activate
          pip install --upgrade pip
          pip3 install --break-system-packages -r requirements.txt

      # pylint for ubuntu and macos
      - name: Run pylint (ubuntu and macos)
        if: matrix.os != 'windows-latest'
        working-directory: ${{ github.workspace }}
        run: |
          source venv/bin/activate
          pylint --disable=R0801,R0902,W0221,W0122 aiagents4pharma/talk2knowledgegraphs
      
      # pylint for windows
      - name: Run pylint (windows)
        if: matrix.os == 'windows-latest'
        working-directory: ${{ github.workspace }}
        run: |
          venv\Scripts\activate
          pylint --disable=R0801,R0902,W0221,W0122 aiagents4pharma/talk2knowledgegraphs

  # code coverage job for macos
  code-cov-macos:
    name: code-coverage
    runs-on: ${{ matrix.os }}

    strategy:
        matrix:
          os: [macos-13]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.12

    - name: Cache files
      uses: actions/cache@v4
      id: cache
      with:
        path: |
          ${{ github.workspace }}/ollama_models/*
          ${{ github.workspace }}/venv/*
        key: ${{ runner.os }}-pip-code-cov

    - name: Install dependencies
      if: steps.cache.outputs.cache-hit != 'true'
      working-directory: ${{ github.workspace }}
      run: |
        python3 -m venv venv
        source venv/bin/activate
        pip install --upgrade pip
        pip3 install -r requirements.txt
        brew install ollama
        mkdir ${{ github.workspace }}/ollama_models
        export OLLAMA_MODELS=${{ github.workspace }}/ollama_models
        ollama serve &
        sleep 10
        ollama pull llama3.2

    - name: Reading cached Ollama models
      working-directory: ${{ github.workspace }}
      run: |
        echo "Cache Hit Status - ${{ steps.cache.outputs.cache-hit }}"
        source venv/bin/activate
        brew install ollama
        export OLLAMA_MODELS=${{ github.workspace }}/ollama_models
        ollama serve &
        sleep 10
        ollama list

    - name: Run tests with coverage
      working-directory: ${{ github.workspace }}
      run: |
        source venv/bin/activate
        coverage run --include=aiagents4pharma/talk2knowledgegraphs/* -m pytest --cache-clear aiagents4pharma/talk2knowledgegraphs/tests/

    - name: Check coverage
      working-directory: ${{ github.workspace }}
      run: |
        source venv/bin/activate
        coverage report -m
        TOTAL_COVERAGE=$(coverage report -m | awk 'END {print int($NF)}')
        if [[ $TOTAL_COVERAGE -ne 100 ]]; then
          echo "Code coverage is not 100%. Please check the coverage report."
          exit 1
        fi
      env:
        COVERAGE_FILE: './.coverage'

  # code coverage job for ubuntu
  code-cov-ubuntu:
    name: code-coverage
    runs-on: ${{ matrix.os }}

    strategy:
        matrix:
          os: [ubuntu-latest]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.12

    - name: Cache files
      uses: actions/cache@v4
      id: cache
      with:
        path: |
          ${{ github.workspace }}/ollama_models/*
          ${{ github.workspace }}/venv/*
        key: ${{ runner.os }}-pip-code-cov

    - name: Install dependencies
      if: steps.cache.outputs.cache-hit != 'true'
      working-directory: ${{ github.workspace }}
      run: |
        python3 -m venv venv
        source venv/bin/activate
        pip install --upgrade pip
        pip3 install -r requirements.txt
        curl -fsSL https://ollama.com/install.sh | sh
        mkdir ${{ github.workspace }}/ollama_models
        export OLLAMA_MODELS=${{ github.workspace }}/ollama_models
        ollama serve &
        sleep 10
        ollama pull llama3.2

    - name: Reading cached Ollama models
      working-directory: ${{ github.workspace }}
      run: |
        echo "Cache Hit Status - ${{ steps.cache.outputs.cache-hit }}"
        source venv/bin/activate
        curl -fsSL https://ollama.com/install.sh | sh
        export OLLAMA_MODELS=${{ github.workspace }}/ollama_models
        ollama serve &
        sleep 10
        ollama list

    - name: Run tests with coverage
      working-directory: ${{ github.workspace }}
      run: |
        source venv/bin/activate
        coverage run --include=aiagents4pharma/talk2knowledgegraphs/* -m pytest --cache-clear aiagents4pharma/talk2knowledgegraphs/tests/

    - name: Check coverage
      working-directory: ${{ github.workspace }}
      run: |
        source venv/bin/activate
        coverage report -m
        TOTAL_COVERAGE=$(coverage report -m | awk 'END {print int($NF)}')
        if [[ $TOTAL_COVERAGE -ne 100 ]]; then
          echo "Code coverage is not 100%. Please check the coverage report."
          exit 1
        fi
      env:
        COVERAGE_FILE: './.coverage'

  # code coverage job for windows
  code-cov-windows:
    name: code-coverage
    runs-on: ${{ matrix.os }}

    strategy:
        matrix:
          os: [windows-latest]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.12

    - name: Cache files
      uses: actions/cache@v4
      id: cache
      with:
        path: |
          ${{ github.workspace }}\ollama_models\*
          ${{ github.workspace }}\venv\*
        key: ${{ runner.os }}-pip-code-cov

    - name: Install dependencies
      if: steps.cache.outputs.cache-hit != 'true'
      working-directory: ${{ github.workspace }}
      run: |
        python3 -m venv venv
        venv\Scripts\activate
        pip install --upgrade pip
        pip3 install -r requirements.txt
        curl -L https://ollama.com/download/ollama-windows-amd64.zip -o ollama-windows-amd64.zip
        tar -xzf .\ollama-windows-amd64.zip
        mkdir ${{ github.workspace }}\ollama_models
        set OLLAMA_MODELS=${{ github.workspace }}\ollama_models
        start ollama serve
        sleep 10
        cmd /k ollama pull llama3.2

    - name: Reading cached Ollama models
      working-directory: ${{ github.workspace }}
      run: |
        echo "Cache Hit Status - ${{ steps.cache.outputs.cache-hit }}"
        venv\Scripts\activate
        curl -L https://ollama.com/download/ollama-windows-amd64.zip -o ollama-windows-amd64.zip
        tar -xzf .\ollama-windows-amd64.zip
        set OLLAMA_MODELS=${{ github.workspace }}\ollama_models
        start ollama serve
        sleep 10
        cmd /k ollama list

    - name: Run tests with coverage
      working-directory: ${{ github.workspace }}
      run: |
        venv\Scripts\activate
        coverage run --include=aiagents4pharma/talk2knowledgegraphs/* -m pytest --cache-clear aiagents4pharma/talk2knowledgegraphs/tests/

    - name: Check coverage
      working-directory: ${{ github.workspace }}
      run: |
        venv\Scripts\activate
        coverage report -m
        # $TOTAL_COVERAGE=(& coverage report -m | Select-Object -Last 1) -replace "[^\d]"  # Extract the last line and remove non-numeric characters
        $TOTAL_COVERAGE=(& coverage report -m | Select-Object -Last 1)
        # split and extract the last element
        $TOTAL_COVERAGE=($TOTAL_COVERAGE -split " ")[-1]
        # remove non-numeric characters
        $TOTAL_COVERAGE=($TOTAL_COVERAGE -replace "[^\d]")
        # convert to int
        $TOTAL_COVERAGE=[int]$TOTAL_COVERAGE
        echo "Total coverage: $TOTAL_COVERAGE"
        if ($TOTAL_COVERAGE -ne 100) {
          Write-Host "Code coverage is not 100%. Please check the coverage report."
          exit 1
        }
      env:
        COVERAGE_FILE: './.coverage'
