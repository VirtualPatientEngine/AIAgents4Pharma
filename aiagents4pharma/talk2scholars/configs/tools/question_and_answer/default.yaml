# Configuration for the PDF question_and_answer Tool - Traditional RAG Pipeline with GPU Support

# Milvus vector database settings
milvus:
  # Connection settings
  host: ${oc.env:MILVUS_HOST,127.0.0.1}
  port: ${oc.env:MILVUS_PORT,19530}

  # Database and collection settings
  db_name: ${oc.env:MILVUS_DB_NAME,pdf_rag_db}
  collection_name: ${oc.env:MILVUS_COLLECTION_NAME,pdf_rag_documents}

  # Ensure collection persists across restarts
  consistency_level: "Strong"
  embedding_dim: 768

  # GPU Configuration (automatically detected)
  # When GPU is detected, uses GPU_CAGRA index for better performance
  # When no GPU, falls back to CPU IVF_FLAT index
  gpu:
    # GPU_CAGRA index settings (used when NVIDIA GPU detected)
    index_params:
      metric_type: "COSINE"
      index_type: "GPU_CAGRA"
      params:
        intermediate_graph_degree: 64 # Higher for better recall
        graph_degree: 32 # Balanced performance/recall
        build_algo: "IVF_PQ" # Higher quality build
        cache_dataset_on_device: "true" # Cache for better recall
        adapt_for_cpu: "false" # Pure GPU mode

    # GPU_CAGRA search parameters
    search_params:
      metric_type: "COSINE"
      params:
        itopk_size: 128 # Power of 2, good for intermediate results
        search_width: 16 # Balanced entry points
        team_size: 16 # Optimize for typical vector dimensions

  # CPU Configuration (fallback when no GPU detected)
  cpu:
    # CPU IVF_FLAT index settings (fallback)
    index_params:
      metric_type: "COSINE"
      index_type: "IVF_FLAT"
      params:
        nlist: 1024 # Number of cluster units

    # CPU search parameters
    search_params:
      metric_type: "COSINE"
      params:
        nprobe: 16 # Slightly higher than original for better recall

# Document processing settings
chunk_size: 1200 # Number of characters per text chunk
chunk_overlap: 200 # Overlap between adjacent chunks

# Parallel processing settings
embedding_batch_size: 1500 # Number of chunks to embed in a single API call
max_parallel_pdfs: 10 # Maximum number of PDFs to process in parallel

# Traditional RAG Pipeline Settings
# Step 1: Initial retrieval (cast wide net)
initial_retrieval_k: 100 # Number of chunks to retrieve before reranking
mmr_diversity: 0.8 # MMR diversity parameter (0=max diversity, 1=max relevance)

# Step 2: Reranking settings
top_k_chunks: 25 # Final number of chunks after reranking
reranker:
  model: "nvidia/nv-rerankqa-mistral-4b-v3"
  api_key: ${oc.env:NVIDIA_API_KEY}

# Answer generation settings
prompt_template: |
  You are a scientific research assistant specialized in reading and extracting information from research papers.
  Your role is to answer questions by retrieving relevant information from the provided context.

  - Provide detailed, structured, and well-argued explanationsâ€”not just brief summaries.
  - Cite specific sources using only the title of the paper.
  - If the context is insufficient, clearly state that more information is needed.

  Context:
  {context}

  Question: {question}

  Your answer should be comprehensive, accurate, and clearly structured for a scientific audience.

# GPU Detection and Performance Settings
gpu_detection:
  # Timeout for GPU detection command (seconds)
  detection_timeout: 10

  # Log GPU detection results
  log_detection: true

  # Performance tuning based on hardware
  auto_tune_params: true # Automatically adjust parameters based on detected hardware
