{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d74f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import networkx as nx\n",
    "import openai \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import hydra\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import cudf\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "sys.path.append('../../..')\n",
    "from aiagents4pharma.talk2knowledgegraphs.utils.extractions.multimodal_pcst import MultimodalPCSTPruning\n",
    "from aiagents4pharma.talk2knowledgegraphs.utils.embeddings.ollama import EmbeddingWithOllama\n",
    "from aiagents4pharma.talk2knowledgegraphs.utils.embeddings.sentence_transformer import EmbeddingWithSentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3981d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"XXX\"\n",
    "# Make sure to replace \"your_api_key\" with your actual API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce163cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35dcb609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_target_': 'talk2knowledgegraphs.tools.multimodal_subgraph_extraction', 'ollama_embeddings': ['nomic-embed-text'], 'temperature': 0.1, 'streaming': False, 'topk': 5, 'topk_e': 5, 'cost_e': 0.5, 'c_const': 0.01, 'root': -1, 'num_clusters': 1, 'pruning': 'gw', 'verbosity_level': 0, 'node_id_column': 'node_id', 'node_attr_column': 'node_attr', 'edge_src_column': 'edge_src', 'edge_attr_column': 'edge_attr', 'edge_dst_column': 'edge_dst', 'node_colors_dict': {'gene/protein': '#6a79f7', 'molecular_function': '#82cafc', 'cellular_component': '#3f9b0b', 'biological_process': '#c5c9c7', 'drug': '#c4a661', 'disease': '#80013f'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load hydra configuration\n",
    "with hydra.initialize(version_base=None, config_path=\"../../../aiagents4pharma/talk2knowledgegraphs/configs\"):\n",
    "    cfg = hydra.compose(\n",
    "        config_name=\"config\", overrides=[\"tools/multimodal_subgraph_extraction=default\"]\n",
    "    )\n",
    "    cfg = cfg.tools.multimodal_subgraph_extraction\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ac1a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state\n",
    "state = {\n",
    "    \"llm_model\": ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0),\n",
    "    \"embedding_model\": OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "    \"selected_genes\": [], #[\"IL6_(1567)\", \"IL21_(34967)\", \"TNF_(2329)\"],\n",
    "    \"selected_drugs\": [], #[\"Remdesivir_(15267)\", \"Mesalazine_(15876)\"],\n",
    "    \"uploaded_files\": [\n",
    "        {\n",
    "            \"file_name\": \"multimodal-analysis.csv\",\n",
    "            \"file_path\": '../../../aiagents4pharma/talk2knowledgegraphs/tests/files/multimodal-analysis.csv',\n",
    "            \"file_type\": \"multimodal\",\n",
    "            \"uploaded_by\": \"VPEUser\",\n",
    "            \"uploaded_timestamp\": \"2024-11-05 00:00:00\",\n",
    "        },\n",
    "    ],\n",
    "    \"topk_nodes\": 10,\n",
    "    \"topk_edges\": 10,\n",
    "    \"dic_source_graph\": [\n",
    "        {\n",
    "            \"name\": \"PrimeKG\",\n",
    "            \"kg_pyg_path\": \"../../../aiagents4pharma/talk2knowledgegraphs/tests/files/biobridge_multimodal_pyg_graph.pkl\",\n",
    "            \"kg_text_path\": \"../../../aiagents4pharma/talk2knowledgegraphs/tests/files/biobridge_multimodal_text_graph.pkl\",\n",
    "        }\n",
    "    ],\n",
    "    \"dic_extracted_graph\": []\n",
    "}\n",
    "\n",
    "# Define prompt\n",
    "prompt = \"\"\"\n",
    "Extract all relevant information related to nodes of genes related to inflammatory bowel disease (IBD) \n",
    "that existed in the knowledge graph.\n",
    "\n",
    "Please set the extraction name for this process as `subkg_12345`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90602837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve source graph from the state\n",
    "initial_graph = {}\n",
    "initial_graph[\"source\"] = state[\"dic_source_graph\"][-1]  # The last source graph as of now\n",
    "# logger.log(logging.INFO, \"Source graph: %s\", source_graph)\n",
    "\n",
    "# Load the knowledge graph\n",
    "with open(initial_graph[\"source\"][\"kg_pyg_path\"], \"rb\") as f:\n",
    "    initial_graph[\"pyg\"] = pickle.load(f)\n",
    "# with open(initial_graph[\"source\"][\"kg_text_path\"], \"rb\") as f:\n",
    "#     initial_graph[\"text\"] = pickle.load(f)\n",
    "\n",
    "pyg_graph = initial_graph[\"pyg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79fbc5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:11434/api/tags \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "prompt_emb = [EmbeddingWithOllama(model_name=cfg.ollama_embeddings[0]).embed_query(prompt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61343c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the parquet files\n",
    "local_dir = '../../../aiagents4pharma/talk2knowledgegraphs/tests/files'\n",
    "nodes_df = cudf.read_parquet(os.path.join(local_dir, 'biobridge_nodes.parquet.gzip'))\n",
    "edges_df = cudf.read_parquet(os.path.join(local_dir, 'biobridge_edges.parquet.gzip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "323c234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataframes\n",
    "multimodal_df = cudf.DataFrame({\"name\": [], \"node_type\": []})\n",
    "query_df = cudf.DataFrame({\"node_id\": [],\n",
    "                            \"node_type\": [],\n",
    "                            \"x\": [],\n",
    "                            \"desc_x\": [],\n",
    "                            \"use_description\": []})\n",
    "\n",
    "# Loop over the uploaded files and find multimodal files\n",
    "for i in range(len(state[\"uploaded_files\"])):\n",
    "    # Check if multimodal file is uploaded\n",
    "    if state[\"uploaded_files\"][i][\"file_type\"] == \"multimodal\":\n",
    "        # Read the Excel file\n",
    "        multimodal_df = cudf.read_csv(state[\"uploaded_files\"][i][\"file_path\"])\n",
    "\n",
    "# Check if the multimodal_df is empty\n",
    "if len(multimodal_df) > 0:\n",
    "    # Merge all obtained dataframes into a single dataframe\n",
    "    multimodal_df.rename(columns={\"name\": \"q_node_name\", \"node_type\": \"q_node_type\"}, inplace=True)\n",
    "\n",
    "    # Make and process a query dataframe by merging the graph_df and multimodal_df\n",
    "    query_df = nodes_df[['node_id', 'node_name', 'node_type', 'enriched_node', 'x', 'desc', 'desc_x']].merge(multimodal_df, how='cross')\n",
    "    query_df['q_node_name'] = query_df['q_node_name'].str.lower()\n",
    "    query_df['node_name'] = query_df['node_name'].str.lower()\n",
    "    # Get the mask for filtering based on the query\n",
    "    mask = (\n",
    "        query_df['node_name'].str.contains(query_df['q_node_name']) &\n",
    "        (query_df['node_type'] == query_df['q_node_type'])\n",
    "    )\n",
    "    query_df = query_df[mask]\n",
    "    query_df = query_df[['node_id', 'node_type', 'enriched_node', 'x', 'desc', 'desc_x']].reset_index(drop=True)\n",
    "    query_df['use_description'] = False # set to False for modal-specific embeddings\n",
    "\n",
    "    # Update the state by adding the the selected node IDs\n",
    "    state[\"selections\"] = query_df.to_pandas().groupby(\"node_type\")[\"node_id\"].apply(list).to_dict()\n",
    "\n",
    "# Append a user prompt to the query dataframe\n",
    "query_df = cudf.concat([\n",
    "    query_df,\n",
    "    cudf.DataFrame({\n",
    "        'node_id': 'user_prompt',\n",
    "        'node_type': 'prompt',\n",
    "        # 'enriched_node': prompt,\n",
    "        'x': prompt_emb,\n",
    "        # 'desc': prompt,\n",
    "        'desc_x': prompt_emb,\n",
    "        'use_description': True # set to True for user prompt embedding\n",
    "    })\n",
    "]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180989a4",
   "metadata": {},
   "source": [
    "### Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d95dbd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "topk = state[\"topk_nodes\"]  \n",
    "topk_e = state[\"topk_edges\"]\n",
    "c_const = 0.01\n",
    "\n",
    "def _compute_node_prizes(graph: Data,\n",
    "                         query_emb: torch.Tensor,\n",
    "                         modality: str,\n",
    "                         use_description: bool=False) :\n",
    "    \"\"\"\n",
    "    Compute the node prizes based on the cosine similarity between the query and nodes.\n",
    "\n",
    "    Args:\n",
    "        graph: The knowledge graph in PyTorch Geometric Data format.\n",
    "        query_emb: The query embedding in PyTorch Tensor format. This can be an embedding of\n",
    "            a prompt, sequence, or any other feature to be used for the subgraph extraction.\n",
    "        modality: The modality to use for the subgraph extraction based on the node type.\n",
    "\n",
    "    Returns:\n",
    "        The prizes of the nodes.\n",
    "    \"\"\"\n",
    "    # Convert PyG graph to a DataFrame\n",
    "    graph_df = cudf.DataFrame({\n",
    "        \"node_type\": graph.node_type,\n",
    "        \"desc_x\": [x.tolist() for x in graph.desc_x],\n",
    "        \"x\": [list(x) for x in graph.x],\n",
    "        \"score\": [0.0 for _ in range(len(graph.node_id))],\n",
    "    })\n",
    "\n",
    "    # Calculate cosine similarity for text features and update the score\n",
    "    if use_description:\n",
    "        graph_df.loc[:, \"score\"] = torch.nn.CosineSimilarity(dim=-1)(\n",
    "                query_emb,\n",
    "                torch.tensor(list(graph_df.desc_x.values)) # Using textual description features\n",
    "            ).tolist()\n",
    "    else:\n",
    "        graph_df.loc[graph_df[\"node_type\"] == modality,\n",
    "                        \"score\"] = torch.nn.CosineSimilarity(dim=-1)(\n",
    "                query_emb,\n",
    "                torch.tensor(list(graph_df[graph_df[\"node_type\"]== modality].x.values))\n",
    "            ).tolist()\n",
    "\n",
    "    # Set the prizes for nodes based on the similarity scores\n",
    "    n_prizes = torch.tensor(graph_df.score.values, dtype=torch.float32)\n",
    "    # n_prizes = torch.nn.CosineSimilarity(dim=-1)(query_emb, graph.x)\n",
    "    topk = min(topk, graph.num_nodes)\n",
    "    _, topk_n_indices = torch.topk(n_prizes, topk, largest=True)\n",
    "    n_prizes = torch.zeros_like(n_prizes)\n",
    "    n_prizes[topk_n_indices] = torch.arange(topk, 0, -1).float()\n",
    "\n",
    "    return n_prizes\n",
    "\n",
    "def _compute_edge_prizes(graph: Data,\n",
    "                         text_emb: torch.Tensor) :\n",
    "    \"\"\"\n",
    "    Compute the node prizes based on the cosine similarity between the query and nodes.\n",
    "\n",
    "    Args:\n",
    "        graph: The knowledge graph in PyTorch Geometric Data format.\n",
    "        text_emb: The textual description embedding in PyTorch Tensor format.\n",
    "\n",
    "    Returns:\n",
    "        The prizes of the nodes.\n",
    "    \"\"\"\n",
    "    # Note that as of now, the edge features are based on textual features\n",
    "    # Compute prizes for edges\n",
    "    e_prizes = torch.nn.CosineSimilarity(dim=-1)(text_emb, graph.edge_attr)\n",
    "    unique_prizes, inverse_indices = e_prizes.unique(return_inverse=True)\n",
    "    topk_e = min(topk_e, unique_prizes.size(0))\n",
    "    topk_e_values, _ = torch.topk(unique_prizes, topk_e, largest=True)\n",
    "    e_prizes[e_prizes < topk_e_values[-1]] = 0.0\n",
    "    last_topk_e_value = topk_e\n",
    "    for k in range(topk_e):\n",
    "        indices = inverse_indices == (\n",
    "            unique_prizes == topk_e_values[k]\n",
    "        ).nonzero(as_tuple=True)[0]\n",
    "        value = min((topk_e - k) / indices.sum().item(), last_topk_e_value)\n",
    "        e_prizes[indices] = value\n",
    "        last_topk_e_value = value * (1 - c_const)\n",
    "\n",
    "    return e_prizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "af9a52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "graph = initial_graph[\"pyg\"]\n",
    "text_emb = torch.tensor(query_df.iloc[0]['desc_x'][0])\n",
    "query_emb = torch.tensor(query_df.iloc[0]['x'][0])\n",
    "modality = query_df.iloc[0]['node_type'][0]\n",
    "\n",
    "# Convert PyG graph to a DataFrame\n",
    "graph_df = pd.DataFrame({\n",
    "    \"node_type\": graph.node_type,\n",
    "    \"desc_x\": [x.tolist() for x in graph.desc_x],\n",
    "    \"x\": [list(x) for x in graph.x],\n",
    "    \"score\": [0.0 for _ in range(len(graph.node_id))],\n",
    "})\n",
    "\n",
    "graph_df.loc[graph_df[\"node_type\"] == modality, \"score\"]  = torch.nn.CosineSimilarity(dim=-1)(\n",
    "        query_emb,\n",
    "        torch.tensor(list(graph_df[graph_df[\"node_type\"]== modality].x.values))\n",
    "    ).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "04658e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the prizes for nodes based on the similarity scores\n",
    "n_prizes = torch.tensor(graph_df.score.values, dtype=torch.float32)\n",
    "topk = min(topk, graph.num_nodes)\n",
    "_, topk_n_indices = torch.topk(n_prizes, topk, largest=True)\n",
    "n_prizes = torch.zeros_like(n_prizes)\n",
    "n_prizes[topk_n_indices] = torch.arange(topk, 0, -1).float()\n",
    "n_prizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adee5a0e",
   "metadata": {},
   "source": [
    "### After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8e05ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import cuvs\n",
    "from cuvs.distance import pairwise_distance\n",
    "\n",
    "# Initialize several variables\n",
    "sim_scores = cudf.Series(cp.zeros(len(nodes_df), dtype=cp.float32))\n",
    "text_emb = torch.tensor(query_df.iloc[0]['desc_x'][0]) # torch.Size([768])\n",
    "query_emb = torch.tensor(query_df.iloc[0]['x'][0]) # torch.Size([2560])\n",
    "modality = query_df.iloc[0]['node_type'][0] # `gene/protein`\n",
    "\n",
    "# Compute cosine distance and similarity\n",
    "mask = (nodes_df.node_type == modality)\n",
    "cosine_distance = pairwise_distance(cp.array(nodes_df[mask][\"x\"].to_arrow().to_pylist()).astype(cp.float32), \n",
    "                                    cp.array(query_emb.cpu().numpy()).reshape(1, -1).astype(cp.float32), \n",
    "                                    metric=\"cosine\")  # shape [N, 1]\n",
    "cosine_similarity = 1 - cp.asarray(cosine_distance).ravel()\n",
    "\n",
    "# Store scores in the graph_df\n",
    "sim_scores[mask] = cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9ce15073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([5, 845, 12, 82, 22, 849, 850, 59, 9, 15], dtype='int64')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores.sort_values(ascending=False).index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5cf945a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  5, 845,  12,  82,  22, 849, 850,  59,   9,  15])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_n_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69971cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89      0.0\n",
       "90      0.0\n",
       "91      0.0\n",
       "92      0.0\n",
       "93      0.0\n",
       "       ... \n",
       "848    <NA>\n",
       "849    <NA>\n",
       "850    <NA>\n",
       "851    <NA>\n",
       "852    <NA>\n",
       "Length: 2991, dtype: float32"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0fb7ef08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  9,  8,  7,  6,  5,  4,  3,  2,  1])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.arange(topk, 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b9152e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = min(topk, sim_scores.size)\n",
    "n_prizes_ = cudf.Series(0.0, index=cp.arange(sim_scores.size))\n",
    "n_prizes_[(-sim_scores).sort_values()[:topk].index] = cp.arange(topk, 0, -1).astype(cp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "62741439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "837    <NA>\n",
       "838    <NA>\n",
       "842    <NA>\n",
       "843    <NA>\n",
       "844    <NA>\n",
       "845    <NA>\n",
       "846    <NA>\n",
       "847    <NA>\n",
       "848    <NA>\n",
       "849    <NA>\n",
       "850    <NA>\n",
       "851    <NA>\n",
       "852    <NA>\n",
       "dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores[sim_scores.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b28741a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, topk_n_indices = torch.topk(n_prizes, topk, largest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5f4f46b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cd451602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 94, 12, 82, 22, 98, 99, 59,  9, 15])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_n_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bbefb981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 94, 12, 82, 22, 98, 99, 59,  9, 15])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_n_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bfdd525b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([5, 12, 82, 22, 59, 9, 15, 44, 11, 62], dtype='int64')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-sim_scores).sort_values()[:topk].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "99b7f320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     1.000000\n",
       "94    0.000000\n",
       "12    0.989550\n",
       "82    0.981857\n",
       "22    0.980781\n",
       "98    0.000000\n",
       "99    0.000000\n",
       "59    0.979544\n",
       "9     0.978507\n",
       "15    0.978297\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores[5, 94, 12, 82, 22, 98, 99, 59,  9, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ff375335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  5.,  0.,  2.,  9.,  0.,\n",
       "         0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  6.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  8.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(n_prizes_.to_arrow().to_pylist()).float()\n",
    "a[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "316c9567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9762842655181885,\n",
       " 0.8985072374343872,\n",
       " 0.9174196124076843,\n",
       " 0.974480390548706,\n",
       " 0.9627967476844788,\n",
       " 0.9999995231628418,\n",
       " 0.968204915523529,\n",
       " 0.8944925665855408,\n",
       " 0.9456265568733215,\n",
       " 0.9785073399543762,\n",
       " 0.9755682945251465,\n",
       " 0.977044403553009,\n",
       " 0.9895495176315308,\n",
       " 0.9467787742614746,\n",
       " 0.9746270179748535,\n",
       " 0.9782971143722534,\n",
       " 0.9550138711929321,\n",
       " 0.9491298198699951,\n",
       " 0.9711894989013672,\n",
       " 0.9494197368621826,\n",
       " 0.9682755470275879,\n",
       " 0.9343744516372681,\n",
       " 0.9807805418968201,\n",
       " 0.9611757397651672,\n",
       " 0.9460437893867493,\n",
       " 0.9518918395042419,\n",
       " 0.9323171973228455,\n",
       " 0.9732439517974854,\n",
       " 0.8083146214485168,\n",
       " 0.906587541103363,\n",
       " 0.9759802222251892,\n",
       " 0.9287912845611572,\n",
       " 0.924881100654602,\n",
       " 0.9658037424087524,\n",
       " 0.9527099132537842,\n",
       " 0.7955286502838135,\n",
       " 0.9495731592178345,\n",
       " 0.9741109609603882,\n",
       " 0.9529463648796082,\n",
       " 0.968661367893219,\n",
       " 0.9751885533332825,\n",
       " 0.968982994556427,\n",
       " 0.97170490026474,\n",
       " 0.9425373673439026,\n",
       " 0.9780073165893555,\n",
       " 0.9757586717605591,\n",
       " 0.9519517421722412,\n",
       " 0.9541404247283936,\n",
       " 0.9324031472206116,\n",
       " 0.9444659948348999,\n",
       " 0.9207035303115845,\n",
       " 0.958713173866272,\n",
       " 0.9603100419044495,\n",
       " 0.9509280920028687,\n",
       " 0.9755832552909851,\n",
       " 0.9468240737915039,\n",
       " 0.9251384735107422,\n",
       " 0.9669831991195679,\n",
       " 0.9164014458656311,\n",
       " 0.9795435070991516,\n",
       " 0.9578174948692322,\n",
       " 0.9454702734947205,\n",
       " 0.9764737486839294,\n",
       " 0.9128760099411011,\n",
       " 0.9676182270050049,\n",
       " 0.9683283567428589,\n",
       " 0.9735762476921082,\n",
       " 0.9461075067520142,\n",
       " 0.9410497546195984,\n",
       " 0.9675152897834778,\n",
       " 0.9416022300720215,\n",
       " 0.973954975605011,\n",
       " 0.9711154699325562,\n",
       " 0.9286346435546875,\n",
       " 0.9672448039054871,\n",
       " 0.9546087384223938,\n",
       " 0.9340300559997559,\n",
       " 0.9451399445533752,\n",
       " 0.9537164568901062,\n",
       " 0.9713762402534485,\n",
       " 0.9390751123428345,\n",
       " 0.9758221507072449,\n",
       " 0.981857419013977,\n",
       " 0.9691124558448792,\n",
       " 0.9474369883537292,\n",
       " 0.9591521620750427,\n",
       " 0.9748917818069458,\n",
       " 0.9645649194717407,\n",
       " 0.9729636311531067,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " None,\n",
       " None,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores.to_arrow().to_pylist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d573dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the prizes for nodes based on the similarity scores\n",
    "n_prizes = torch.tensor(scores, dtype=torch.float32)\n",
    "topk = min(topk, graph.num_nodes)\n",
    "_, topk_n_indices = torch.topk(n_prizes, topk, largest=True)\n",
    "# n_prizes = torch.zeros_like(n_prizes)\n",
    "# n_prizes[topk_n_indices] = torch.arange(topk, 0, -1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b15682c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(topk, graph.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1d0b54a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cuvs' has no attribute 'selection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m scores_cp \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39masarray(scores, dtype\u001b[38;5;241m=\u001b[39mcp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      2\u001b[0m topk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(topk, nodes_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[43mcuvs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselection\u001b[49m\u001b[38;5;241m.\u001b[39mselect_k(scores_cp, k\u001b[38;5;241m=\u001b[39mtopk, select_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkth_largest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cuvs' has no attribute 'selection'"
     ]
    }
   ],
   "source": [
    "scores_cp = cp.asarray(scores, dtype=cp.float32)\n",
    "topk = min(topk, nodes_df.shape[0])\n",
    "cuvs.selection.select_k(scores_cp, k=topk, select_type='kth_largest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9ccc8f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9763, 0.8985, 0.9174, 0.9745, 0.9628, 1.0000, 0.9682, 0.8945, 0.9456,\n",
       "        0.9785, 0.9756, 0.9770, 0.9896, 0.9468, 0.9746, 0.9783, 0.9550, 0.9491,\n",
       "        0.9712, 0.9494, 0.9683, 0.9344, 0.9808, 0.9612, 0.9460, 0.9519, 0.9323,\n",
       "        0.9732, 0.8083, 0.9066, 0.9760, 0.9288, 0.9249, 0.9658, 0.9527, 0.7955,\n",
       "        0.9496, 0.9741, 0.9529, 0.9687, 0.9752, 0.9690, 0.9717, 0.9425, 0.9780,\n",
       "        0.9758, 0.9520, 0.9541, 0.9324, 0.9445, 0.9207, 0.9587, 0.9603, 0.9509,\n",
       "        0.9756, 0.9468, 0.9251, 0.9670, 0.9164, 0.9795, 0.9578, 0.9455, 0.9765,\n",
       "        0.9129, 0.9676, 0.9683, 0.9736, 0.9461, 0.9411, 0.9675, 0.9416, 0.9740,\n",
       "        0.9711, 0.9286, 0.9672, 0.9546, 0.9340, 0.9451, 0.9537, 0.9714, 0.9391,\n",
       "        0.9758, 0.9819, 0.9691, 0.9474, 0.9592, 0.9749, 0.9646, 0.9730, 0.9561,\n",
       "        0.9326, 0.9668, 0.9626, 0.9579, 0.9899, 0.9696, 0.9358, 0.9430, 0.9804,\n",
       "        0.9797, 0.9782, 0.9713])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_prizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "51c4023a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  2.,  0.,  0.,  8.,  0.,\n",
       "         0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,\n",
       "         5.,  4.,  0.,  0.])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_prizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ef3b67a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.976284384727478,\n",
       " 0.8985079526901245,\n",
       " 0.9174203872680664,\n",
       " 0.9744806885719299,\n",
       " 0.9627973437309265,\n",
       " 1.000000238418579,\n",
       " 0.9682051539421082,\n",
       " 0.8944931626319885,\n",
       " 0.9456267952919006,\n",
       " 0.978507399559021,\n",
       " 0.9755687117576599,\n",
       " 0.9770446419715881,\n",
       " 0.9895502924919128,\n",
       " 0.9467793107032776,\n",
       " 0.9746269583702087,\n",
       " 0.978297770023346,\n",
       " 0.9550144076347351,\n",
       " 0.9491303563117981,\n",
       " 0.9711899161338806,\n",
       " 0.949420154094696,\n",
       " 0.9682762622833252,\n",
       " 0.9343748092651367,\n",
       " 0.980780839920044,\n",
       " 0.961176335811615,\n",
       " 0.9460442662239075,\n",
       " 0.9518922567367554,\n",
       " 0.932317852973938,\n",
       " 0.9732446074485779,\n",
       " 0.8083150386810303,\n",
       " 0.9065879583358765,\n",
       " 0.9759810566902161,\n",
       " 0.9287917613983154,\n",
       " 0.924881637096405,\n",
       " 0.9658040404319763,\n",
       " 0.9527105689048767,\n",
       " 0.7955290079116821,\n",
       " 0.9495737552642822,\n",
       " 0.9741115570068359,\n",
       " 0.9529469609260559,\n",
       " 0.9686618447303772,\n",
       " 0.9751890301704407,\n",
       " 0.9689838886260986,\n",
       " 0.9717056751251221,\n",
       " 0.9425379633903503,\n",
       " 0.9780075550079346,\n",
       " 0.9757587909698486,\n",
       " 0.9519528746604919,\n",
       " 0.954140841960907,\n",
       " 0.9324033856391907,\n",
       " 0.9444662928581238,\n",
       " 0.9207038879394531,\n",
       " 0.9587132334709167,\n",
       " 0.9603102207183838,\n",
       " 0.9509289264678955,\n",
       " 0.9755833745002747,\n",
       " 0.9468245506286621,\n",
       " 0.9251387715339661,\n",
       " 0.96698397397995,\n",
       " 0.9164019227027893,\n",
       " 0.9795442819595337,\n",
       " 0.9578176736831665,\n",
       " 0.9454708695411682,\n",
       " 0.9764742255210876,\n",
       " 0.9128766655921936,\n",
       " 0.9676188826560974,\n",
       " 0.9683290123939514,\n",
       " 0.9735767841339111,\n",
       " 0.946107804775238,\n",
       " 0.9410502910614014,\n",
       " 0.967516303062439,\n",
       " 0.9416028261184692,\n",
       " 0.9739552736282349,\n",
       " 0.9711155891418457,\n",
       " 0.9286351203918457,\n",
       " 0.9672455787658691,\n",
       " 0.9546090364456177,\n",
       " 0.9340299963951111,\n",
       " 0.9451403021812439,\n",
       " 0.9537164568901062,\n",
       " 0.9713769555091858,\n",
       " 0.9390756487846375,\n",
       " 0.975823163986206,\n",
       " 0.9818581342697144,\n",
       " 0.9691125750541687,\n",
       " 0.947436511516571,\n",
       " 0.959152340888977,\n",
       " 0.9748916625976562,\n",
       " 0.964565098285675,\n",
       " 0.9729644060134888,\n",
       " 0.956136167049408,\n",
       " 0.9326204657554626,\n",
       " 0.9667711853981018,\n",
       " 0.9626268148422241,\n",
       " 0.9578860402107239,\n",
       " 0.9898545145988464,\n",
       " 0.9696245193481445,\n",
       " 0.9357683062553406,\n",
       " 0.9429613351821899,\n",
       " 0.9803764820098877,\n",
       " 0.9796908497810364,\n",
       " 0.9781819581985474,\n",
       " 0.9712690711021423]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e7fab8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.976284\n",
       "1    0.898507\n",
       "2    0.917420\n",
       "3    0.974480\n",
       "4    0.962797\n",
       "5    1.000000\n",
       "6    0.968205\n",
       "7    0.894493\n",
       "8    0.945627\n",
       "9    0.978507\n",
       "dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cf4608fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2560"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "node_mask = (graph.node_type == modality)\n",
    "len(graph.x[node_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8a9983b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "        ...  \n",
       "2986    False\n",
       "2987    False\n",
       "2988    False\n",
       "2989    False\n",
       "2990    False\n",
       "Length: 2991, dtype: bool"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cudf.Series(initial_graph[\"pyg\"].node_type) == 'gene/protein'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7674e82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.976284384727478,\n",
       "  0.8985079526901245,\n",
       "  0.9174203872680664,\n",
       "  0.9744806885719299,\n",
       "  0.9627973437309265,\n",
       "  1.000000238418579,\n",
       "  0.9682051539421082,\n",
       "  0.8944931626319885,\n",
       "  0.9456267952919006,\n",
       "  0.978507399559021],\n",
       " 0    0.976284\n",
       " 1    0.898507\n",
       " 2    0.917420\n",
       " 3    0.974480\n",
       " 4    0.962797\n",
       " 5    1.000000\n",
       " 6    0.968205\n",
       " 7    0.894493\n",
       " 8    0.945627\n",
       " 9    0.978507\n",
       " dtype: float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:10], scores_new[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc130e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.3715734e-02, 1.0149276e-01, 8.2580388e-02, 2.5519609e-02,\n",
       "       3.7203252e-02, 4.7683716e-07, 3.1795084e-02, 1.0550743e-01,\n",
       "       5.4373443e-02, 2.1492660e-02, 2.4431705e-02, 2.2955596e-02,\n",
       "       1.0450482e-02, 5.3221226e-02, 2.5372982e-02, 2.1702886e-02,\n",
       "       4.4986129e-02, 5.0870180e-02, 2.8810501e-02, 5.0580263e-02,\n",
       "       3.1724453e-02, 6.5625548e-02, 1.9219458e-02, 3.8824260e-02,\n",
       "       5.3956211e-02, 4.8108160e-02, 6.7682803e-02, 2.6756048e-02,\n",
       "       1.9168538e-01, 9.3412459e-02, 2.4019778e-02, 7.1208715e-02,\n",
       "       7.5118899e-02, 3.4196258e-02, 4.7290087e-02, 2.0447135e-01,\n",
       "       5.0426841e-02, 2.5889039e-02, 4.7053635e-02, 3.1338632e-02,\n",
       "       2.4811447e-02, 3.1017005e-02, 2.8295100e-02, 5.7462633e-02,\n",
       "       2.1992683e-02, 2.4241328e-02, 4.8048258e-02, 4.5859575e-02,\n",
       "       6.7596853e-02, 5.5534005e-02, 7.9296470e-02, 4.1286826e-02,\n",
       "       3.9689958e-02, 4.9071908e-02, 2.4416745e-02, 5.3175926e-02,\n",
       "       7.4861526e-02, 3.3016801e-02, 8.3598554e-02, 2.0456493e-02,\n",
       "       4.2182505e-02, 5.4529727e-02, 2.3526251e-02, 8.7123990e-02,\n",
       "       3.2381773e-02, 3.1671643e-02, 2.6423752e-02, 5.3892493e-02,\n",
       "       5.8950245e-02, 3.2484710e-02, 5.8397770e-02, 2.6045024e-02,\n",
       "       2.8884530e-02, 7.1365356e-02, 3.2755196e-02, 4.5391262e-02,\n",
       "       6.5969944e-02, 5.4860055e-02, 4.6283543e-02, 2.8623760e-02,\n",
       "       6.0924888e-02, 2.4177849e-02, 1.8142581e-02, 3.0887544e-02,\n",
       "       5.2563012e-02, 4.0847838e-02, 2.5108218e-02, 3.5435081e-02,\n",
       "       2.7036369e-02, 4.3864191e-02, 6.7379713e-02, 3.3228934e-02,\n",
       "       3.7374139e-02, 4.2114496e-02, 1.0146022e-02, 3.0375779e-02,\n",
       "       6.4232469e-02, 5.7038844e-02, 1.9623637e-02, 2.0309746e-02,\n",
       "       2.1818280e-02, 2.8731823e-02], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9f6e1cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "*obj* doesn't implement the cuda array interface.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m graph_df\u001b[38;5;241m.\u001b[39mloc[graph_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m modality,\n\u001b[1;32m      2\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCosineSimilarity(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(\n\u001b[1;32m      3\u001b[0m         query_emb,\n\u001b[0;32m----> 4\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlist\u001b[39m(\u001b[43mgraph_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgraph_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnode_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodality\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m))\n\u001b[1;32m      5\u001b[0m     )\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/cudf/utils/performance_tracking.py:51\u001b[0m, in \u001b[0;36m_performance_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nvtx\u001b[38;5;241m.\u001b[39menabled():\n\u001b[1;32m     44\u001b[0m     stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m     45\u001b[0m         nvtx\u001b[38;5;241m.\u001b[39mannotate(\n\u001b[1;32m     46\u001b[0m             message\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m         )\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/cudf/core/single_column_frame.py:109\u001b[0m, in \u001b[0;36mSingleColumnFrame.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;129m@property\u001b[39m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;129m@_performance_tracking\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m cupy\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_column\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/cudf/core/column/column.py:677\u001b[0m, in \u001b[0;36mColumnBase.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_nulls():\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn must have no nulls.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 677\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cupy\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_array_view\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/cudf/core/column/column.py:568\u001b[0m, in \u001b[0;36mColumnBase.data_array_view\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    567\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_cuda_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/numba_cuda/numba/cuda/api.py:74\u001b[0m, in \u001b[0;36mas_cuda_array\u001b[0;34m(obj, sync)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a DeviceNDArray from any object that implements\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03mthe :ref:`cuda array interface <cuda-array-interface>`.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03msynchronized.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cuda_array(obj):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*obj* doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt implement the cuda array interface.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_cuda_array_interface(obj\u001b[38;5;241m.\u001b[39m__cuda_array_interface__,\n\u001b[1;32m     77\u001b[0m                                      owner\u001b[38;5;241m=\u001b[39mobj, sync\u001b[38;5;241m=\u001b[39msync)\n",
      "\u001b[0;31mTypeError\u001b[0m: *obj* doesn't implement the cuda array interface."
     ]
    }
   ],
   "source": [
    "graph_df.loc[graph_df[\"node_type\"] == modality,\n",
    "                \"score\"] = torch.nn.CosineSimilarity(dim=-1)(\n",
    "        query_emb,\n",
    "        torch.tensor(list(graph_df[graph_df[\"node_type\"]== modality].x.values))\n",
    "    ).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fce67034",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "*obj* doesn't implement the cuda array interface.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m modality \u001b[38;5;241m=\u001b[39m query_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_type\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Compute prizes for nodes\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m n_prizes \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_node_prizes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodality\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Compute prizes for edges\u001b[39;00m\n\u001b[1;32m     10\u001b[0m e_prizes \u001b[38;5;241m=\u001b[39m _compute_edge_prizes(graph, text_emb)\n",
      "Cell \u001b[0;32mIn[14], line 41\u001b[0m, in \u001b[0;36m_compute_node_prizes\u001b[0;34m(graph, query_emb, modality, use_description)\u001b[0m\n\u001b[1;32m     33\u001b[0m     graph_df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCosineSimilarity(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(\n\u001b[1;32m     34\u001b[0m             query_emb,\n\u001b[1;32m     35\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlist\u001b[39m(graph_df\u001b[38;5;241m.\u001b[39mdesc_x\u001b[38;5;241m.\u001b[39mvalues)) \u001b[38;5;66;03m# Using textual description features\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     graph_df\u001b[38;5;241m.\u001b[39mloc[graph_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m modality,\n\u001b[1;32m     39\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCosineSimilarity(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(\n\u001b[1;32m     40\u001b[0m             query_emb,\n\u001b[0;32m---> 41\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlist\u001b[39m(\u001b[43mgraph_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgraph_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnode_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodality\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m))\n\u001b[1;32m     42\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Set the prizes for nodes based on the similarity scores\u001b[39;00m\n\u001b[1;32m     45\u001b[0m n_prizes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(graph_df\u001b[38;5;241m.\u001b[39mscore\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/cudf/utils/performance_tracking.py:51\u001b[0m, in \u001b[0;36m_performance_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nvtx\u001b[38;5;241m.\u001b[39menabled():\n\u001b[1;32m     44\u001b[0m     stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m     45\u001b[0m         nvtx\u001b[38;5;241m.\u001b[39mannotate(\n\u001b[1;32m     46\u001b[0m             message\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m         )\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/cudf/core/single_column_frame.py:109\u001b[0m, in \u001b[0;36mSingleColumnFrame.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;129m@property\u001b[39m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;129m@_performance_tracking\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m cupy\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_column\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/cudf/core/column/column.py:677\u001b[0m, in \u001b[0;36mColumnBase.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_nulls():\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn must have no nulls.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 677\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cupy\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_array_view\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/cudf/core/column/column.py:568\u001b[0m, in \u001b[0;36mColumnBase.data_array_view\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    567\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_cuda_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/numba_cuda/numba/cuda/api.py:74\u001b[0m, in \u001b[0;36mas_cuda_array\u001b[0;34m(obj, sync)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a DeviceNDArray from any object that implements\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03mthe :ref:`cuda array interface <cuda-array-interface>`.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03msynchronized.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cuda_array(obj):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*obj* doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt implement the cuda array interface.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_cuda_array_interface(obj\u001b[38;5;241m.\u001b[39m__cuda_array_interface__,\n\u001b[1;32m     77\u001b[0m                                      owner\u001b[38;5;241m=\u001b[39mobj, sync\u001b[38;5;241m=\u001b[39msync)\n",
      "\u001b[0;31mTypeError\u001b[0m: *obj* doesn't implement the cuda array interface."
     ]
    }
   ],
   "source": [
    "graph = initial_graph[\"pyg\"]\n",
    "text_emb = torch.tensor(query_df.iloc[0]['desc_x'][0])\n",
    "query_emb = torch.tensor(query_df.iloc[0]['x'][0])\n",
    "modality = query_df.iloc[0]['node_type'][0]\n",
    "\n",
    "# Compute prizes for nodes\n",
    "n_prizes = _compute_node_prizes(graph, query_emb, modality)\n",
    "\n",
    "# Compute prizes for edges\n",
    "e_prizes = _compute_edge_prizes(graph, text_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e7fd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the subgraph dictionary\n",
    "subgraphs = {}\n",
    "subgraphs[\"nodes\"] = []\n",
    "subgraphs[\"edges\"] = []\n",
    "\n",
    "# Loop over query embeddings and modalities\n",
    "for q in query_df.to_pandas().iterrows():\n",
    "    # Prepare the PCSTPruning object and extract the subgraph\n",
    "    # Parameters were set in the configuration file obtained from Hydra\n",
    "    subgraph = MultimodalPCSTPruning(\n",
    "        topk=state[\"topk_nodes\"],\n",
    "        topk_e=state[\"topk_edges\"],\n",
    "        cost_e=cfg.cost_e,\n",
    "        c_const=cfg.c_const,\n",
    "        root=cfg.root,\n",
    "        num_clusters=cfg.num_clusters,\n",
    "        pruning=cfg.pruning,\n",
    "        verbosity_level=cfg.verbosity_level,\n",
    "        use_description=q[1]['use_description'],\n",
    "    ).extract_subgraph(pyg_graph,\n",
    "                        torch.tensor(q[1]['desc_x']), # description embedding\n",
    "                        torch.tensor(q[1]['x']), # modal-specific embedding\n",
    "                        q[1]['node_type'])\n",
    "\n",
    "    # Append the extracted subgraph to the dictionary\n",
    "    subgraphs[\"nodes\"].append(subgraph[\"nodes\"].tolist())\n",
    "    subgraphs[\"edges\"].append(subgraph[\"edges\"].tolist())\n",
    "\n",
    "# Concatenate and get unique node and edge indices\n",
    "subgraphs[\"nodes\"] = np.unique(\n",
    "    np.concatenate([np.array(list_) for list_ in subgraphs[\"nodes\"]])\n",
    ")\n",
    "subgraphs[\"edges\"] = np.unique(\n",
    "    np.concatenate([np.array(list_) for list_ in subgraphs[\"edges\"]])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41f062a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': array([   3,    5,    9,   10,   12,   15,   22,   27,   30,   31,   40,\n",
       "          44,   54,   59,   62,   63,   71,   72,   73,   82,   87,  839,\n",
       "         840,  841,  845,  846,  849,  850,  851,  853,  854,  855,  869,\n",
       "        1176, 1320, 1372, 1415, 1734, 1747, 1918, 1933, 1952, 2102, 2113,\n",
       "        2263, 2435, 2447, 2479, 2779, 2827, 2886]),\n",
       " 'edges': array([  166,   167,   272,   273,   276,   277,   291,   292,   296,\n",
       "          299,   301,   302,   553,  1922,  2055,  2097,  2703,  2930,\n",
       "         2931,  2932,  3930,  3936,  3938,  3940,  3944,  3950,  3951,\n",
       "         3952,  3953,  3954,  4410,  4671,  4683,  4703,  5270,  6303,\n",
       "         6320,  6357,  6363,  6372,  6381,  6398,  6490,  6564,  6575,\n",
       "         6712,  6743,  6819,  9015,  9140,  9142,  9143,  9597,  9694,\n",
       "        11056, 11070, 11078])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before optimiziation\n",
    "before_ = subgraphs\n",
    "before_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ad2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
