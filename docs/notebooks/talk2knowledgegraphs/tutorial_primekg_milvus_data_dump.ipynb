{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de0f1c5",
   "metadata": {},
   "source": [
    "In this tutorial, we will prepare Milvus database for storing and searching nodes and edges of a graph.\n",
    "\n",
    "In particular, we are using PrimeKG multimodal data from the BioBridge project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import hydra\n",
    "import cudf\n",
    "import cupy as cp\n",
    "from pymilvus import MilvusClient, Collection, CollectionSchema, FieldSchema, DataType, connections, utility, MilvusClient\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac57d9a5",
   "metadata": {},
   "source": [
    "### Loading BioBridge-PrimeKG Multimodal Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e8eb8",
   "metadata": {},
   "source": [
    "First, we need to get the path to the directory containing the parquet files of nodes and edges.\n",
    "\n",
    "For nodes and edges, we have a separate folder that contains its enrichment and embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff16637a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_target_': 'talk2knowledgegraphs.tools.multimodal_subgraph_extraction', 'ollama_embeddings': ['nomic-embed-text'], 'temperature': 0.1, 'streaming': False, 'topk': 5, 'topk_e': 5, 'cost_e': 0.5, 'c_const': 0.01, 'root': -1, 'num_clusters': 1, 'pruning': 'gw', 'verbosity_level': 0, 'node_id_column': 'node_id', 'node_attr_column': 'node_attr', 'edge_src_column': 'edge_src', 'edge_attr_column': 'edge_attr', 'edge_dst_column': 'edge_dst', 'node_colors_dict': {'gene/protein': '#6a79f7', 'molecular_function': '#82cafc', 'cellular_component': '#3f9b0b', 'biological_process': '#c5c9c7', 'drug': '#c4a661', 'disease': '#80013f'}, 'biobridge': {'source': '/mnt/blockstorage/biobridge_multimodal/', 'node_type': ['gene/protein', 'molecular_function', 'cellular_component', 'biological_process', 'drug', 'disease']}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load hydra configuration\n",
    "with hydra.initialize(version_base=None, config_path=\"../../../aiagents4pharma/talk2knowledgegraphs/configs\"):\n",
    "    cfg = hydra.compose(\n",
    "        config_name=\"config\", overrides=[\"tools/multimodal_subgraph_extraction=default\"]\n",
    "    )\n",
    "    cfg = cfg.tools.multimodal_subgraph_extraction\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9854940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set the source directory for biobridge data here\n",
    "cfg.biobridge.source = \"/mnt/blockstorage/biobridge_multimodal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecdb3496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes enrichment\n",
      "['/mnt/blockstorage/biobridge_multimodal/nodes/enrichment/drug.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/nodes/enrichment/cellular_component.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/nodes/enrichment/gene_protein.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/nodes/enrichment/disease.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/nodes/enrichment/biological_process.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/nodes/enrichment/molecular_function.parquet.gzip']\n",
      "nodes embedding\n",
      "['/mnt/blockstorage/biobridge_multimodal/nodes/embedding/drug.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/nodes/embedding/cellular_component.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/nodes/embedding/gene_protein.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/nodes/embedding/disease.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/nodes/embedding/biological_process.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/nodes/embedding/molecular_function.parquet.gzip']\n",
      "edges enrichment\n",
      "['/mnt/blockstorage/biobridge_multimodal/edges/enrichment/edges.parquet.gzip']\n",
      "edges embedding\n",
      "['/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3050000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2250000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1150000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_600000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1550000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1750000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3100000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1600000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2750000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2950000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3700000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_500000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_800000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1050000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_300000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_250000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3600000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_900000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2400000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1100000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3450000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_400000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1500000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_0.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1250000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3900000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1400000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_50000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1450000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1800000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1000000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1950000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2100000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2350000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3500000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3750000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2800000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1350000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_150000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2500000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_450000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_850000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1850000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3000000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_550000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_200000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3300000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2650000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3350000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_100000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3400000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3550000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_350000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3800000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3200000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2850000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2200000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3850000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3250000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2900000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_750000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1300000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2300000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2700000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3150000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1900000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2150000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_950000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2450000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1700000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_650000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_3650000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2550000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_700000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2000000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2600000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_2050000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1200000.parquet.gzip', '/mnt/blockstorage/biobridge_multimodal/edges/embedding/edges_1650000.parquet.gzip']\n"
     ]
    }
   ],
   "source": [
    "# Loop over nodes and edges\n",
    "graph_dict = {}\n",
    "for element in [\"nodes\", \"edges\"]:\n",
    "    # Make an empty dictionary for each folder\n",
    "    graph_dict[element] = {}\n",
    "    for stage in [\"enrichment\", \"embedding\"]:\n",
    "        print(element, stage)\n",
    "        # Create the file pattern for the current subfolder\n",
    "        file_list = glob.glob(os.path.join(cfg.biobridge.source,\n",
    "                                           element,\n",
    "                                           stage, '*.parquet.gzip'))\n",
    "        print(file_list)\n",
    "        # Read and concatenate all dataframes in the folder\n",
    "        # Except the edges embedding, which is too large to read in one go\n",
    "        # We are using a chunk size to read the edges embedding in smaller parts instead\n",
    "        if element == \"edges\" and stage == \"embedding\":\n",
    "            # For edges embedding, only read two columns: triplet_index and edge_emb\n",
    "            # graph_dict[element][stage] = cudf.concat([cudf.read_parquet(f, columns=[\"triplet_index\", \"edge_emb\"]) for f in file_list[:2]], ignore_index=True)\n",
    "            # Loop by chunks\n",
    "            # file_list = file_list[:2]\n",
    "            chunk_size = 5\n",
    "            graph_dict[element][stage] = []\n",
    "            for i in range(0, len(file_list), chunk_size):\n",
    "                chunk_files = file_list[i:i+chunk_size]\n",
    "                chunk_df = cudf.concat([cudf.read_parquet(f, columns=[\"triplet_index\", \"edge_emb\"]) for f in chunk_files], ignore_index=True)\n",
    "                graph_dict[element][stage].append(chunk_df)\n",
    "        else:\n",
    "            # For nodes and edges enrichment, read and concatenate all dataframes in the folder\n",
    "            # This includes the nodes embedding, which is small enough to read in one go\n",
    "            graph_dict[element][stage] = cudf.concat([cudf.read_parquet(f) for f in file_list], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nodes enrichment and embedding dataframes\n",
    "nodes_enrichment_df = graph_dict['nodes']['enrichment']\n",
    "nodes_embedding_df = graph_dict['nodes']['embedding']\n",
    "\n",
    "# Get edges enrichment and embedding dataframes\n",
    "edges_enrichment_df = graph_dict['edges']['enrichment']\n",
    "edges_embedding_df = graph_dict['edges']['embedding'] # !!consisted of a list of dataframes!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb11ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge nodes enrichment and embedding dataframes\n",
    "merged_nodes_df = nodes_enrichment_df.merge(\n",
    "    nodes_embedding_df[[\"node_id\", \"desc_emb\", \"feat_emb\"]],\n",
    "    on=\"node_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "# del nodes_enrichment_df, nodes_embedding_df  # Free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946e4a7",
   "metadata": {},
   "source": [
    "### Setup Milvus Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1672082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Milvus\n",
    "milvus_uri = \"http://localhost:19530\"\n",
    "milvus_token = \"root:Milvus\"\n",
    "milvus_database = \"t2kg_primekg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abdd7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    uri=milvus_uri,\n",
    "    token=milvus_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de426ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Milvus client and database\n",
    "milvus_client = MilvusClient(uri=milvus_uri, token=milvus_token)\n",
    "# Check if the database exists, if not create it\n",
    "if milvus_database not in milvus_client.list_databases():\n",
    "    # Create the database if it does not exist\n",
    "    milvus_client.create_database(db_name=milvus_database)\n",
    "# Use the newly created database\n",
    "milvus_client.using_database(milvus_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6225958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to chunk the data into smaller parts\n",
    "# Utility: chunk generator\n",
    "def chunked(data_list, chunk_size):\n",
    "    for i in range(0, len(data_list), chunk_size):\n",
    "        yield data_list[i:i + chunk_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf8ae0",
   "metadata": {},
   "source": [
    "#### Building Node Collection (Description Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bccba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Milvus collection\n",
    "node_coll_name = f\"{milvus_database}_nodes\"\n",
    "\n",
    "# Define schema for the collection\n",
    "# Leave out the feat and feat_emb fields for now\n",
    "desc_emb_dim = len(merged_nodes_df.iloc[0]['desc_emb'].to_arrow().to_pylist()[0])\n",
    "node_fields = [\n",
    "    FieldSchema(name=\"node_index\", dtype=DataType.INT64, is_primary=True),\n",
    "    FieldSchema(name=\"node_id\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "    FieldSchema(name=\"node_name\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "    FieldSchema(name=\"node_type\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "    FieldSchema(name=\"desc\", dtype=DataType.VARCHAR, max_length=40960),\n",
    "    FieldSchema(name=\"desc_emb\", dtype=DataType.FLOAT_VECTOR, dim=desc_emb_dim),\n",
    "]\n",
    "node_schema = CollectionSchema(fields=node_fields, description=f\"schema for collection {node_coll_name}\")\n",
    "\n",
    "# Set index params\n",
    "index_params = milvus_client.prepare_index_params()\n",
    "# Indexing for node_index field\n",
    "index_params.add_index(field_name=\"node_index\", index_type=\"STL_SORT\",\n",
    "                        index_name=\"node_index_index\")\n",
    "# Indexing for desc_emb field\n",
    "index_params.add_index(field_name=\"desc_emb\", index_type=\"AUTOINDEX\",\n",
    "                        index_name=\"desc_emb_index\", metric_type=\"COSINE\")\n",
    "\n",
    "# Create the collection if it does not exist\n",
    "if node_coll_name not in milvus_client.list_collections():\n",
    "    milvus_client.create_collection(collection_name=node_coll_name,\n",
    "                                    schema=node_schema,\n",
    "                                    index_params=index_params)\n",
    "\n",
    "# # Create index for scalar field `node_index`\n",
    "# collection = Collection(name=node_coll_name)\n",
    "# collection.create_index(\n",
    "#     field_name=\"node_index\",\n",
    "#     index_params={\n",
    "#         \"index_type\": \"STL_SORT\"  # Scalar index for filtering\n",
    "#     },\n",
    "#     index_name=\"node_index_index\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Populate the collection with data\n",
    "# Build list of records\n",
    "data = [\n",
    "    {\n",
    "        \"node_index\": idx,\n",
    "        \"node_id\": nid,\n",
    "        \"node_name\": nname,\n",
    "        \"node_type\": ntype,\n",
    "        \"desc\": desc,\n",
    "        \"feat\": feat,\n",
    "        \"desc_emb\": desc_emb,\n",
    "    }\n",
    "    for idx, nid, nname, ntype, desc, feat, desc_emb, feat_emb in zip(\n",
    "        merged_nodes_df[\"node_index\"].to_arrow().to_pylist(),\n",
    "        merged_nodes_df[\"node_id\"].to_arrow().to_pylist(),\n",
    "        merged_nodes_df[\"node_name\"].to_arrow().to_pylist(),\n",
    "        merged_nodes_df[\"node_type\"].to_arrow().to_pylist(),\n",
    "        merged_nodes_df[\"desc\"].to_arrow().to_pylist(),\n",
    "        merged_nodes_df[\"desc_emb\"].list.leaves.to_cupy().astype(cp.float32).reshape(merged_nodes_df.shape[0], -1).tolist()\n",
    "    )\n",
    "]\n",
    "\n",
    "# Insert data in chunks to avoid memory issues\n",
    "# Batch insert into Milvus\n",
    "batch_size = 500\n",
    "for i, batch in tqdm(enumerate(chunked(data, batch_size))):\n",
    "    # print(f\"Inserting batch {i + 1}/{(len(data) - 1) // batch_size + 1} ...\")\n",
    "    milvus_client.insert(collection_name=node_coll_name, data=batch)\n",
    "\n",
    "# Flush the collection to ensure data is written\n",
    "milvus_client.flush(collection_name=node_coll_name)\n",
    "\n",
    "# Printout collection status\n",
    "print(milvus_client.get_collection_stats(collection_name=node_coll_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coll in milvus_client.list_collections():\n",
    "    print(f\"Collection: {coll}\")\n",
    "    print(milvus_client.get_collection_stats(collection_name=coll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = milvus_client.query(\n",
    "    collection_name=node_coll_name,\n",
    "    filter=\"node_index == 4992\"\n",
    "    # filter=\"node_index in [4992]\"\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d537f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = milvus_client.query(\n",
    "    collection_name=node_coll_name,\n",
    "    # filter=\"node_index == 4992\"\n",
    "    filter=\"node_index in [4992]\"\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36378f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vector_to_search = merged_nodes_df[\"desc_emb\"].loc[2]\n",
    "\n",
    "# Vector similarity search in Milvus by defining a particular collection (node_type)\n",
    "results = milvus_client.search(\n",
    "    collection_name='t2kg_primekg_node_gene_protein',\n",
    "    data=[vector_to_search],\n",
    "    anns_field=\"desc_emb\",\n",
    "    output_fields=[\"node_id\", \"node_name\"],\n",
    "    search_params={\"metric_type\": \"COSINE\"},\n",
    "    limit=10,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b682b66a",
   "metadata": {},
   "source": [
    "#### Building Node Collection (Node Type-specific Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab68486",
   "metadata": {},
   "source": [
    "Note that nodes information of the PrimeKG data is different for each node type, \n",
    "we are going to build a separate collection for each node type.\n",
    "\n",
    "We will use the node type as the collection name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f350f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node type: biological_process\n",
      "Inserting batch 1/55 ...\n",
      "Inserting batch 2/55 ...\n",
      "Inserting batch 3/55 ...\n",
      "Inserting batch 4/55 ...\n",
      "Inserting batch 5/55 ...\n",
      "Inserting batch 6/55 ...\n",
      "Inserting batch 7/55 ...\n",
      "Inserting batch 8/55 ...\n",
      "Inserting batch 9/55 ...\n",
      "Inserting batch 10/55 ...\n",
      "Inserting batch 11/55 ...\n",
      "Inserting batch 12/55 ...\n",
      "Inserting batch 13/55 ...\n",
      "Inserting batch 14/55 ...\n",
      "Inserting batch 15/55 ...\n",
      "Inserting batch 16/55 ...\n",
      "Inserting batch 17/55 ...\n",
      "Inserting batch 18/55 ...\n",
      "Inserting batch 19/55 ...\n",
      "Inserting batch 20/55 ...\n",
      "Inserting batch 21/55 ...\n",
      "Inserting batch 22/55 ...\n",
      "Inserting batch 23/55 ...\n",
      "Inserting batch 24/55 ...\n",
      "Inserting batch 25/55 ...\n",
      "Inserting batch 26/55 ...\n",
      "Inserting batch 27/55 ...\n",
      "Inserting batch 28/55 ...\n",
      "Inserting batch 29/55 ...\n",
      "Inserting batch 30/55 ...\n",
      "Inserting batch 31/55 ...\n",
      "Inserting batch 32/55 ...\n",
      "Inserting batch 33/55 ...\n",
      "Inserting batch 34/55 ...\n",
      "Inserting batch 35/55 ...\n",
      "Inserting batch 36/55 ...\n",
      "Inserting batch 37/55 ...\n",
      "Inserting batch 38/55 ...\n",
      "Inserting batch 39/55 ...\n",
      "Inserting batch 40/55 ...\n",
      "Inserting batch 41/55 ...\n",
      "Inserting batch 42/55 ...\n",
      "Inserting batch 43/55 ...\n",
      "Inserting batch 44/55 ...\n",
      "Inserting batch 45/55 ...\n",
      "Inserting batch 46/55 ...\n",
      "Inserting batch 47/55 ...\n",
      "Inserting batch 48/55 ...\n",
      "Inserting batch 49/55 ...\n",
      "Inserting batch 50/55 ...\n",
      "Inserting batch 51/55 ...\n",
      "Inserting batch 52/55 ...\n",
      "Inserting batch 53/55 ...\n",
      "Inserting batch 54/55 ...\n",
      "Inserting batch 55/55 ...\n",
      "{'row_count': 27409}\n",
      "Processing node type: cellular_component\n",
      "Inserting batch 1/9 ...\n",
      "Inserting batch 2/9 ...\n",
      "Inserting batch 3/9 ...\n",
      "Inserting batch 4/9 ...\n",
      "Inserting batch 5/9 ...\n",
      "Inserting batch 6/9 ...\n",
      "Inserting batch 7/9 ...\n",
      "Inserting batch 8/9 ...\n",
      "Inserting batch 9/9 ...\n",
      "{'row_count': 4011}\n",
      "Processing node type: disease\n",
      "Inserting batch 1/35 ...\n",
      "Inserting batch 2/35 ...\n",
      "Inserting batch 3/35 ...\n",
      "Inserting batch 4/35 ...\n",
      "Inserting batch 5/35 ...\n",
      "Inserting batch 6/35 ...\n",
      "Inserting batch 7/35 ...\n",
      "Inserting batch 8/35 ...\n",
      "Inserting batch 9/35 ...\n",
      "Inserting batch 10/35 ...\n",
      "Inserting batch 11/35 ...\n",
      "Inserting batch 12/35 ...\n",
      "Inserting batch 13/35 ...\n",
      "Inserting batch 14/35 ...\n",
      "Inserting batch 15/35 ...\n",
      "Inserting batch 16/35 ...\n",
      "Inserting batch 17/35 ...\n",
      "Inserting batch 18/35 ...\n",
      "Inserting batch 19/35 ...\n",
      "Inserting batch 20/35 ...\n",
      "Inserting batch 21/35 ...\n",
      "Inserting batch 22/35 ...\n",
      "Inserting batch 23/35 ...\n",
      "Inserting batch 24/35 ...\n",
      "Inserting batch 25/35 ...\n",
      "Inserting batch 26/35 ...\n",
      "Inserting batch 27/35 ...\n",
      "Inserting batch 28/35 ...\n",
      "Inserting batch 29/35 ...\n",
      "Inserting batch 30/35 ...\n",
      "Inserting batch 31/35 ...\n",
      "Inserting batch 32/35 ...\n",
      "Inserting batch 33/35 ...\n",
      "Inserting batch 34/35 ...\n",
      "Inserting batch 35/35 ...\n",
      "{'row_count': 17054}\n",
      "Processing node type: drug\n",
      "Inserting batch 1/14 ...\n",
      "Inserting batch 2/14 ...\n",
      "Inserting batch 3/14 ...\n",
      "Inserting batch 4/14 ...\n",
      "Inserting batch 5/14 ...\n",
      "Inserting batch 6/14 ...\n",
      "Inserting batch 7/14 ...\n",
      "Inserting batch 8/14 ...\n",
      "Inserting batch 9/14 ...\n",
      "Inserting batch 10/14 ...\n",
      "Inserting batch 11/14 ...\n",
      "Inserting batch 12/14 ...\n",
      "Inserting batch 13/14 ...\n",
      "Inserting batch 14/14 ...\n",
      "{'row_count': 6759}\n",
      "Processing node type: gene/protein\n",
      "Inserting batch 1/38 ...\n",
      "Inserting batch 2/38 ...\n",
      "Inserting batch 3/38 ...\n",
      "Inserting batch 4/38 ...\n",
      "Inserting batch 5/38 ...\n",
      "Inserting batch 6/38 ...\n",
      "Inserting batch 7/38 ...\n",
      "Inserting batch 8/38 ...\n",
      "Inserting batch 9/38 ...\n",
      "Inserting batch 10/38 ...\n",
      "Inserting batch 11/38 ...\n",
      "Inserting batch 12/38 ...\n",
      "Inserting batch 13/38 ...\n",
      "Inserting batch 14/38 ...\n",
      "Inserting batch 15/38 ...\n",
      "Inserting batch 16/38 ...\n",
      "Inserting batch 17/38 ...\n",
      "Inserting batch 18/38 ...\n",
      "Inserting batch 19/38 ...\n",
      "Inserting batch 20/38 ...\n",
      "Inserting batch 21/38 ...\n",
      "Inserting batch 22/38 ...\n",
      "Inserting batch 23/38 ...\n",
      "Inserting batch 24/38 ...\n",
      "Inserting batch 25/38 ...\n",
      "Inserting batch 26/38 ...\n",
      "Inserting batch 27/38 ...\n",
      "Inserting batch 28/38 ...\n",
      "Inserting batch 29/38 ...\n",
      "Inserting batch 30/38 ...\n",
      "Inserting batch 31/38 ...\n",
      "Inserting batch 32/38 ...\n",
      "Inserting batch 33/38 ...\n",
      "Inserting batch 34/38 ...\n",
      "Inserting batch 35/38 ...\n",
      "Inserting batch 36/38 ...\n",
      "Inserting batch 37/38 ...\n",
      "Inserting batch 38/38 ...\n",
      "{'row_count': 18797}\n",
      "Processing node type: molecular_function\n",
      "Inserting batch 1/22 ...\n",
      "Inserting batch 2/22 ...\n",
      "Inserting batch 3/22 ...\n",
      "Inserting batch 4/22 ...\n",
      "Inserting batch 5/22 ...\n",
      "Inserting batch 6/22 ...\n",
      "Inserting batch 7/22 ...\n",
      "Inserting batch 8/22 ...\n",
      "Inserting batch 9/22 ...\n",
      "Inserting batch 10/22 ...\n",
      "Inserting batch 11/22 ...\n",
      "Inserting batch 12/22 ...\n",
      "Inserting batch 13/22 ...\n",
      "Inserting batch 14/22 ...\n",
      "Inserting batch 15/22 ...\n",
      "Inserting batch 16/22 ...\n",
      "Inserting batch 17/22 ...\n",
      "Inserting batch 18/22 ...\n",
      "Inserting batch 19/22 ...\n",
      "Inserting batch 20/22 ...\n",
      "Inserting batch 21/22 ...\n",
      "Inserting batch 22/22 ...\n",
      "{'row_count': 10951}\n"
     ]
    }
   ],
   "source": [
    "# Merge nodes enrichment and embedding dataframes\n",
    "merged_nodes_df = nodes_enrichment_df.merge(\n",
    "    nodes_embedding_df[[\"node_id\", \"desc_emb\", \"feat_emb\"]],\n",
    "    on=\"node_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "# del nodes_enrichment_df, nodes_embedding_df  # Free memory\n",
    "\n",
    "# Loop over group enrichment nodes by type\n",
    "for node_type, nodes_df in tqdm(merged_nodes_df.groupby('node_type')):\n",
    "    print(f\"Processing node type: {node_type}\")\n",
    "\n",
    "    # Configuration for Milvus collection\n",
    "    node_coll_name = f\"{milvus_database}_nodes_{node_type.replace('/', '_')}\"\n",
    "\n",
    "    # Define schema for the collection\n",
    "    desc_emb_dim = len(nodes_df.iloc[0]['desc_emb'].to_arrow().to_pylist()[0])\n",
    "    feat_emb_dim = len(nodes_df.iloc[0]['feat_emb'].to_arrow().to_pylist()[0])\n",
    "    node_fields = [\n",
    "        FieldSchema(name=\"node_index\", dtype=DataType.INT64, is_primary=True),\n",
    "        FieldSchema(name=\"node_id\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "        FieldSchema(name=\"node_name\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "        FieldSchema(name=\"node_type\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "        # FieldSchema(name=\"desc\", dtype=DataType.VARCHAR, max_length=40960),\n",
    "        FieldSchema(name=\"feat\", dtype=DataType.VARCHAR, max_length=40960),\n",
    "        # FieldSchema(name=\"desc_emb\", dtype=DataType.FLOAT_VECTOR, dim=desc_emb_dim),\n",
    "        FieldSchema(name=\"feat_emb\", dtype=DataType.FLOAT_VECTOR, dim=feat_emb_dim),\n",
    "    ]\n",
    "    node_schema = CollectionSchema(fields=node_fields, description=f\"schema for collection {node_coll_name}\")\n",
    "\n",
    "    # Set index params\n",
    "    index_params = milvus_client.prepare_index_params()\n",
    "    # Indexing for node_index field\n",
    "    index_params.add_index(field_name=\"node_index\", index_type=\"AUTOINDEX\",\n",
    "                            index_name=\"node_index_index\")\n",
    "    # Indexing for desc_emb field\n",
    "    # index_params.add_index(field_name=\"desc_emb\", index_type=\"AUTOINDEX\",\n",
    "    #                        index_name=\"desc_emb_index\", metric_type=\"COSINE\")\n",
    "    # Indexing for feat_emb field\n",
    "    index_params.add_index(field_name=\"feat_emb\", index_type=\"AUTOINDEX\",\n",
    "                           index_name=\"feat_emb_index\", metric_type=\"COSINE\")\n",
    "\n",
    "    # Create the collection if it does not exist\n",
    "    if node_coll_name not in milvus_client.list_collections():\n",
    "        milvus_client.create_collection(collection_name=node_coll_name,\n",
    "                                        schema=node_schema,\n",
    "                                        index_params=index_params)\n",
    "\n",
    "    # Populate the collection with data\n",
    "    # Build list of records\n",
    "    data = [\n",
    "        {\n",
    "            \"node_index\": idx,\n",
    "            \"node_id\": nid,\n",
    "            \"node_name\": nname,\n",
    "            \"node_type\": ntype,\n",
    "            # \"desc\": desc,\n",
    "            \"feat\": feat,\n",
    "            # \"desc_emb\": desc_emb,\n",
    "            \"feat_emb\": feat_emb,\n",
    "        }\n",
    "        for idx, nid, nname, ntype, desc, feat, desc_emb, feat_emb in zip(\n",
    "            nodes_df[\"node_index\"].to_arrow().to_pylist(),\n",
    "            nodes_df[\"node_id\"].to_arrow().to_pylist(),\n",
    "            nodes_df[\"node_name\"].to_arrow().to_pylist(),\n",
    "            nodes_df[\"node_type\"].to_arrow().to_pylist(),\n",
    "            # nodes_df[\"desc\"].to_arrow().to_pylist(),\n",
    "            nodes_df[\"feat\"].to_arrow().to_pylist(),\n",
    "            # nodes_df[\"desc_emb\"].list.leaves.to_cupy().astype(cp.float32).reshape(nodes_df.shape[0], -1).tolist(),\n",
    "            nodes_df[\"feat_emb\"].list.leaves.to_cupy().astype(cp.float32).reshape(nodes_df.shape[0], -1).tolist()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Insert data in chunks to avoid memory issues\n",
    "    # Batch insert into Milvus\n",
    "    batch_size = 500\n",
    "    for i, batch in tqdm(enumerate(chunked(data, batch_size))):\n",
    "        # print(f\"Inserting batch {i + 1}/{(len(data) - 1) // batch_size + 1} ...\")\n",
    "        milvus_client.insert(collection_name=node_coll_name, data=batch)\n",
    "\n",
    "    # Flush the collection to ensure data is written\n",
    "    milvus_client.flush(collection_name=node_coll_name)\n",
    "\n",
    "    # Printout collection status\n",
    "    print(milvus_client.get_collection_stats(collection_name=node_coll_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3879d58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t2kg_primekg_node_biological_process',\n",
       " 't2kg_primekg_node_cellular_component',\n",
       " 't2kg_primekg_node_disease',\n",
       " 't2kg_primekg_node_drug',\n",
       " 't2kg_primekg_node_gene_protein',\n",
       " 't2kg_primekg_node_molecular_function']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milvus_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1e5eef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: t2kg_primekg_node_biological_process\n",
      "{'row_count': 27409}\n",
      "Collection: t2kg_primekg_node_cellular_component\n",
      "{'row_count': 4011}\n",
      "Collection: t2kg_primekg_node_disease\n",
      "{'row_count': 17054}\n",
      "Collection: t2kg_primekg_node_drug\n",
      "{'row_count': 6759}\n",
      "Collection: t2kg_primekg_node_gene_protein\n",
      "{'row_count': 18797}\n",
      "Collection: t2kg_primekg_node_molecular_function\n",
      "{'row_count': 10951}\n"
     ]
    }
   ],
   "source": [
    "for coll in milvus_client.list_collections():\n",
    "    print(f\"Collection: {coll}\")\n",
    "    print(milvus_client.get_collection_stats(collection_name=coll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127f18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.59 ms, sys: 3.65 ms, total: 12.2 ms\n",
      "Wall time: 26.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vector_to_search = merged_nodes_df[\"feat_emb\"].loc[2]\n",
    "\n",
    "# Vector similarity search in Milvus by defining a particular collection (node_type)\n",
    "results = milvus_client.search(\n",
    "    collection_name='t2kg_primekg_node_gene_protein',\n",
    "    data=[vector_to_search],\n",
    "    anns_field=\"feat_emb\",\n",
    "    output_fields=[\"node_id\", \"node_name\"],\n",
    "    search_params={\"metric_type\": \"COSINE\"},\n",
    "    limit=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ad0c340c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_index</th>\n",
       "      <th>primekg_node_index</th>\n",
       "      <th>node_id</th>\n",
       "      <th>node_name</th>\n",
       "      <th>node_type</th>\n",
       "      <th>desc</th>\n",
       "      <th>feat</th>\n",
       "      <th>desc_emb</th>\n",
       "      <th>feat_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4992</td>\n",
       "      <td>5021</td>\n",
       "      <td>RBM5_(5021)</td>\n",
       "      <td>RBM5</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>RBM5 belongs to gene/protein node. RBM5 is RNA...</td>\n",
       "      <td>MGSDKRVSRTERSGRYGSIIDRDDRDERESRSRRRDSDYKRSSDDR...</td>\n",
       "      <td>[-0.050645936, -0.012549261, -0.017889792, -0....</td>\n",
       "      <td>[-0.09598235785961151, -0.05643630400300026, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_index  primekg_node_index      node_id node_name     node_type  \\\n",
       "2        4992                5021  RBM5_(5021)      RBM5  gene/protein   \n",
       "\n",
       "                                                desc  \\\n",
       "2  RBM5 belongs to gene/protein node. RBM5 is RNA...   \n",
       "\n",
       "                                                feat  \\\n",
       "2  MGSDKRVSRTERSGRYGSIIDRDDRDERESRSRRRDSDYKRSSDDR...   \n",
       "\n",
       "                                            desc_emb  \\\n",
       "2  [-0.050645936, -0.012549261, -0.017889792, -0....   \n",
       "\n",
       "                                            feat_emb  \n",
       "2  [-0.09598235785961151, -0.05643630400300026, 0...  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the ground truth for the search\n",
    "merged_nodes_df.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "167fab4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data: [[{'node_index': 4992, 'distance': 1.0, 'entity': {'node_id': 'RBM5_(5021)', 'node_name': 'RBM5'}}, {'node_index': 9760, 'distance': 0.9463825225830078, 'entity': {'node_id': 'RBM22_(9845)', 'node_name': 'RBM22'}}, {'node_index': 9691, 'distance': 0.9457356929779053, 'entity': {'node_id': 'RBM25_(9776)', 'node_name': 'RBM25'}}, {'node_index': 943, 'distance': 0.9427413940429688, 'entity': {'node_id': 'RBM6_(943)', 'node_name': 'RBM6'}}, {'node_index': 5240, 'distance': 0.9424200057983398, 'entity': {'node_id': 'RBM28_(5270)', 'node_name': 'RBM28'}}, {'node_index': 2848, 'distance': 0.9393284916877747, 'entity': {'node_id': 'RBM10_(2860)', 'node_name': 'RBM10'}}, {'node_index': 8265, 'distance': 0.938931941986084, 'entity': {'node_id': 'RBM17_(8330)', 'node_name': 'RBM17'}}, {'node_index': 9632, 'distance': 0.9384500980377197, 'entity': {'node_id': 'RBM19_(9716)', 'node_name': 'RBM19'}}, {'node_index': 6722, 'distance': 0.9366649389266968, 'entity': {'node_id': 'RBM42_(6767)', 'node_name': 'RBM42'}}, {'node_index': 27886, 'distance': 0.9360105991363525, 'entity': {'node_id': 'RBM20_(34676)', 'node_name': 'RBM20'}}]]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "444bb0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4992, 9760, 9691, 943, 5240, 2848, 8265, 9632, 6722, 27886]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get node indices from the results\n",
    "[n['node_index'] for n in results[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "659ffddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.9463825225830078,\n",
       " 0.9457356929779053,\n",
       " 0.9427413940429688,\n",
       " 0.9424200057983398,\n",
       " 0.9393284916877747,\n",
       " 0.938931941986084,\n",
       " 0.9384500980377197,\n",
       " 0.9366649389266968,\n",
       " 0.9360105991363525]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the cosine similarity scores\n",
    "[n['distance'] for n in results[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730f362",
   "metadata": {},
   "source": [
    "#### Building Edge Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c267b2",
   "metadata": {},
   "source": [
    "Subsquently, we are also building the edges collection in Milvus.\n",
    "\n",
    "Note that the edges information of PrimeKG has massive records, so once again we are chunking the data to avoid memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f02647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge collection\n",
    "# Configuration for Milvus collection\n",
    "edge_coll_name = f\"{milvus_database}_edges\"\n",
    "\n",
    "# Define schema for the collection\n",
    "edge_fields = [\n",
    "    FieldSchema(name=\"triplet_index\", dtype=DataType.INT64, is_primary=True),\n",
    "    FieldSchema(name=\"head_id\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "    FieldSchema(name=\"head_index\", dtype=DataType.INT64),\n",
    "    FieldSchema(name=\"tail_id\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "    FieldSchema(name=\"tail_index\", dtype=DataType.INT64),\n",
    "    FieldSchema(name=\"edge_type\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "    FieldSchema(name=\"display_relation\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "    FieldSchema(name=\"feat\", dtype=DataType.VARCHAR, max_length=40960),\n",
    "    FieldSchema(name=\"feat_emb\", dtype=DataType.FLOAT_VECTOR, dim=1536),\n",
    "]\n",
    "edge_schema = CollectionSchema(fields=edge_fields, description=\"schema for edges collection\")\n",
    "\n",
    "# Set index params\n",
    "index_params = milvus_client.prepare_index_params()\n",
    "# Indexing for feat_emb field\n",
    "index_params.add_index(field_name=\"feat_emb\", index_type=\"AUTOINDEX\",\n",
    "                       index_name=\"feat_emb_index\", metric_type=\"COSINE\")\n",
    "\n",
    "# Create the collection if it does not exist\n",
    "if edge_coll_name not in milvus_client.list_collections():\n",
    "    milvus_client.create_collection(collection_name=edge_coll_name,\n",
    "                                    schema=edge_schema,\n",
    "                                    index_params=index_params)\n",
    "\n",
    "# Populate the collection with data\n",
    "# Build list of records\n",
    "# Since the embedding is too large, we will read it in chunks\n",
    "for edges_df in tqdm(edges_embedding_df):\n",
    "    # Merging edges enrichment and embedding dataframes\n",
    "    merged_edges_df = edges_enrichment_df.merge(\n",
    "        edges_df[[\"triplet_index\", \"feat_emb\"]],\n",
    "        on=\"triplet_index\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # Populate the collection with data\n",
    "    # Build list of records\n",
    "    data = [\n",
    "        {\n",
    "            \"triplet_index\": triplet_idx,\n",
    "            \"head_id\": head_id,\n",
    "            \"head_index\": head_idx,\n",
    "            \"tail_id\": tail_id,\n",
    "            \"tail_index\": tail_idx,\n",
    "            \"edge_type\": edge_type,\n",
    "            \"display_relation\": display_relation,\n",
    "            \"feat\": feat,\n",
    "            \"feat_emb\": feat_emb.tolist(),\n",
    "        }\n",
    "        for triplet_idx, head_id, head_idx, tail_id, tail_idx, edge_type, display_relation, feat, feat_emb in zip(\n",
    "            merged_edges_df[\"triplet_index\"].to_arrow().to_pylist(),\n",
    "            merged_edges_df[\"head_id\"].to_arrow().to_pylist(),\n",
    "            merged_edges_df[\"head_index\"].to_arrow().to_pylist(),\n",
    "            merged_edges_df[\"tail_id\"].to_arrow().to_pylist(),\n",
    "            merged_edges_df[\"tail_index\"].to_arrow().to_pylist(),\n",
    "            merged_edges_df[\"edge_type\"].to_arrow().to_pylist(),\n",
    "            merged_edges_df[\"display_relation\"].to_arrow().to_pylist(),\n",
    "            merged_edges_df[\"feat\"].to_arrow().to_pylist(),\n",
    "            merged_edges_df[\"feat_emb\"].list.leaves.to_cupy().astype(cp.float32).reshape(merged_edges_df.shape[0], -1).tolist()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Insert data in chunks to avoid memory issues\n",
    "    # Batch insert into Milvus\n",
    "    batch_size = 500\n",
    "    for i, batch in tqdm(enumerate(chunked(data, batch_size))):\n",
    "        # print(f\"Inserting batch {i + 1}/{(len(data) - 1) // batch_size + 1} ...\")\n",
    "        milvus_client.insert(collection_name=edge_coll_name, data=batch)\n",
    "\n",
    "    # Flush the collection to ensure data is written\n",
    "    milvus_client.flush(collection_name=edge_coll_name)\n",
    "\n",
    "    # Printout collection status\n",
    "    print(milvus_client.get_collection_stats(collection_name=edge_coll_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394748bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad17e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coll in milvus_client.list_collections():\n",
    "    print(f\"Collection: {coll}\")\n",
    "    print(milvus_client.get_collection_stats(collection_name=coll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6797cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vector_to_search = merged_edges_df[\"feat_emb\"].loc[0]\n",
    "\n",
    "# Vector similarity search in Milvus by defining a particular collection (edge)\n",
    "results = milvus_client.search(\n",
    "    collection_name='t2kg_primekg_edge',\n",
    "    data=[vector_to_search],\n",
    "    anns_field=\"feat_emb\",\n",
    "    output_fields=[\"head_id\", \"tail_id\", \"edge_type\", \"feat\"],\n",
    "    search_params={\"metric_type\": \"COSINE\"},\n",
    "    limit=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94911253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the ground truth for the search\n",
    "merged_edges_df.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6944a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bce0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get node indices from the results\n",
    "[n['triplet_index'] for n in results[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cosine similarity scores\n",
    "[n['distance'] for n in results[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
