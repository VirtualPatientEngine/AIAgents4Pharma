{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90dc3f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:aiagents4pharma.talk2scholars.tools.pdf.question_and_answer:Loaded Question and Answer tool configuration.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../')\n",
    "from aiagents4pharma.talk2knowledgegraphs.datasets.biobridge_datamodule import BioBridgeDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca305932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiagents4pharma.talk2knowledgegraphs.models.nbfnet import tasks, util\n",
    "import torch\n",
    "import pprint\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb569aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PrimeKG dataset...\n",
      "Loading nodes of PrimeKG dataset ...\n",
      "../../../../../data/primekg/primekg_nodes.tsv.gz already exists. Loading the data from the local directory.\n",
      "Loading edges of PrimeKG dataset ...\n",
      "../../../../../data/primekg/primekg_edges.tsv.gz already exists. Loading the data from the local directory.\n",
      "Loading data config file of BioBridgePrimeKG...\n",
      "File data_config.json already exists in ../../../../../data/biobridge_primekg.\n",
      "Building node embeddings...\n",
      "Building full triplets...\n",
      "Building train-test split...\n"
     ]
    }
   ],
   "source": [
    "# Prepare BioBridge dataset\n",
    "configs = {\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"val_ratio\": 0.1,\n",
    "    \"test_ratio\": 0.1,\n",
    "    \"num_workers\": 0,\n",
    "    \"batch_size\": 32,\n",
    "    \"random_state\": 0,\n",
    "}\n",
    "biobridge_dataset = BioBridgeDataModule(primekg_dir=\"../../../../../data/primekg\",\n",
    "                                        biobridge_dir=\"../../../../../data/biobridge_primekg\",\n",
    "                                        configs=configs)\n",
    "biobridge_dataset.prepare_data()\n",
    "biobridge_dataset.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34e8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = biobridge_dataset.data[\"set\"]\n",
    "train_data = biobridge_dataset.data[\"train\"]\n",
    "val_data = biobridge_dataset.data[\"val\"]\n",
    "test_data = biobridge_dataset.data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a32099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments to run the model\n",
    "args_config = \"../../../../aiagents4pharma/talk2knowledgegraphs/models/config/transductive/biobridge.yaml\"\n",
    "args_seed = 1024\n",
    "vars = {\"gpus\": \"null\"}\n",
    "\n",
    "cfg = util.load_config(args_config, context=vars)\n",
    "working_dir = util.create_working_directory(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ca213c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7bd05e30f370>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args_seed + util.get_rank())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bcbbe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Random seed: 1024\n",
      "WARNING:root:Config file: ../../../../aiagents4pharma/talk2knowledgegraphs/models/config/transductive/biobridge.yaml\n",
      "WARNING:root:{'dataset': {'class': 'BioBridgeDataModule',\n",
      "             'root': '~/datasets/knowledge_graphs/'},\n",
      " 'model': {'aggregate_func': 'pna',\n",
      "           'class': 'NBFNet',\n",
      "           'dependent': True,\n",
      "           'hidden_dims': [32, 32, 32, 32, 32, 32],\n",
      "           'input_dim': 32,\n",
      "           'layer_norm': True,\n",
      "           'message_func': 'distmult',\n",
      "           'remove_one_hop': True,\n",
      "           'short_cut': True},\n",
      " 'optimizer': {'class': 'Adam', 'lr': 0.005},\n",
      " 'output_dir': '~/experiments/',\n",
      " 'task': {'adversarial_temperature': 0.5,\n",
      "          'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10'],\n",
      "          'num_negative': 32,\n",
      "          'strict_negative': True},\n",
      " 'train': {'batch_size': 8, 'gpus': None, 'log_interval': 100, 'num_epoch': 1}}\n"
     ]
    }
   ],
   "source": [
    "logger = util.get_root_logger()\n",
    "if util.get_rank() == 0:\n",
    "    logger.warning(\"Random seed: %d\" % args_seed)\n",
    "    logger.warning(\"Config file: %s\" % args_config)\n",
    "    logger.warning(pprint.pformat(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07295397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_dir': '~/experiments/',\n",
       " 'dataset': {'class': 'BioBridgeDataModule',\n",
       "  'root': '~/datasets/knowledge_graphs/'},\n",
       " 'model': {'class': 'NBFNet',\n",
       "  'input_dim': 32,\n",
       "  'hidden_dims': [32, 32, 32, 32, 32, 32],\n",
       "  'message_func': 'distmult',\n",
       "  'aggregate_func': 'pna',\n",
       "  'short_cut': True,\n",
       "  'layer_norm': True,\n",
       "  'dependent': True,\n",
       "  'remove_one_hop': True,\n",
       "  'num_relation': 18},\n",
       " 'task': {'num_negative': 32,\n",
       "  'strict_negative': True,\n",
       "  'adversarial_temperature': 0.5,\n",
       "  'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10']},\n",
       " 'optimizer': {'class': 'Adam', 'lr': 0.005},\n",
       " 'train': {'gpus': None, 'batch_size': 8, 'num_epoch': 1, 'log_interval': 100}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update config with dataset information\n",
    "is_inductive = cfg.dataset[\"class\"].startswith(\"Ind\")\n",
    "# dataset = util.build_dataset(cfg) # We use the dataset from BioBridgeDataModule\n",
    "cfg.model.num_relation = dataset.num_relations\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c1b63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.DataFrame.from_dict({\"node_type\": biobridge_dataset.mapper[\"ntid2dim\"].keys(), \"node_dim\": biobridge_dataset.mapper[\"ntid2dim\"].values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be9553e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 768, 7: 768, 2: 768, 6: 512, 5: 768, 1: 2560}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in a.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce37bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add BioBridge parameters\n",
    "cfg.model.biobridge = {\n",
    "    \"nodes\": biobridge_dataset.nodes,\n",
    "    \"mapper_ntid2dim\": pd.DataFrame.from_dict({\"node_type\": biobridge_dataset.mapper[\"ntid2dim\"].keys(), \"node_dim\": biobridge_dataset.mapper[\"ntid2dim\"].values()})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "062d008d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NBFNet(\n",
       "  (project): ModuleDict(\n",
       "    (node_type_0): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (node_type_7): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (node_type_2): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (node_type_6): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (node_type_5): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (node_type_1): Sequential(\n",
       "      (0): Linear(in_features=2560, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x GeneralizedRelationalConv()\n",
       "  )\n",
       "  (query): Embedding(18, 32)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model = util.build_model(cfg)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e56e0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device for each data\n",
    "device = util.get_device(cfg)\n",
    "model = model.to(device)\n",
    "train_data, valid_data, test_data = dataset[0], dataset[1], dataset[2]\n",
    "train_data = train_data.to(device)\n",
    "valid_data = valid_data.to(device)\n",
    "test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edc9cf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Filtered data for ranking\n",
    "if is_inductive:\n",
    "    # for inductive setting, use only the test fact graph for filtered ranking\n",
    "    filtered_data = None\n",
    "else:\n",
    "    # for transductive setting, use the whole graph for filtered ranking\n",
    "    filtered_data = Data(edge_index=dataset.data.target_edge_index, edge_type=dataset.data.target_edge_type)\n",
    "    filtered_data = filtered_data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81096e4",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b70aab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import distributed as dist\n",
    "from torch.utils import data as torch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e202e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = \">\" * 30\n",
    "line = \"-\" * 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69458fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(cfg, model, test_data, filtered_data=None):\n",
    "    world_size = util.get_world_size()\n",
    "    rank = util.get_rank()\n",
    "\n",
    "    test_triplets = torch.cat([test_data.target_edge_index, test_data.target_edge_type.unsqueeze(0)]).t()\n",
    "    sampler = torch_data.DistributedSampler(test_triplets, world_size, rank)\n",
    "    test_loader = torch_data.DataLoader(test_triplets, cfg.train.batch_size, sampler=sampler)\n",
    "\n",
    "    model.eval()\n",
    "    rankings = []\n",
    "    num_negatives = []\n",
    "    for batch in test_loader:\n",
    "        t_batch, h_batch = tasks.all_negative(test_data, batch)\n",
    "        t_pred = model(test_data, t_batch)\n",
    "        h_pred = model(test_data, h_batch)\n",
    "\n",
    "        if filtered_data is None:\n",
    "            t_mask, h_mask = tasks.strict_negative_mask(test_data, batch)\n",
    "        else:\n",
    "            t_mask, h_mask = tasks.strict_negative_mask(filtered_data, batch)\n",
    "        pos_h_index, pos_t_index, pos_r_index = batch.t()\n",
    "        t_ranking = tasks.compute_ranking(t_pred, pos_t_index, t_mask)\n",
    "        h_ranking = tasks.compute_ranking(h_pred, pos_h_index, h_mask)\n",
    "        num_t_negative = t_mask.sum(dim=-1)\n",
    "        num_h_negative = h_mask.sum(dim=-1)\n",
    "\n",
    "        rankings += [t_ranking, h_ranking]\n",
    "        num_negatives += [num_t_negative, num_h_negative]\n",
    "\n",
    "    ranking = torch.cat(rankings)\n",
    "    num_negative = torch.cat(num_negatives)\n",
    "    all_size = torch.zeros(world_size, dtype=torch.long, device=device)\n",
    "    all_size[rank] = len(ranking)\n",
    "    if world_size > 1:\n",
    "        dist.all_reduce(all_size, op=dist.ReduceOp.SUM)\n",
    "    cum_size = all_size.cumsum(0)\n",
    "    all_ranking = torch.zeros(all_size.sum(), dtype=torch.long, device=device)\n",
    "    all_ranking[cum_size[rank] - all_size[rank]: cum_size[rank]] = ranking\n",
    "    all_num_negative = torch.zeros(all_size.sum(), dtype=torch.long, device=device)\n",
    "    all_num_negative[cum_size[rank] - all_size[rank]: cum_size[rank]] = num_negative\n",
    "    if world_size > 1:\n",
    "        dist.all_reduce(all_ranking, op=dist.ReduceOp.SUM)\n",
    "        dist.all_reduce(all_num_negative, op=dist.ReduceOp.SUM)\n",
    "\n",
    "    if rank == 0:\n",
    "        for metric in cfg.task.metric:\n",
    "            if metric == \"mr\":\n",
    "                score = all_ranking.float().mean()\n",
    "            elif metric == \"mrr\":\n",
    "                score = (1 / all_ranking.float()).mean()\n",
    "            elif metric.startswith(\"hits@\"):\n",
    "                values = metric[5:].split(\"_\")\n",
    "                threshold = int(values[0])\n",
    "                if len(values) > 1:\n",
    "                    num_sample = int(values[1])\n",
    "                    # unbiased estimation\n",
    "                    fp_rate = (all_ranking - 1).float() / all_num_negative\n",
    "                    score = 0\n",
    "                    for i in range(threshold):\n",
    "                        # choose i false positive from num_sample - 1 negatives\n",
    "                        num_comb = math.factorial(num_sample - 1) / \\\n",
    "                                   math.factorial(i) / math.factorial(num_sample - i - 1)\n",
    "                        score += num_comb * (fp_rate ** i) * ((1 - fp_rate) ** (num_sample - i - 1))\n",
    "                    score = score.mean()\n",
    "                else:\n",
    "                    score = (all_ranking <= threshold).float().mean()\n",
    "            logger.warning(\"%s: %g\" % (metric, score))\n",
    "    mrr = (1 / all_ranking.float()).mean()\n",
    "\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aacfce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(cfg, model, train_data, valid_data, filtered_data=None):\n",
    "    if cfg.train.num_epoch == 0:\n",
    "        return\n",
    "\n",
    "    world_size = util.get_world_size()\n",
    "    rank = util.get_rank()\n",
    "\n",
    "    train_triplets = torch.cat([train_data.target_edge_index, train_data.target_edge_type.unsqueeze(0)]).t()\n",
    "    sampler = torch_data.DistributedSampler(train_triplets, world_size, rank)\n",
    "    train_loader = torch_data.DataLoader(train_triplets, cfg.train.batch_size, sampler=sampler)\n",
    "\n",
    "    cls = cfg.optimizer.pop(\"class\")\n",
    "    optimizer = getattr(optim, cls)(model.parameters(), **cfg.optimizer)\n",
    "    if world_size > 1:\n",
    "        parallel_model = nn.parallel.DistributedDataParallel(model, device_ids=[device])\n",
    "    else:\n",
    "        parallel_model = model\n",
    "\n",
    "    step = math.ceil(cfg.train.num_epoch / 10)\n",
    "    best_result = float(\"-inf\")\n",
    "    best_epoch = -1\n",
    "\n",
    "    batch_id = 0\n",
    "    for i in range(0, cfg.train.num_epoch, step):\n",
    "        parallel_model.train()\n",
    "        for epoch in range(i, min(cfg.train.num_epoch, i + step)):\n",
    "            if util.get_rank() == 0:\n",
    "                logger.warning(separator)\n",
    "                logger.warning(\"Epoch %d begin\" % epoch)\n",
    "\n",
    "            losses = []\n",
    "            sampler.set_epoch(epoch)\n",
    "            for batch in train_loader:\n",
    "                batch = tasks.negative_sampling(train_data, batch, cfg.task.num_negative,\n",
    "                                                strict=cfg.task.strict_negative)\n",
    "                pred = parallel_model(train_data, batch)\n",
    "                target = torch.zeros_like(pred)\n",
    "                target[:, 0] = 1\n",
    "                loss = F.binary_cross_entropy_with_logits(pred, target, reduction=\"none\")\n",
    "                neg_weight = torch.ones_like(pred)\n",
    "                if cfg.task.adversarial_temperature > 0:\n",
    "                    with torch.no_grad():\n",
    "                        neg_weight[:, 1:] = F.softmax(pred[:, 1:] / cfg.task.adversarial_temperature, dim=-1)\n",
    "                else:\n",
    "                    neg_weight[:, 1:] = 1 / cfg.task.num_negative\n",
    "                loss = (loss * neg_weight).sum(dim=-1) / neg_weight.sum(dim=-1)\n",
    "                loss = loss.mean()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if util.get_rank() == 0 and batch_id % cfg.train.log_interval == 0:\n",
    "                    logger.warning(separator)\n",
    "                    logger.warning(\"binary cross entropy: %g\" % loss)\n",
    "                losses.append(loss.item())\n",
    "                batch_id += 1\n",
    "\n",
    "            if util.get_rank() == 0:\n",
    "                avg_loss = sum(losses) / len(losses)\n",
    "                logger.warning(separator)\n",
    "                logger.warning(\"Epoch %d end\" % epoch)\n",
    "                logger.warning(line)\n",
    "                logger.warning(\"average binary cross entropy: %g\" % avg_loss)\n",
    "\n",
    "        epoch = min(cfg.train.num_epoch, i + step)\n",
    "        if rank == 0:\n",
    "            logger.warning(\"Save checkpoint to model_epoch_%d.pth\" % epoch)\n",
    "            state = {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict()\n",
    "            }\n",
    "            torch.save(state, \"model_epoch_%d.pth\" % epoch)\n",
    "        util.synchronize()\n",
    "\n",
    "        if rank == 0:\n",
    "            logger.warning(separator)\n",
    "            logger.warning(\"Evaluate on valid\")\n",
    "        result = test(cfg, model, valid_data, filtered_data=filtered_data)\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_epoch = epoch\n",
    "\n",
    "    if rank == 0:\n",
    "        logger.warning(\"Load checkpoint from model_epoch_%d.pth\" % best_epoch)\n",
    "    state = torch.load(\"model_epoch_%d.pth\" % best_epoch, map_location=device)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    util.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab6e1680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"5.0;6.0;7.0;7.5;8.0;8.6;9.0+PTX\"\n",
    "os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda-12.8\"\n",
    "os.environ[\"PATH\"] = os.environ[\"CUDA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "# os.environ[\"LD_LIBRARY_PATH\"] = os.environ[\"CUDA_HOME\"] + \"/lib64:\" + os.environ[\"LD_LIBRARY_PATH\"]\n",
    "\n",
    "# export TORCH_CUDA_ARCH_LIST=\"5.0;6.0;7.0;7.5;8.0;8.6;9.0+PTX\"\n",
    "# export CUDA_HOME=/usr/local/cuda-12.8\n",
    "# export PATH=$CUDA_HOME/bin:$PATH\n",
    "# export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecf686ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "WARNING:root:Epoch 0 begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load rspmm extension. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "WARNING:root:binary cross entropy: 0.793771\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train and validate the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiltered_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 36\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(cfg, model, train_data, valid_data, filtered_data)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     34\u001b[0m     batch \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mnegative_sampling(train_data, batch, cfg\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mnum_negative,\n\u001b[1;32m     35\u001b[0m                                     strict\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mstrict_negative)\n\u001b[0;32m---> 36\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(pred)\n\u001b[1;32m     38\u001b[0m     target[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/docs/notebooks/talk2knowledgegraphs/nbfnet/../../../../aiagents4pharma/talk2knowledgegraphs/models/nbfnet/models.py:147\u001b[0m, in \u001b[0;36mNBFNet.forward\u001b[0;34m(self, data, batch)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (r_index[:, [\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m==\u001b[39m r_index)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# message passing and updated node representations\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbellmanford\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (num_nodes, batch_size, feature_dim）\u001b[39;00m\n\u001b[1;32m    148\u001b[0m feature \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_feature\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    149\u001b[0m index \u001b[38;5;241m=\u001b[39m t_index\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, feature\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/docs/notebooks/talk2knowledgegraphs/nbfnet/../../../../aiagents4pharma/talk2knowledgegraphs/models/nbfnet/models.py:94\u001b[0m, in \u001b[0;36mNBFNet.bellmanford\u001b[0;34m(self, data, h_index, r_index, separate_grad)\u001b[0m\n\u001b[1;32m     91\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(r_index)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# initialize queries (relation types of the given triples)\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m index \u001b[38;5;241m=\u001b[39m h_index\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand_as(query)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# initial (boundary) condition - initialize all node states as zeros\u001b[39;00m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# Train and validate the model\n",
    "train_and_validate(cfg, model, train_data, valid_data, filtered_data=filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b87af54",
   "metadata": {},
   "source": [
    "### Evaluation on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate\n",
    "if util.get_rank() == 0:\n",
    "    logger.warning(separator)\n",
    "    logger.warning(\"Evaluate on valid\")\n",
    "test(cfg, model, valid_data, filtered_data=filtered_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e82dd",
   "metadata": {},
   "source": [
    "### Evaluation on Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24723a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if util.get_rank() == 0:\n",
    "    logger.warning(separator)\n",
    "    logger.warning(\"Evaluate on test\")\n",
    "test(cfg, model, test_data, filtered_data=filtered_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
