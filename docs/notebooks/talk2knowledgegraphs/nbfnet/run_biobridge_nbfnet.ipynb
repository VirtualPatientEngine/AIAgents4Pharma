{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90dc3f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:aiagents4pharma.talk2scholars.tools.pdf.question_and_answer:Loaded Question and Answer tool configuration.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../')\n",
    "from aiagents4pharma.talk2knowledgegraphs.datasets.biobridge_datamodule import BioBridgeDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca305932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiagents4pharma.talk2knowledgegraphs.models.nbfnet import tasks, util\n",
    "import torch\n",
    "import pprint\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb569aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PrimeKG dataset...\n",
      "Loading nodes of PrimeKG dataset ...\n",
      "../../../../../data/primekg\\primekg_nodes.tsv.gz already exists. Loading the data from the local directory.\n",
      "Loading edges of PrimeKG dataset ...\n",
      "../../../../../data/primekg\\primekg_edges.tsv.gz already exists. Loading the data from the local directory.\n",
      "Loading data config file of BioBridgePrimeKG...\n",
      "File data_config.json already exists in ../../../../../data/biobridge_primekg.\n",
      "Building node embeddings...\n",
      "Building full triplets...\n",
      "Building train-test split...\n"
     ]
    }
   ],
   "source": [
    "# Prepare BioBridge dataset\n",
    "configs = {\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"val_ratio\": 0.1,\n",
    "    \"test_ratio\": 0.1,\n",
    "    \"num_workers\": 0,\n",
    "    \"batch_size\": 32,\n",
    "    \"random_state\": 0,\n",
    "}\n",
    "biobridge_dataset = BioBridgeDataModule(primekg_dir=\"../../../../../data/primekg\",\n",
    "                                        biobridge_dir=\"../../../../../data/biobridge_primekg\",\n",
    "                                        configs=configs)\n",
    "biobridge_dataset.prepare_data()\n",
    "biobridge_dataset.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34e8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = biobridge_dataset.data[\"set\"]\n",
    "train_data = biobridge_dataset.data[\"train\"]\n",
    "val_data = biobridge_dataset.data[\"val\"]\n",
    "test_data = biobridge_dataset.data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a32099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments to run the model\n",
    "args_config = \"../../../../aiagents4pharma/talk2knowledgegraphs/models/config/transductive/biobridge.yaml\"\n",
    "args_seed = 1024\n",
    "vars = {\"gpus\": \"null\"}\n",
    "\n",
    "cfg = util.load_config(args_config, context=vars)\n",
    "working_dir = util.create_working_directory(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ca213c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a1ce6bccd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args_seed + util.get_rank())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bcbbe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Random seed: 1024\n",
      "WARNING:root:Config file: ../../../../aiagents4pharma/talk2knowledgegraphs/models/config/transductive/biobridge.yaml\n",
      "WARNING:root:{'dataset': {'class': 'BioBridgeDataModule',\n",
      "             'root': '~/datasets/knowledge_graphs/'},\n",
      " 'model': {'aggregate_func': 'pna',\n",
      "           'class': 'NBFNet',\n",
      "           'dependent': True,\n",
      "           'hidden_dims': [32, 32, 32, 32, 32, 32],\n",
      "           'input_dim': 128,\n",
      "           'layer_norm': True,\n",
      "           'message_func': 'distmult',\n",
      "           'remove_one_hop': True,\n",
      "           'short_cut': True},\n",
      " 'optimizer': {'class': 'Adam', 'lr': 0.005},\n",
      " 'output_dir': '~/experiments/',\n",
      " 'task': {'adversarial_temperature': 0.5,\n",
      "          'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10'],\n",
      "          'num_negative': 32,\n",
      "          'strict_negative': True},\n",
      " 'train': {'batch_size': 32,\n",
      "           'gpus': None,\n",
      "           'log_interval': 100,\n",
      "           'num_epoch': 20}}\n"
     ]
    }
   ],
   "source": [
    "logger = util.get_root_logger()\n",
    "if util.get_rank() == 0:\n",
    "    logger.warning(\"Random seed: %d\" % args_seed)\n",
    "    logger.warning(\"Config file: %s\" % args_config)\n",
    "    logger.warning(pprint.pformat(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07295397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_dir': '~/experiments/',\n",
       " 'dataset': {'class': 'BioBridgeDataModule',\n",
       "  'root': '~/datasets/knowledge_graphs/'},\n",
       " 'model': {'class': 'NBFNet',\n",
       "  'input_dim': 128,\n",
       "  'hidden_dims': [32, 32, 32, 32, 32, 32],\n",
       "  'message_func': 'distmult',\n",
       "  'aggregate_func': 'pna',\n",
       "  'short_cut': True,\n",
       "  'layer_norm': True,\n",
       "  'dependent': True,\n",
       "  'remove_one_hop': True,\n",
       "  'num_relation': 18},\n",
       " 'task': {'num_negative': 32,\n",
       "  'strict_negative': True,\n",
       "  'adversarial_temperature': 0.5,\n",
       "  'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10']},\n",
       " 'optimizer': {'class': 'Adam', 'lr': 0.005},\n",
       " 'train': {'gpus': None,\n",
       "  'batch_size': 32,\n",
       "  'num_epoch': 20,\n",
       "  'log_interval': 100}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update config with dataset information\n",
    "is_inductive = cfg.dataset[\"class\"].startswith(\"Ind\")\n",
    "# dataset = util.build_dataset(cfg) # We use the dataset from BioBridgeDataModule\n",
    "cfg.model.num_relation = dataset.num_relations\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c1b63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.DataFrame.from_dict({\"node_type\": biobridge_dataset.mapper[\"ntid2dim\"].keys(), \"node_dim\": biobridge_dataset.mapper[\"ntid2dim\"].values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3be9553e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 768, 7: 768, 2: 768, 6: 512, 5: 768, 1: 2560}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in a.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cce37bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add BioBridge parameters\n",
    "cfg.model.biobridge = {\n",
    "    \"nodes\": biobridge_dataset.nodes,\n",
    "    \"mapper_ntid2dim\": pd.DataFrame.from_dict({\"node_type\": biobridge_dataset.mapper[\"ntid2dim\"].keys(), \"node_dim\": biobridge_dataset.mapper[\"ntid2dim\"].values()})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "062d008d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NBFNet(\n",
       "  (project): ModuleDict(\n",
       "    (node_type_0): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (node_type_7): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (node_type_2): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (node_type_6): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (node_type_5): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (node_type_1): Sequential(\n",
       "      (0): Linear(in_features=2560, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x GeneralizedRelationalConv()\n",
       "  )\n",
       "  (query): Embedding(18, 128)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=160, out_features=160, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "model = util.build_model(cfg)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e56e0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device for each data\n",
    "device = util.get_device(cfg)\n",
    "model = model.to(device)\n",
    "train_data, valid_data, test_data = dataset[0], dataset[1], dataset[2]\n",
    "train_data = train_data.to(device)\n",
    "valid_data = valid_data.to(device)\n",
    "test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edc9cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered data for ranking\n",
    "if is_inductive:\n",
    "    # for inductive setting, use only the test fact graph for filtered ranking\n",
    "    filtered_data = None\n",
    "else:\n",
    "    # for transductive setting, use the whole graph for filtered ranking\n",
    "    filtered_data = Data(edge_index=dataset.data.target_edge_index, edge_type=dataset.data.target_edge_type)\n",
    "    filtered_data = filtered_data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81096e4",
   "metadata": {},
   "source": [
    "### Train and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b70aab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import distributed as dist\n",
    "from torch.utils import data as torch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35e202e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = \">\" * 30\n",
    "line = \"-\" * 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69458fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(cfg, model, test_data, filtered_data=None):\n",
    "    world_size = util.get_world_size()\n",
    "    rank = util.get_rank()\n",
    "\n",
    "    test_triplets = torch.cat([test_data.target_edge_index, test_data.target_edge_type.unsqueeze(0)]).t()\n",
    "    sampler = torch_data.DistributedSampler(test_triplets, world_size, rank)\n",
    "    test_loader = torch_data.DataLoader(test_triplets, cfg.train.batch_size, sampler=sampler)\n",
    "\n",
    "    model.eval()\n",
    "    rankings = []\n",
    "    num_negatives = []\n",
    "    for batch in test_loader:\n",
    "        t_batch, h_batch = tasks.all_negative(test_data, batch)\n",
    "        t_pred = model(test_data, t_batch)\n",
    "        h_pred = model(test_data, h_batch)\n",
    "\n",
    "        if filtered_data is None:\n",
    "            t_mask, h_mask = tasks.strict_negative_mask(test_data, batch)\n",
    "        else:\n",
    "            t_mask, h_mask = tasks.strict_negative_mask(filtered_data, batch)\n",
    "        pos_h_index, pos_t_index, pos_r_index = batch.t()\n",
    "        t_ranking = tasks.compute_ranking(t_pred, pos_t_index, t_mask)\n",
    "        h_ranking = tasks.compute_ranking(h_pred, pos_h_index, h_mask)\n",
    "        num_t_negative = t_mask.sum(dim=-1)\n",
    "        num_h_negative = h_mask.sum(dim=-1)\n",
    "\n",
    "        rankings += [t_ranking, h_ranking]\n",
    "        num_negatives += [num_t_negative, num_h_negative]\n",
    "\n",
    "    ranking = torch.cat(rankings)\n",
    "    num_negative = torch.cat(num_negatives)\n",
    "    all_size = torch.zeros(world_size, dtype=torch.long, device=device)\n",
    "    all_size[rank] = len(ranking)\n",
    "    if world_size > 1:\n",
    "        dist.all_reduce(all_size, op=dist.ReduceOp.SUM)\n",
    "    cum_size = all_size.cumsum(0)\n",
    "    all_ranking = torch.zeros(all_size.sum(), dtype=torch.long, device=device)\n",
    "    all_ranking[cum_size[rank] - all_size[rank]: cum_size[rank]] = ranking\n",
    "    all_num_negative = torch.zeros(all_size.sum(), dtype=torch.long, device=device)\n",
    "    all_num_negative[cum_size[rank] - all_size[rank]: cum_size[rank]] = num_negative\n",
    "    if world_size > 1:\n",
    "        dist.all_reduce(all_ranking, op=dist.ReduceOp.SUM)\n",
    "        dist.all_reduce(all_num_negative, op=dist.ReduceOp.SUM)\n",
    "\n",
    "    if rank == 0:\n",
    "        for metric in cfg.task.metric:\n",
    "            if metric == \"mr\":\n",
    "                score = all_ranking.float().mean()\n",
    "            elif metric == \"mrr\":\n",
    "                score = (1 / all_ranking.float()).mean()\n",
    "            elif metric.startswith(\"hits@\"):\n",
    "                values = metric[5:].split(\"_\")\n",
    "                threshold = int(values[0])\n",
    "                if len(values) > 1:\n",
    "                    num_sample = int(values[1])\n",
    "                    # unbiased estimation\n",
    "                    fp_rate = (all_ranking - 1).float() / all_num_negative\n",
    "                    score = 0\n",
    "                    for i in range(threshold):\n",
    "                        # choose i false positive from num_sample - 1 negatives\n",
    "                        num_comb = math.factorial(num_sample - 1) / \\\n",
    "                                   math.factorial(i) / math.factorial(num_sample - i - 1)\n",
    "                        score += num_comb * (fp_rate ** i) * ((1 - fp_rate) ** (num_sample - i - 1))\n",
    "                    score = score.mean()\n",
    "                else:\n",
    "                    score = (all_ranking <= threshold).float().mean()\n",
    "            logger.warning(\"%s: %g\" % (metric, score))\n",
    "    mrr = (1 / all_ranking.float()).mean()\n",
    "\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aacfce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(cfg, model, train_data, valid_data, filtered_data=None):\n",
    "    if cfg.train.num_epoch == 0:\n",
    "        return\n",
    "\n",
    "    world_size = util.get_world_size()\n",
    "    rank = util.get_rank()\n",
    "\n",
    "    train_triplets = torch.cat([train_data.target_edge_index, train_data.target_edge_type.unsqueeze(0)]).t()\n",
    "    sampler = torch_data.DistributedSampler(train_triplets, world_size, rank)\n",
    "    train_loader = torch_data.DataLoader(train_triplets, cfg.train.batch_size, sampler=sampler)\n",
    "\n",
    "    cls = cfg.optimizer.pop(\"class\")\n",
    "    optimizer = getattr(optim, cls)(model.parameters(), **cfg.optimizer)\n",
    "    if world_size > 1:\n",
    "        parallel_model = nn.parallel.DistributedDataParallel(model, device_ids=[device])\n",
    "    else:\n",
    "        parallel_model = model\n",
    "\n",
    "    step = math.ceil(cfg.train.num_epoch / 10)\n",
    "    best_result = float(\"-inf\")\n",
    "    best_epoch = -1\n",
    "\n",
    "    batch_id = 0\n",
    "    for i in range(0, cfg.train.num_epoch, step):\n",
    "        parallel_model.train()\n",
    "        for epoch in range(i, min(cfg.train.num_epoch, i + step)):\n",
    "            if util.get_rank() == 0:\n",
    "                logger.warning(separator)\n",
    "                logger.warning(\"Epoch %d begin\" % epoch)\n",
    "\n",
    "            losses = []\n",
    "            sampler.set_epoch(epoch)\n",
    "            for batch in train_loader:\n",
    "                batch = tasks.negative_sampling(train_data, batch, cfg.task.num_negative,\n",
    "                                                strict=cfg.task.strict_negative)\n",
    "                pred = parallel_model(train_data, batch)\n",
    "                target = torch.zeros_like(pred)\n",
    "                target[:, 0] = 1\n",
    "                loss = F.binary_cross_entropy_with_logits(pred, target, reduction=\"none\")\n",
    "                neg_weight = torch.ones_like(pred)\n",
    "                if cfg.task.adversarial_temperature > 0:\n",
    "                    with torch.no_grad():\n",
    "                        neg_weight[:, 1:] = F.softmax(pred[:, 1:] / cfg.task.adversarial_temperature, dim=-1)\n",
    "                else:\n",
    "                    neg_weight[:, 1:] = 1 / cfg.task.num_negative\n",
    "                loss = (loss * neg_weight).sum(dim=-1) / neg_weight.sum(dim=-1)\n",
    "                loss = loss.mean()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if util.get_rank() == 0 and batch_id % cfg.train.log_interval == 0:\n",
    "                    logger.warning(separator)\n",
    "                    logger.warning(\"binary cross entropy: %g\" % loss)\n",
    "                losses.append(loss.item())\n",
    "                batch_id += 1\n",
    "\n",
    "            if util.get_rank() == 0:\n",
    "                avg_loss = sum(losses) / len(losses)\n",
    "                logger.warning(separator)\n",
    "                logger.warning(\"Epoch %d end\" % epoch)\n",
    "                logger.warning(line)\n",
    "                logger.warning(\"average binary cross entropy: %g\" % avg_loss)\n",
    "\n",
    "        epoch = min(cfg.train.num_epoch, i + step)\n",
    "        if rank == 0:\n",
    "            logger.warning(\"Save checkpoint to model_epoch_%d.pth\" % epoch)\n",
    "            state = {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict()\n",
    "            }\n",
    "            torch.save(state, \"model_epoch_%d.pth\" % epoch)\n",
    "        util.synchronize()\n",
    "\n",
    "        if rank == 0:\n",
    "            logger.warning(separator)\n",
    "            logger.warning(\"Evaluate on valid\")\n",
    "        result = test(cfg, model, valid_data, filtered_data=filtered_data)\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_epoch = epoch\n",
    "\n",
    "    if rank == 0:\n",
    "        logger.warning(\"Load checkpoint from model_epoch_%d.pth\" % best_epoch)\n",
    "    state = torch.load(\"model_epoch_%d.pth\" % best_epoch, map_location=device)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    util.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecf686ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "WARNING:root:Epoch 0 begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load rspmm extension. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\venv\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:382: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "  warnings.warn(f'Error checking compiler version for {compiler}: {error}')\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['where', 'cl']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiltered_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 36\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[1;34m(cfg, model, train_data, valid_data, filtered_data)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     34\u001b[0m     batch \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mnegative_sampling(train_data, batch, cfg\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mnum_negative,\n\u001b[0;32m     35\u001b[0m                                     strict\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mstrict_negative)\n\u001b[1;32m---> 36\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(pred)\n\u001b[0;32m     38\u001b[0m     target[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\docs\\notebooks\\talk2knowledgegraphs\\nbfnet\\../../../..\\aiagents4pharma\\talk2knowledgegraphs\\models\\nbfnet\\models.py:147\u001b[0m, in \u001b[0;36mNBFNet.forward\u001b[1;34m(self, data, batch)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (r_index[:, [\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m==\u001b[39m r_index)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# message passing and updated node representations\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbellmanford\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (num_nodes, batch_size, feature_dimï¼‰\u001b[39;00m\n\u001b[0;32m    148\u001b[0m feature \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_feature\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    149\u001b[0m index \u001b[38;5;241m=\u001b[39m t_index\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, feature\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\docs\\notebooks\\talk2knowledgegraphs\\nbfnet\\../../../..\\aiagents4pharma\\talk2knowledgegraphs\\models\\nbfnet\\models.py:112\u001b[0m, in \u001b[0;36mNBFNet.bellmanford\u001b[1;34m(self, data, h_index, r_index, separate_grad)\u001b[0m\n\u001b[0;32m    110\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m edge_weight\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Bellman-Ford iteration, we send the original boundary condition in addition to the updated node states\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m hidden \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshort_cut \u001b[38;5;129;01mand\u001b[39;00m hidden\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m layer_input\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# residual connection here\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m hidden \u001b[38;5;241m+\u001b[39m layer_input\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\docs\\notebooks\\talk2knowledgegraphs\\nbfnet\\../../../..\\aiagents4pharma\\talk2knowledgegraphs\\models\\nbfnet\\layers.py:66\u001b[0m, in \u001b[0;36mGeneralizedRelationalConv.forward\u001b[1;34m(self, input, query, boundary, edge_index, edge_type, size, edge_weight)\u001b[0m\n\u001b[0;32m     62\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(edge_type), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# note that we send the initial boundary condition (node states at layer0) to the message passing\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# correspond to Eq.6 on p5 in https://arxiv.org/pdf/2106.06935.pdf\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mboundary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m                        \u001b[49m\u001b[43medge_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\docs\\notebooks\\talk2knowledgegraphs\\nbfnet\\../../../..\\aiagents4pharma\\talk2knowledgegraphs\\models\\nbfnet\\layers.py:96\u001b[0m, in \u001b[0;36mGeneralizedRelationalConv.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m         edge_index, msg_aggr_kwargs \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m---> 96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_and_aggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_aggr_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_and_aggregate_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m     98\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (edge_index, msg_aggr_kwargs), out)\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\docs\\notebooks\\talk2knowledgegraphs\\nbfnet\\../../../..\\aiagents4pharma\\talk2knowledgegraphs\\models\\nbfnet\\layers.py:165\u001b[0m, in \u001b[0;36mGeneralizedRelationalConv.message_and_aggregate\u001b[1;34m(self, edge_index, input, relation, boundary, edge_type, edge_weight, index, dim_size)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmessage_and_aggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, edge_index, \u001b[38;5;28minput\u001b[39m, relation, boundary, edge_type, edge_weight, index, dim_size):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# fused computation of message and aggregate steps with the custom rspmm cuda kernel\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# speed up computation by several times\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# reduce memory complexity from O(|E|d) to O(|V|d), so we can apply it to larger graphs\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrspmm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generalized_rspmm\n\u001b[0;32m    167\u001b[0m     batch_size, num_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\docs\\notebooks\\talk2knowledgegraphs\\nbfnet\\../../../..\\aiagents4pharma\\talk2knowledgegraphs\\models\\nbfnet\\rspmm\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrspmm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generalized_rspmm\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\docs\\notebooks\\talk2knowledgegraphs\\nbfnet\\../../../..\\aiagents4pharma\\talk2knowledgegraphs\\models\\nbfnet\\rspmm\\rspmm.py:207\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad rspmm extension. This may take a while...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    206\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 207\u001b[0m rspmm \u001b[38;5;241m=\u001b[39m \u001b[43mload_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrspmm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrspmm.cpp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrspmm.cu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\docs\\notebooks\\talk2knowledgegraphs\\nbfnet\\../../../..\\aiagents4pharma\\talk2knowledgegraphs\\models\\nbfnet\\rspmm\\rspmm.py:202\u001b[0m, in \u001b[0;36mload_extension\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 new_sources\u001b[38;5;241m.\u001b[39mappend(source)\n\u001b[0;32m    200\u001b[0m         sources \u001b[38;5;241m=\u001b[39m new_sources\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcpp_extension\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\venv\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:1314\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(name,\n\u001b[0;32m   1223\u001b[0m          sources: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   1224\u001b[0m          extra_cflags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1232\u001b[0m          is_standalone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1233\u001b[0m          keep_intermediates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;124;03m    Load a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[0;32m   1236\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m        ...     verbose=True)\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\venv\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:1721\u001b[0m, in \u001b[0;36m_jit_compile\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[0;32m   1717\u001b[0m                 hipified_sources\u001b[38;5;241m.\u001b[39madd(hipify_result[s_abs]\u001b[38;5;241m.\u001b[39mhipified_path \u001b[38;5;28;01mif\u001b[39;00m s_abs \u001b[38;5;129;01min\u001b[39;00m hipify_result \u001b[38;5;28;01melse\u001b[39;00m s_abs)\n\u001b[0;32m   1719\u001b[0m             sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(hipified_sources)\n\u001b[1;32m-> 1721\u001b[0m         \u001b[43m_write_ninja_file_and_build_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1723\u001b[0m \u001b[43m            \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1724\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_standalone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m verbose:\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo modifications detected for re-loaded extension \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1734\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, skipping build step...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\venv\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:1820\u001b[0m, in \u001b[0;36m_write_ninja_file_and_build_library\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[0;32m   1817\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmitting ninja build file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbuild_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m   1818\u001b[0m \u001b[38;5;66;03m# NOTE: Emitting a new ninja build file does not cause re-compilation if\u001b[39;00m\n\u001b[0;32m   1819\u001b[0m \u001b[38;5;66;03m# the sources did not change, so it's ok to re-emit (and it's fast).\u001b[39;00m\n\u001b[1;32m-> 1820\u001b[0m \u001b[43m_write_ninja_file_to_build_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1823\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_standalone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m   1832\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuilding extension module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\venv\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:2246\u001b[0m, in \u001b[0;36m_write_ninja_file_to_build_library\u001b[1;34m(path, name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, with_cuda, is_standalone)\u001b[0m\n\u001b[0;32m   2243\u001b[0m ext \u001b[38;5;241m=\u001b[39m EXEC_EXT \u001b[38;5;28;01mif\u001b[39;00m is_standalone \u001b[38;5;28;01melse\u001b[39;00m LIB_EXT\n\u001b[0;32m   2244\u001b[0m library_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 2246\u001b[0m \u001b[43m_write_ninja_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcuda_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcuda_post_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcuda_dlink_post_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2253\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mulyadi\\TempRepo\\AIAgents4Pharma\\venv\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:2382\u001b[0m, in \u001b[0;36m_write_ninja_file\u001b[1;34m(path, cflags, post_cflags, cuda_cflags, cuda_post_cflags, cuda_dlink_post_cflags, sources, objects, ldflags, library_target, with_cuda)\u001b[0m\n\u001b[0;32m   2380\u001b[0m link_rule \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrule link\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m   2381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IS_WINDOWS:\n\u001b[1;32m-> 2382\u001b[0m     cl_paths \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhere\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2383\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;241m*\u001b[39mSUBPROCESS_DECODE_ARGS)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cl_paths) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2385\u001b[0m         cl_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(cl_paths[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:466\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    463\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    464\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[1;32m--> 466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[1;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['where', 'cl']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "train_and_validate(cfg, model, train_data, valid_data, filtered_data=filtered_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
