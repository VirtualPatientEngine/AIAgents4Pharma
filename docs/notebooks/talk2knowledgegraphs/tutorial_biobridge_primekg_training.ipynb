{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrimeKG Subgraph Construction (Multi-Modal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First of all, we need to import necessary libraries as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"xxx\"\n",
    "os.environ[\"NVCF_RUN_KEY\"] = \"xxx\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch \n",
    "from torch_geometric.utils import from_networkx\n",
    "import sys\n",
    "sys.path.append('../../..')\n",
    "from aiagents4pharma.talk2knowledgegraphs.datasets.starkqa_primekg import StarkQAPrimeKG\n",
    "from aiagents4pharma.talk2knowledgegraphs.datasets.biobridge_primekg import BioBridgePrimeKG\n",
    "from aiagents4pharma.talk2knowledgegraphs.utils.embeddings.ollama import EmbeddingWithOllama\n",
    "from aiagents4pharma.talk2knowledgegraphs.utils import kg_utils\n",
    "\n",
    "# # Set the logging level for httpx to WARNING to suppress INFO messages\n",
    "import logging\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PrimeKG dataset...\n",
      "Loading nodes of PrimeKG dataset ...\n",
      "../../../../data/primekg/primekg_nodes.tsv.gz already exists. Loading the data from the local directory.\n",
      "Loading edges of PrimeKG dataset ...\n",
      "../../../../data/primekg/primekg_edges.tsv.gz already exists. Loading the data from the local directory.\n",
      "Loading data config file of BioBridgePrimeKG...\n",
      "File data_config.json already exists in ../../../../data/biobridge_primekg/.\n",
      "Building node embeddings...\n",
      "Building full triplets...\n",
      "Building train-test split...\n",
      "Building negative triplets...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['gene/protein', 'molecular_function', 'cellular_component', 'biological_process', 'drug', 'disease'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define biobridge primekg data by providing a local directory where the data is stored\n",
    "biobridge_data = BioBridgePrimeKG(primekg_dir=\"../../../../data/primekg/\",\n",
    "                                  local_dir=\"../../../../data/biobridge_primekg/\")\n",
    "\n",
    "# Invoke a method to load the data\n",
    "biobridge_data.load_data()\n",
    "\n",
    "# Get the node information of the BioBridge PrimeKG\n",
    "biobridge_node_info = biobridge_data.get_node_info_dict()\n",
    "biobridge_node_info.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "hidden_dim=768 # the hidden dimension of the transformation model\n",
    "n_layer=6 # the number of transformer layers\n",
    "batch_size=1024 # the training batch size\n",
    "learning_rate=1.6e-3 # the learning ratesss\n",
    "n_epoch=10 # the number of training epochs\n",
    "weight_decay=1e-4 # the weight decay\n",
    "eval_steps=10 # the number of steps to evaluate the |model\n",
    "save_dir=\"./checkpoints/model-1\" # the directory to save the model\n",
    "dataloader_num_workers=4 # the number of workers for data loading\n",
    "use_wandb=False, # whether to use wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./checkpoints/model-1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Use the train set for contrastive learning with InfoNCE loss.\n",
    "    \"\"\"\n",
    "    def __init__(self, triplet, node):\n",
    "        self.triplet = triplet\n",
    "        self.node = node\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.triplet.iloc[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Use the test set to evaluate the retrieval performance of the model. The evaluation is performed in this way:\n",
    "    1. get the raw embeddings of all nodes in `self.node_all`.\n",
    "    2. for each relation type, transform head node embedding to tail node embedding using the transformation model.\n",
    "    3. match the transformed embedding with the raw embedding of the target node.\n",
    "\n",
    "    Args:\n",
    "        node_test (pd.DataFrame): the test node dataframe\n",
    "        triplet (pd.DataFrame): the **all** triplet dataframe\n",
    "        node_all (pd.DataFrame): the **all** node dataframe. Need to encode them all when evaluating.\n",
    "        target_node_type_index (int): the target node type to consider for evaluation and prediction.\n",
    "            Defaults to None and use all node types.\n",
    "        target_relation (int): the `display relation` type to consider for evaluation. \n",
    "        frequent_threshold (int, optional): the tail node that appears less than this threshold will be removed in the evaluation.\n",
    "            Defaults to None and use all nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 node_test,\n",
    "                 triplet_all,\n",
    "                 node_all,\n",
    "                 target_node_type_index=None,\n",
    "                 target_relation=None,\n",
    "                 frequent_threshold=None,\n",
    "                 ):\n",
    "        self.target_relation = target_relation\n",
    "        self.frequent_threshold = frequent_threshold\n",
    "        self.target_node_type_index = target_node_type_index\n",
    "        if target_relation is not None:\n",
    "\n",
    "            # filter the triplet and node dataframe by the relation\n",
    "            # only maintain triplets with the relation in the relation list\n",
    "            # only maintain the nodes that appear in the triplets\n",
    "            # only maintain the test nodes that appear in the triplets\n",
    "            triplet_all = triplet_all[triplet_all['display_relation'].isin([target_relation])].reset_index(drop=True).copy()\n",
    "            all_node_index  = pd.concat([triplet_all[\"head_index\"], triplet_all[\"tail_index\"]]).unique()\n",
    "            node_all = node_all[node_all[\"node_index\"].isin(all_node_index)].reset_index(drop=True).copy()\n",
    "            node_test = node_test[node_test[\"node_index\"].isin(all_node_index)].reset_index(drop=True).copy()\n",
    "\n",
    "        if target_node_type_index is not None:\n",
    "            # filter the triplet that has head_type equal to the target node type\n",
    "            triplet_all = triplet_all[triplet_all[\"head_type\"] == target_node_type_index].reset_index(drop=True).copy()\n",
    "            # only choose the test nodes that are the target node type\n",
    "            node_test = node_test[node_test[\"node_type\"] == target_node_type_index].reset_index(drop=True).copy()\n",
    "            # only choose node_all that are the head node in node_test and the tail node in triplet_all\n",
    "            all_node_index = pd.concat([node_test[\"node_index\"], triplet_all[\"tail_index\"]]).unique()\n",
    "            node_all = node_all[node_all[\"node_index\"].isin(all_node_index)].reset_index(drop=True).copy()\n",
    "\n",
    "        # filter out the target node in the triplet that is not frequent enough\n",
    "        if self.frequent_threshold is not None:\n",
    "            val_counts = triplet_all[\"tail_index\"].value_counts()\n",
    "            frequent_node_index = val_counts[val_counts >= self.frequent_threshold].index\n",
    "            triplet_all = triplet_all[triplet_all[\"tail_index\"].isin(frequent_node_index)].reset_index(drop=True).copy()\n",
    "            all_node_index = pd.concat([node_test[\"node_index\"], triplet_all[\"tail_index\"]]).unique()\n",
    "            node_all = node_all[node_all[\"node_index\"].isin(all_node_index)].reset_index(drop=True).copy()\n",
    "\n",
    "        # filter out the test node that does have a tail node in the triplet\n",
    "        node_test_new = node_test[node_test[\"node_index\"].isin(triplet_all[\"head_index\"])].reset_index(drop=True).copy()\n",
    "        if len(node_test_new) != len(node_test):\n",
    "            print(f\"Warning: {len(node_test) - len(node_test_new)} test nodes are removed because they do not have a tail node in the triplet.\")\n",
    "            # find the difference between the two dataframes\n",
    "            diff_index = node_test[\"node_index\"][~node_test[\"node_index\"].isin(node_test_new[\"node_index\"])]\n",
    "            # filter out node all\n",
    "            node_all = node_all[~node_all[\"node_index\"].isin(diff_index)].reset_index(drop=True).copy()\n",
    "            node_test = node_test_new\n",
    "\n",
    "        # save the filtered dataframes\n",
    "        self.triplet = triplet_all\n",
    "        self.node = node_test\n",
    "        self.node_all = node_all   \n",
    "        self.tail_node_types = self.triplet[\"tail_type\"].unique()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get the positive tail_index and all candidate tail_index from the same type\n",
    "        row = self.node.iloc[index]\n",
    "        triplet = self.triplet[self.triplet[\"head_index\"] == row[\"node_index\"]]\n",
    "        outputs = {\n",
    "            \"head_index\": row[\"node_index\"],\n",
    "            \"head_type\": row[\"node_type\"],\n",
    "            \"tail_index\": triplet[\"tail_index\"].tolist(),\n",
    "            \"tail_type\": triplet[\"tail_type\"].tolist(),\n",
    "            \"display_relation\": triplet[\"display_relation\"].tolist(),\n",
    "            \"relation\": triplet[\"relation\"].tolist(),\n",
    "        }\n",
    "        return outputs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.node)\n",
    "    \n",
    "    def get_all_node(self):\n",
    "        return self.node_all\n",
    "    \n",
    "    def get_all_triplet(self):\n",
    "        return self.triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_index</th>\n",
       "      <th>head_name</th>\n",
       "      <th>head_source</th>\n",
       "      <th>head_id</th>\n",
       "      <th>head_type</th>\n",
       "      <th>tail_index</th>\n",
       "      <th>tail_name</th>\n",
       "      <th>tail_source</th>\n",
       "      <th>tail_id</th>\n",
       "      <th>tail_type</th>\n",
       "      <th>display_relation</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>MT1A</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>4489</td>\n",
       "      <td>1</td>\n",
       "      <td>1785</td>\n",
       "      <td>TP53</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>7157</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>CD7</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>924</td>\n",
       "      <td>1</td>\n",
       "      <td>7681</td>\n",
       "      <td>SFXN5</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>94097</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>SNRPD2</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>6633</td>\n",
       "      <td>1</td>\n",
       "      <td>3235</td>\n",
       "      <td>PRPF4</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>9128</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>VAV3</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>10451</td>\n",
       "      <td>1</td>\n",
       "      <td>3005</td>\n",
       "      <td>ZRANB1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>54764</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>SNRPD2</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>6633</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>NCSTN</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>23385</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393675</th>\n",
       "      <td>125342</td>\n",
       "      <td>myosin V complex</td>\n",
       "      <td>GO</td>\n",
       "      <td>31475</td>\n",
       "      <td>7</td>\n",
       "      <td>9639</td>\n",
       "      <td>DYNLL2</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>140735</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cellcomp_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393676</th>\n",
       "      <td>55608</td>\n",
       "      <td>extracellular membrane-bounded organelle</td>\n",
       "      <td>GO</td>\n",
       "      <td>65010</td>\n",
       "      <td>7</td>\n",
       "      <td>57129</td>\n",
       "      <td>PHOSPHO1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>162466</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cellcomp_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393677</th>\n",
       "      <td>124243</td>\n",
       "      <td>axonemal outer doublet</td>\n",
       "      <td>GO</td>\n",
       "      <td>97545</td>\n",
       "      <td>7</td>\n",
       "      <td>59351</td>\n",
       "      <td>CFAP100</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>348807</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cellcomp_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393678</th>\n",
       "      <td>124243</td>\n",
       "      <td>axonemal outer doublet</td>\n",
       "      <td>GO</td>\n",
       "      <td>97545</td>\n",
       "      <td>7</td>\n",
       "      <td>59352</td>\n",
       "      <td>CFAP73</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>387885</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cellcomp_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393679</th>\n",
       "      <td>126258</td>\n",
       "      <td>uropod membrane</td>\n",
       "      <td>GO</td>\n",
       "      <td>31259</td>\n",
       "      <td>7</td>\n",
       "      <td>57434</td>\n",
       "      <td>SCIMP</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>388325</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cellcomp_protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393680 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        head_index                                 head_name head_source  \\\n",
       "0                8                                      MT1A        NCBI   \n",
       "1               12                                       CD7        NCBI   \n",
       "2               16                                    SNRPD2        NCBI   \n",
       "3               19                                      VAV3        NCBI   \n",
       "4               16                                    SNRPD2        NCBI   \n",
       "...            ...                                       ...         ...   \n",
       "393675      125342                          myosin V complex          GO   \n",
       "393676       55608  extracellular membrane-bounded organelle          GO   \n",
       "393677      124243                    axonemal outer doublet          GO   \n",
       "393678      124243                    axonemal outer doublet          GO   \n",
       "393679      126258                           uropod membrane          GO   \n",
       "\n",
       "       head_id  head_type  tail_index tail_name tail_source tail_id  \\\n",
       "0         4489          1        1785      TP53        NCBI    7157   \n",
       "1          924          1        7681     SFXN5        NCBI   94097   \n",
       "2         6633          1        3235     PRPF4        NCBI    9128   \n",
       "3        10451          1        3005    ZRANB1        NCBI   54764   \n",
       "4         6633          1         216     NCSTN        NCBI   23385   \n",
       "...        ...        ...         ...       ...         ...     ...   \n",
       "393675   31475          7        9639    DYNLL2        NCBI  140735   \n",
       "393676   65010          7       57129  PHOSPHO1        NCBI  162466   \n",
       "393677   97545          7       59351   CFAP100        NCBI  348807   \n",
       "393678   97545          7       59352    CFAP73        NCBI  387885   \n",
       "393679   31259          7       57434     SCIMP        NCBI  388325   \n",
       "\n",
       "        tail_type  display_relation          relation  \n",
       "0               1                 3   protein_protein  \n",
       "1               1                 3   protein_protein  \n",
       "2               1                 3   protein_protein  \n",
       "3               1                 3   protein_protein  \n",
       "4               1                 3   protein_protein  \n",
       "...           ...               ...               ...  \n",
       "393675          1                 2  cellcomp_protein  \n",
       "393676          1                 2  cellcomp_protein  \n",
       "393677          1                 2  cellcomp_protein  \n",
       "393678          1                 2  cellcomp_protein  \n",
       "393679          1                 2  cellcomp_protein  \n",
       "\n",
       "[393680 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biobridge_data.get_train_test_split()[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_index</th>\n",
       "      <th>head_name</th>\n",
       "      <th>head_source</th>\n",
       "      <th>head_id</th>\n",
       "      <th>head_type</th>\n",
       "      <th>tail_index</th>\n",
       "      <th>tail_name</th>\n",
       "      <th>tail_source</th>\n",
       "      <th>tail_id</th>\n",
       "      <th>tail_type</th>\n",
       "      <th>display_relation</th>\n",
       "      <th>relation</th>\n",
       "      <th>negative_tail_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PHYHIP</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>9796</td>\n",
       "      <td>1</td>\n",
       "      <td>8889</td>\n",
       "      <td>KIF15</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>56992</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "      <td>[1533, 13199, 3392, 58453, 2320, 5335, 5931, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GPANK1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>7918</td>\n",
       "      <td>1</td>\n",
       "      <td>2798</td>\n",
       "      <td>PNMA1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>9240</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "      <td>[3703, 3058, 12245, 77327, 1523, 11417, 8180, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ZRSR2</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>8233</td>\n",
       "      <td>1</td>\n",
       "      <td>5646</td>\n",
       "      <td>TTC33</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>23548</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "      <td>[57364, 4827, 3618, 4619, 13537, 2283, 13604, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NRF1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>4899</td>\n",
       "      <td>1</td>\n",
       "      <td>11592</td>\n",
       "      <td>MAN1B1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>11253</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "      <td>[9075, 14006, 57630, 58767, 59599, 566, 9093, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PI4KA</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>5297</td>\n",
       "      <td>1</td>\n",
       "      <td>2122</td>\n",
       "      <td>RGS20</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>8601</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "      <td>[1104, 9454, 11225, 6657, 13626, 5516, 12844, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510925</th>\n",
       "      <td>124473</td>\n",
       "      <td>longitudinal sarcoplasmic reticulum</td>\n",
       "      <td>GO</td>\n",
       "      <td>14801</td>\n",
       "      <td>7</td>\n",
       "      <td>58744</td>\n",
       "      <td>DHRS7C</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>201140</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cellcomp_protein</td>\n",
       "      <td>[274, 58856, 34400, 9268, 6714, 1526, 58741, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510926</th>\n",
       "      <td>55747</td>\n",
       "      <td>myofilament</td>\n",
       "      <td>GO</td>\n",
       "      <td>36379</td>\n",
       "      <td>7</td>\n",
       "      <td>57367</td>\n",
       "      <td>MYBPHL</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>343263</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cellcomp_protein</td>\n",
       "      <td>[58257, 56530, 521, 823, 2377, 1444, 5686, 117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510927</th>\n",
       "      <td>126945</td>\n",
       "      <td>lateral wall of outer hair cell</td>\n",
       "      <td>GO</td>\n",
       "      <td>120249</td>\n",
       "      <td>7</td>\n",
       "      <td>22033</td>\n",
       "      <td>SLC26A5</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>375611</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cellcomp_protein</td>\n",
       "      <td>[59304, 57686, 10627, 12313, 6187, 2347, 1572,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510928</th>\n",
       "      <td>125456</td>\n",
       "      <td>Swi5-Swi2 complex</td>\n",
       "      <td>GO</td>\n",
       "      <td>34974</td>\n",
       "      <td>7</td>\n",
       "      <td>57415</td>\n",
       "      <td>SWI5</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>375757</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cellcomp_protein</td>\n",
       "      <td>[7770, 4549, 59268, 11118, 10631, 2777, 6701, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510929</th>\n",
       "      <td>55667</td>\n",
       "      <td>SUMO ligase complex</td>\n",
       "      <td>GO</td>\n",
       "      <td>106068</td>\n",
       "      <td>7</td>\n",
       "      <td>35398</td>\n",
       "      <td>SUMO4</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>387082</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cellcomp_protein</td>\n",
       "      <td>[12719, 6375, 10602, 5835, 5810, 6651, 56598, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3510930 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         head_index                            head_name head_source head_id  \\\n",
       "0                 0                               PHYHIP        NCBI    9796   \n",
       "1                 1                               GPANK1        NCBI    7918   \n",
       "2                 2                                ZRSR2        NCBI    8233   \n",
       "3                 3                                 NRF1        NCBI    4899   \n",
       "4                 4                                PI4KA        NCBI    5297   \n",
       "...             ...                                  ...         ...     ...   \n",
       "3510925      124473  longitudinal sarcoplasmic reticulum          GO   14801   \n",
       "3510926       55747                          myofilament          GO   36379   \n",
       "3510927      126945      lateral wall of outer hair cell          GO  120249   \n",
       "3510928      125456                    Swi5-Swi2 complex          GO   34974   \n",
       "3510929       55667                  SUMO ligase complex          GO  106068   \n",
       "\n",
       "         head_type  tail_index tail_name tail_source tail_id  tail_type  \\\n",
       "0                1        8889     KIF15        NCBI   56992          1   \n",
       "1                1        2798     PNMA1        NCBI    9240          1   \n",
       "2                1        5646     TTC33        NCBI   23548          1   \n",
       "3                1       11592    MAN1B1        NCBI   11253          1   \n",
       "4                1        2122     RGS20        NCBI    8601          1   \n",
       "...            ...         ...       ...         ...     ...        ...   \n",
       "3510925          7       58744    DHRS7C        NCBI  201140          1   \n",
       "3510926          7       57367    MYBPHL        NCBI  343263          1   \n",
       "3510927          7       22033   SLC26A5        NCBI  375611          1   \n",
       "3510928          7       57415      SWI5        NCBI  375757          1   \n",
       "3510929          7       35398     SUMO4        NCBI  387082          1   \n",
       "\n",
       "         display_relation          relation  \\\n",
       "0                       3   protein_protein   \n",
       "1                       3   protein_protein   \n",
       "2                       3   protein_protein   \n",
       "3                       3   protein_protein   \n",
       "4                       3   protein_protein   \n",
       "...                   ...               ...   \n",
       "3510925                 2  cellcomp_protein   \n",
       "3510926                 2  cellcomp_protein   \n",
       "3510927                 2  cellcomp_protein   \n",
       "3510928                 2  cellcomp_protein   \n",
       "3510929                 2  cellcomp_protein   \n",
       "\n",
       "                                       negative_tail_index  \n",
       "0        [1533, 13199, 3392, 58453, 2320, 5335, 5931, 6...  \n",
       "1        [3703, 3058, 12245, 77327, 1523, 11417, 8180, ...  \n",
       "2        [57364, 4827, 3618, 4619, 13537, 2283, 13604, ...  \n",
       "3        [9075, 14006, 57630, 58767, 59599, 566, 9093, ...  \n",
       "4        [1104, 9454, 11225, 6657, 13626, 5516, 12844, ...  \n",
       "...                                                    ...  \n",
       "3510925  [274, 58856, 34400, 9268, 6714, 1526, 58741, 1...  \n",
       "3510926  [58257, 56530, 521, 823, 2377, 1444, 5686, 117...  \n",
       "3510927  [59304, 57686, 10627, 12313, 6187, 2347, 1572,...  \n",
       "3510928  [7770, 4549, 59268, 11118, 10631, 2777, 6701, ...  \n",
       "3510929  [12719, 6375, 10602, 5835, 5810, 6651, 56598, ...  \n",
       "\n",
       "[3510930 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biobridge_data.get_primekg_triplets_negative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_index</th>\n",
       "      <th>head_name</th>\n",
       "      <th>head_source</th>\n",
       "      <th>head_id</th>\n",
       "      <th>head_type</th>\n",
       "      <th>tail_index</th>\n",
       "      <th>tail_name</th>\n",
       "      <th>tail_source</th>\n",
       "      <th>tail_id</th>\n",
       "      <th>tail_type</th>\n",
       "      <th>display_relation</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PHYHIP</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>9796</td>\n",
       "      <td>1</td>\n",
       "      <td>8889</td>\n",
       "      <td>KIF15</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>56992</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GPANK1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>7918</td>\n",
       "      <td>1</td>\n",
       "      <td>2798</td>\n",
       "      <td>PNMA1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>9240</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ZRSR2</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>8233</td>\n",
       "      <td>1</td>\n",
       "      <td>5646</td>\n",
       "      <td>TTC33</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>23548</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NRF1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>4899</td>\n",
       "      <td>1</td>\n",
       "      <td>11592</td>\n",
       "      <td>MAN1B1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>11253</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PI4KA</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>5297</td>\n",
       "      <td>1</td>\n",
       "      <td>2122</td>\n",
       "      <td>RGS20</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>8601</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>protein_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904605</th>\n",
       "      <td>52855</td>\n",
       "      <td>B cell receptor transport into membrane raft</td>\n",
       "      <td>GO</td>\n",
       "      <td>32597</td>\n",
       "      <td>0</td>\n",
       "      <td>34572</td>\n",
       "      <td>CD24</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>100133941</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>bioprocess_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904606</th>\n",
       "      <td>113352</td>\n",
       "      <td>chemokine receptor transport out of membrane raft</td>\n",
       "      <td>GO</td>\n",
       "      <td>32600</td>\n",
       "      <td>0</td>\n",
       "      <td>34572</td>\n",
       "      <td>CD24</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>100133941</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>bioprocess_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904607</th>\n",
       "      <td>42264</td>\n",
       "      <td>negative regulation of cytoskeleton organization</td>\n",
       "      <td>GO</td>\n",
       "      <td>51494</td>\n",
       "      <td>0</td>\n",
       "      <td>57675</td>\n",
       "      <td>IQCJ-SCHIP1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>100505385</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>bioprocess_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904608</th>\n",
       "      <td>109904</td>\n",
       "      <td>mesendoderm migration</td>\n",
       "      <td>GO</td>\n",
       "      <td>90133</td>\n",
       "      <td>0</td>\n",
       "      <td>58770</td>\n",
       "      <td>APELA</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>100506013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>bioprocess_protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904609</th>\n",
       "      <td>44810</td>\n",
       "      <td>regulation of endoplasmic reticulum unfolded p...</td>\n",
       "      <td>GO</td>\n",
       "      <td>1900101</td>\n",
       "      <td>0</td>\n",
       "      <td>57692</td>\n",
       "      <td>PIGBOS1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>101928527</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>bioprocess_protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3904610 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         head_index                                          head_name  \\\n",
       "0                 0                                             PHYHIP   \n",
       "1                 1                                             GPANK1   \n",
       "2                 2                                              ZRSR2   \n",
       "3                 3                                               NRF1   \n",
       "4                 4                                              PI4KA   \n",
       "...             ...                                                ...   \n",
       "3904605       52855       B cell receptor transport into membrane raft   \n",
       "3904606      113352  chemokine receptor transport out of membrane raft   \n",
       "3904607       42264   negative regulation of cytoskeleton organization   \n",
       "3904608      109904                              mesendoderm migration   \n",
       "3904609       44810  regulation of endoplasmic reticulum unfolded p...   \n",
       "\n",
       "        head_source  head_id  head_type  tail_index    tail_name tail_source  \\\n",
       "0              NCBI     9796          1        8889        KIF15        NCBI   \n",
       "1              NCBI     7918          1        2798        PNMA1        NCBI   \n",
       "2              NCBI     8233          1        5646        TTC33        NCBI   \n",
       "3              NCBI     4899          1       11592       MAN1B1        NCBI   \n",
       "4              NCBI     5297          1        2122        RGS20        NCBI   \n",
       "...             ...      ...        ...         ...          ...         ...   \n",
       "3904605          GO    32597          0       34572         CD24        NCBI   \n",
       "3904606          GO    32600          0       34572         CD24        NCBI   \n",
       "3904607          GO    51494          0       57675  IQCJ-SCHIP1        NCBI   \n",
       "3904608          GO    90133          0       58770        APELA        NCBI   \n",
       "3904609          GO  1900101          0       57692      PIGBOS1        NCBI   \n",
       "\n",
       "           tail_id  tail_type  display_relation            relation  \n",
       "0            56992          1                 3     protein_protein  \n",
       "1             9240          1                 3     protein_protein  \n",
       "2            23548          1                 3     protein_protein  \n",
       "3            11253          1                 3     protein_protein  \n",
       "4             8601          1                 3     protein_protein  \n",
       "...            ...        ...               ...                 ...  \n",
       "3904605  100133941          1                 2  bioprocess_protein  \n",
       "3904606  100133941          1                 2  bioprocess_protein  \n",
       "3904607  100505385          1                 2  bioprocess_protein  \n",
       "3904608  100506013          1                 2  bioprocess_protein  \n",
       "3904609  101928527          1                 2  bioprocess_protein  \n",
       "\n",
       "[3904610 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biobridge_data.get_primekg_triplets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = biobridge_data.get_primekg_triplets_negative()\n",
    "test_split = biobridge_data.get_train_test_split()[\"test\"]\n",
    "node_train_split = biobridge_data.get_train_test_split()[\"node_train\"]\n",
    "node_test_split = biobridge_data.get_train_test_split()[\"node_test\"]\n",
    "\n",
    "df_all = biobridge_data.get_primekg_triplets()\n",
    "df_node_all = pd.concat([node_train_split, node_test_split], axis=0).reset_index(drop=True)\n",
    "\n",
    "# drop duplicate nodes and triples\n",
    "train_split = train_split.drop_duplicates(subset=[\"head_index\", \"tail_index\", \"display_relation\"]).reset_index(drop=True)\n",
    "# test_split = test_split.drop_duplicates(subset=[\"head_index\", \"tail_index\", \"display_relation\"]).reset_index(drop=True)\n",
    "node_train_split = node_train_split.drop_duplicates(subset=[\"node_index\"]).reset_index(drop=True)\n",
    "node_test_split = node_test_split.drop_duplicates(subset=[\"node_index\"]).reset_index(drop=True)\n",
    "df_all = df_all.drop_duplicates(subset=[\"head_index\", \"tail_index\", \"display_relation\"]).reset_index(drop=True)\n",
    "df_node_all = df_node_all.drop_duplicates(subset=[\"node_index\"]).reset_index(drop=True)\n",
    "\n",
    "split_data = {\n",
    "    \"train\": train_split,\n",
    "    \"test\": test_split,\n",
    "    \"node_train\": node_train_split,\n",
    "    \"node_test\": node_test_split,\n",
    "    \"all\": df_all,\n",
    "    \"node_all\": df_node_all,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_config(data_config):\n",
    "    # build model config\n",
    "    model_config = {\n",
    "        \"n_node\": len(data_config[\"node_type\"]),\n",
    "        \"n_relation\": len(data_config[\"relation_type\"]),\n",
    "        }\n",
    "    proj_dim = {}\n",
    "    for node_type, dim in data_config[\"emb_dim\"].items():\n",
    "        proj_dim[data_config[\"node_type\"][node_type]] = dim\n",
    "    model_config[\"proj_dim\"] = proj_dim\n",
    "    return model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrainDataset(**{\"triplet\":split_data[\"train\"], \n",
    "                             \"node\":split_data[\"node_train\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_index</th>\n",
       "      <th>node_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84976</th>\n",
       "      <td>127404</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84977</th>\n",
       "      <td>127415</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84978</th>\n",
       "      <td>127421</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84979</th>\n",
       "      <td>127425</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84980</th>\n",
       "      <td>127434</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84981 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       node_index  node_type\n",
       "0               0          1\n",
       "1               1          1\n",
       "2               2          1\n",
       "3               3          1\n",
       "4               4          1\n",
       "...           ...        ...\n",
       "84976      127404          7\n",
       "84977      127415          7\n",
       "84978      127421          7\n",
       "84979      127425          7\n",
       "84980      127434          7\n",
       "\n",
       "[84981 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data[\"node_all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 4 test nodes are removed because they do not have a tail node in the triplet.\n"
     ]
    }
   ],
   "source": [
    "val_data = ValDataset(**{\"triplet_all\":split_data[\"all\"], \n",
    "                         \"node_test\":split_data[\"node_test\"],\n",
    "                         \"node_all\":split_data[\"node_all\"],\n",
    "                         \"target_relation\": 2, # only consider the evaluation on one relation, 2: `interact with`\n",
    "                         \"target_node_type_index\": 1, # the index of the target node type: protein/gene is 1\n",
    "                         \"frequent_threshold\": 50, # the threshold of the frequent node\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_type': {'biological_process': 0,\n",
       "  'gene/protein': 1,\n",
       "  'disease': 2,\n",
       "  'effect/phenotype': 3,\n",
       "  'anatomy': 4,\n",
       "  'molecular_function': 5,\n",
       "  'drug': 6,\n",
       "  'cellular_component': 7,\n",
       "  'pathway': 8,\n",
       "  'exposure': 9},\n",
       " 'relation_type': {'expression present': 0,\n",
       "  'synergistic interaction': 1,\n",
       "  'interacts with': 2,\n",
       "  'ppi': 3,\n",
       "  'phenotype present': 4,\n",
       "  'parent-child': 5,\n",
       "  'associated with': 6,\n",
       "  'side effect': 7,\n",
       "  'contraindication': 8,\n",
       "  'expression absent': 9,\n",
       "  'target': 10,\n",
       "  'indication': 11,\n",
       "  'enzyme': 12,\n",
       "  'transporter': 13,\n",
       "  'off-label use': 14,\n",
       "  'linked to': 15,\n",
       "  'phenotype absent': 16,\n",
       "  'carrier': 17},\n",
       " 'emb_dim': {'biological_process': 768,\n",
       "  'cellular_component': 768,\n",
       "  'disease': 768,\n",
       "  'drug': 512,\n",
       "  'molecular_function': 768,\n",
       "  'gene/protein': 2560}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_config = biobridge_data.get_data_config()\n",
    "data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# urls = ['https://raw.githubusercontent.com/RyanWangZf/BioBridge/refs/heads/main/src/losses.py',\n",
    "#         'https://raw.githubusercontent.com/RyanWangZf/BioBridge/refs/heads/main/src/model.py',\n",
    "#         'https://raw.githubusercontent.com/RyanWangZf/BioBridge/refs/heads/main/src/trainer.py',\n",
    "#         'https://raw.githubusercontent.com/RyanWangZf/BioBridge/refs/heads/main/src/schema.py',\n",
    "#         'https://raw.githubusercontent.com/RyanWangZf/BioBridge/refs/heads/main/src/collator.py']\n",
    "# os.makedirs(\"biobridge\", exist_ok=True)\n",
    "# for url in urls:\n",
    "#        filename = url.split('/')[-1]\n",
    "#        urllib.request.urlretrieve(url, \"biobridge/\"+filename)\n",
    "\n",
    "# init_file_path = os.path.join(\"biobridge\", \"__init__.py\")    \n",
    "# with open(init_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#       f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Model Configuration ###\n",
      "{\n",
      "    \"n_node\": 10,\n",
      "    \"n_relation\": 18,\n",
      "    \"proj_dim\": {\n",
      "        \"0\": 768,\n",
      "        \"7\": 768,\n",
      "        \"2\": 768,\n",
      "        \"6\": 512,\n",
      "        \"5\": 768,\n",
      "        \"1\": 2560\n",
      "    },\n",
      "    \"hidden_dim\": 768,\n",
      "    \"n_layer\": 6\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BindingModel(\n",
       "  (paired_loss_fn): InfoNCE()\n",
       "  (unpaired_loss_fn): InfoNCE()\n",
       "  (node_type_embed): Sequential(\n",
       "    (0): Embedding(10, 768)\n",
       "    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (relation_type_embed): Sequential(\n",
       "    (0): Embedding(18, 768)\n",
       "    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (proj_layer): ModuleDict(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=False)\n",
       "    (7): Linear(in_features=768, out_features=768, bias=False)\n",
       "    (2): Linear(in_features=768, out_features=768, bias=False)\n",
       "    (6): Linear(in_features=512, out_features=768, bias=False)\n",
       "    (5): Linear(in_features=768, out_features=768, bias=False)\n",
       "    (1): Linear(in_features=2560, out_features=768, bias=False)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from docs.notebooks.talk2knowledgegraphs.biobridge.model import BindingModel\n",
    "\n",
    "\n",
    "# build the model\n",
    "print(\"### Model Configuration ###\")\n",
    "# build model config\n",
    "model_config = build_model_config(data_config)\n",
    "model_config[\"hidden_dim\"] = hidden_dim\n",
    "model_config[\"n_layer\"] = n_layer\n",
    "print(json.dumps(model_config, indent=4))\n",
    "model = BindingModel(**model_config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model config to the save directory\n",
    "with open(os.path.join(save_dir, \"model_config.json\"), \"w\") as f:\n",
    "    json.dump(model_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers.trainer_utils import speed_metrics\n",
    "from transformers.debug_utils import DebugOption\n",
    "from transformers.trainer_utils import (\n",
    "    EvalPrediction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# build trainer\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=save_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=n_epoch,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=2, # every node corresponds to multiple tail nodes\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=5,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=eval_steps,\n",
    "    max_grad_norm=1.0, # gradient clipping\n",
    "    warmup_ratio=0.1,\n",
    "    dataloader_num_workers=dataloader_num_workers, # number of processes to use for dataloading\n",
    "    report_to=\"wandb\" if use_wandb else \"none\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (52660047.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install transformers[torch]\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]\n",
    "pip install accelerate==1.4.0\n",
    "pip install wandb==0.19.8\n",
    "pip install lightning==2.5.0.post0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Training Arguments ###\n",
      "{\n",
      "    \"output_dir\": \"./checkpoints/model-1\",\n",
      "    \"overwrite_output_dir\": true,\n",
      "    \"do_train\": false,\n",
      "    \"do_eval\": true,\n",
      "    \"do_predict\": false,\n",
      "    \"eval_strategy\": \"steps\",\n",
      "    \"prediction_loss_only\": false,\n",
      "    \"per_device_train_batch_size\": 1024,\n",
      "    \"per_device_eval_batch_size\": 2,\n",
      "    \"per_gpu_train_batch_size\": null,\n",
      "    \"per_gpu_eval_batch_size\": null,\n",
      "    \"gradient_accumulation_steps\": 1,\n",
      "    \"eval_accumulation_steps\": null,\n",
      "    \"eval_delay\": 0,\n",
      "    \"torch_empty_cache_steps\": null,\n",
      "    \"learning_rate\": 0.0016,\n",
      "    \"weight_decay\": 0.0001,\n",
      "    \"adam_beta1\": 0.9,\n",
      "    \"adam_beta2\": 0.999,\n",
      "    \"adam_epsilon\": 1e-08,\n",
      "    \"max_grad_norm\": 1.0,\n",
      "    \"num_train_epochs\": 10,\n",
      "    \"max_steps\": -1,\n",
      "    \"lr_scheduler_type\": \"linear\",\n",
      "    \"lr_scheduler_kwargs\": {},\n",
      "    \"warmup_ratio\": 0.1,\n",
      "    \"warmup_steps\": 0,\n",
      "    \"log_level\": \"passive\",\n",
      "    \"log_level_replica\": \"warning\",\n",
      "    \"log_on_each_node\": true,\n",
      "    \"logging_dir\": \"./checkpoints/model-1/runs/Mar13_12-59-40_awmulyadi\",\n",
      "    \"logging_strategy\": \"steps\",\n",
      "    \"logging_first_step\": false,\n",
      "    \"logging_steps\": 10,\n",
      "    \"logging_nan_inf_filter\": true,\n",
      "    \"save_strategy\": \"steps\",\n",
      "    \"save_steps\": 10,\n",
      "    \"save_total_limit\": 5,\n",
      "    \"save_safetensors\": true,\n",
      "    \"save_on_each_node\": false,\n",
      "    \"save_only_model\": false,\n",
      "    \"restore_callback_states_from_checkpoint\": false,\n",
      "    \"no_cuda\": false,\n",
      "    \"use_cpu\": false,\n",
      "    \"use_mps_device\": false,\n",
      "    \"seed\": 42,\n",
      "    \"data_seed\": null,\n",
      "    \"jit_mode_eval\": false,\n",
      "    \"use_ipex\": false,\n",
      "    \"bf16\": false,\n",
      "    \"fp16\": false,\n",
      "    \"fp16_opt_level\": \"O1\",\n",
      "    \"half_precision_backend\": \"auto\",\n",
      "    \"bf16_full_eval\": false,\n",
      "    \"fp16_full_eval\": false,\n",
      "    \"tf32\": null,\n",
      "    \"local_rank\": 0,\n",
      "    \"ddp_backend\": null,\n",
      "    \"tpu_num_cores\": null,\n",
      "    \"tpu_metrics_debug\": false,\n",
      "    \"debug\": [],\n",
      "    \"dataloader_drop_last\": false,\n",
      "    \"eval_steps\": 10,\n",
      "    \"dataloader_num_workers\": 4,\n",
      "    \"dataloader_prefetch_factor\": null,\n",
      "    \"past_index\": -1,\n",
      "    \"run_name\": \"./checkpoints/model-1\",\n",
      "    \"disable_tqdm\": false,\n",
      "    \"remove_unused_columns\": true,\n",
      "    \"label_names\": null,\n",
      "    \"load_best_model_at_end\": false,\n",
      "    \"metric_for_best_model\": null,\n",
      "    \"greater_is_better\": null,\n",
      "    \"ignore_data_skip\": false,\n",
      "    \"fsdp\": [],\n",
      "    \"fsdp_min_num_params\": 0,\n",
      "    \"fsdp_config\": {\n",
      "        \"min_num_params\": 0,\n",
      "        \"xla\": false,\n",
      "        \"xla_fsdp_v2\": false,\n",
      "        \"xla_fsdp_grad_ckpt\": false\n",
      "    },\n",
      "    \"fsdp_transformer_layer_cls_to_wrap\": null,\n",
      "    \"accelerator_config\": {\n",
      "        \"split_batches\": false,\n",
      "        \"dispatch_batches\": null,\n",
      "        \"even_batches\": true,\n",
      "        \"use_seedable_sampler\": true,\n",
      "        \"non_blocking\": false,\n",
      "        \"gradient_accumulation_kwargs\": null\n",
      "    },\n",
      "    \"deepspeed\": null,\n",
      "    \"label_smoothing_factor\": 0.0,\n",
      "    \"optim\": \"adamw_torch\",\n",
      "    \"optim_args\": null,\n",
      "    \"adafactor\": false,\n",
      "    \"group_by_length\": false,\n",
      "    \"length_column_name\": \"length\",\n",
      "    \"report_to\": [\n",
      "        \"wandb\"\n",
      "    ],\n",
      "    \"ddp_find_unused_parameters\": null,\n",
      "    \"ddp_bucket_cap_mb\": null,\n",
      "    \"ddp_broadcast_buffers\": null,\n",
      "    \"dataloader_pin_memory\": true,\n",
      "    \"dataloader_persistent_workers\": false,\n",
      "    \"skip_memory_metrics\": true,\n",
      "    \"use_legacy_prediction_loop\": false,\n",
      "    \"push_to_hub\": false,\n",
      "    \"resume_from_checkpoint\": null,\n",
      "    \"hub_model_id\": null,\n",
      "    \"hub_strategy\": \"every_save\",\n",
      "    \"hub_token\": \"<HUB_TOKEN>\",\n",
      "    \"hub_private_repo\": null,\n",
      "    \"hub_always_push\": false,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"gradient_checkpointing_kwargs\": null,\n",
      "    \"include_inputs_for_metrics\": false,\n",
      "    \"include_for_metrics\": [],\n",
      "    \"eval_do_concat_batches\": true,\n",
      "    \"fp16_backend\": \"auto\",\n",
      "    \"evaluation_strategy\": \"steps\",\n",
      "    \"push_to_hub_model_id\": null,\n",
      "    \"push_to_hub_organization\": null,\n",
      "    \"push_to_hub_token\": \"<PUSH_TO_HUB_TOKEN>\",\n",
      "    \"mp_parameters\": \"\",\n",
      "    \"auto_find_batch_size\": false,\n",
      "    \"full_determinism\": false,\n",
      "    \"torchdynamo\": null,\n",
      "    \"ray_scope\": \"last\",\n",
      "    \"ddp_timeout\": 1800,\n",
      "    \"torch_compile\": false,\n",
      "    \"torch_compile_backend\": null,\n",
      "    \"torch_compile_mode\": null,\n",
      "    \"dispatch_batches\": null,\n",
      "    \"split_batches\": null,\n",
      "    \"include_tokens_per_second\": false,\n",
      "    \"include_num_input_tokens_seen\": false,\n",
      "    \"neftune_noise_alpha\": null,\n",
      "    \"optim_target_modules\": null,\n",
      "    \"batch_eval_metrics\": false,\n",
      "    \"eval_on_start\": false,\n",
      "    \"use_liger_kernel\": false,\n",
      "    \"eval_use_gather_object\": false,\n",
      "    \"average_tokens_across_devices\": false\n",
      "}\n",
      "### Number of Trainable Parameters ###\n",
      "37827072\n"
     ]
    }
   ],
   "source": [
    "print(\"### Training Arguments ###\")\n",
    "print(json.dumps(train_args.to_dict(), indent=4))\n",
    "\n",
    "print(\"### Number of Trainable Parameters ###\")\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "from collections import defaultdict\n",
    "from transformers.trainer_utils import (\n",
    "    EvalPrediction,\n",
    ")\n",
    "\n",
    "def compute_metrics(inputs: EvalPrediction) -> Dict:\n",
    "    \"\"\"Compute the metrics for the prediction.\"\"\"\n",
    "    metrics = defaultdict(list)\n",
    "    predictions = inputs.predictions\n",
    "    # print(inputs.predictions)\n",
    "    # print(predictions)\n",
    "    # print(predictions['prediction'])\n",
    "    num_samples = len(predictions[\"node_index\"])\n",
    "    node_types = predictions[\"node_type\"]\n",
    "    all_tail_types = list(predictions['prediction'].keys())\n",
    "    for tail_type in all_tail_types:\n",
    "        preds, labels = predictions['prediction'][tail_type], predictions['label'][tail_type]\n",
    "        for i in range(num_samples):\n",
    "            # compute r@k, k = 5, 10, 20\n",
    "            # compute ndcg@k, k = 5\n",
    "            # recall: tp / (tp+fn)\n",
    "            node_types_i = node_types[i]\n",
    "            pred, label = preds[i], labels[i]\n",
    "            label = label[label!=-100]\n",
    "            if len(label) > 0:\n",
    "                # only consider the case where the label is not empty\n",
    "                rec_5 = len(set(pred[0][:5].tolist()).intersection(set(label.tolist()))) / len(label)\n",
    "                metrics[f\"head_{node_types_i}_tail_{tail_type}_rec@5\"].append(rec_5)\n",
    "                rec_10 = len(set(pred[0][:10].tolist()).intersection(set(label.tolist()))) / len(label)\n",
    "                metrics[f\"head_{node_types_i}_tail_{tail_type}_rec@10\"].append(rec_10)\n",
    "                rec_20 = len(set(pred[0][:20].tolist()).intersection(set(label.tolist()))) / len(label)\n",
    "                metrics[f\"head_{node_types_i}_tail_{tail_type}_rec@20\"].append(rec_20)\n",
    "\n",
    "    # compute the sample average\n",
    "    new_metrics = {}\n",
    "    for k, v in metrics.items():\n",
    "        new_metrics[k] = np.mean(v)\n",
    "\n",
    "    # TODO: average over all tail types if more than one tail type\n",
    "    if len(all_tail_types) > 1:\n",
    "        pass\n",
    "\n",
    "    return new_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Dict, List, Optional\n",
    "# from collections import defaultdict\n",
    "# from transformers.trainer_utils import (\n",
    "#     EvalPrediction,\n",
    "# )\n",
    "\n",
    "\n",
    "# def compute_metrics(inputs: EvalPrediction) -> Dict:\n",
    "#     \"\"\"Compute the metrics for the prediction.\"\"\"\n",
    "#     metrics = defaultdict(list)\n",
    "#     predictions_list = inputs.predictions[0]\n",
    "#     print(\"Type of predictions_list:\", type(predictions_list))\n",
    "#     print(\"First element in predictions_list:\", predictions_list)\n",
    "    \n",
    "#     num_samples = len(predictions_list)\n",
    "#     print(\"Number of samples:\", num_samples)\n",
    "    \n",
    "#     predictions_dict = {\n",
    "#         \"node_index\": [],\n",
    "#         \"node_type\": [],\n",
    "#         \"prediction\": defaultdict(list),\n",
    "#         \"label\": defaultdict(list)\n",
    "#     }\n",
    "\n",
    "    \n",
    "#     for prediction in predictions_list:\n",
    "#         print(\"Prediction\", prediction)\n",
    "#         predictions_dict[\"node_index\"].append(prediction[\"node_index\"])\n",
    "#         predictions_dict[\"node_type\"].append(prediction[\"node_type\"])\n",
    "#         for key in prediction[\"prediction\"]:\n",
    "#             predictions_dict[\"prediction\"][key].append(prediction[\"prediction\"][key])\n",
    "#         for key in prediction[\"label\"]:\n",
    "#             predictions_dict[\"label\"][key].append(prediction[\"label\"][key])\n",
    "    \n",
    "#     node_types = predictions_dict[\"node_type\"]\n",
    "#     all_tail_types = list(predictions_dict['prediction'].keys())\n",
    "\n",
    "#     for tail_type in all_tail_types:\n",
    "#         preds, labels = predictions_dict['prediction'][tail_type], predictions_dict['label'][tail_type]\n",
    "        \n",
    "#         for i in range(num_samples):\n",
    "#             node_types_i = node_types[i]\n",
    "#             pred, label = preds[i], labels[i]\n",
    "#             label = label[label != -100]\n",
    "            \n",
    "#             if len(label) > 0:\n",
    "#                 rec_5 = len(set(pred[:5]).intersection(set(label))) / len(label)\n",
    "#                 metrics[f\"head_{node_types_i}_tail_{tail_type}_rec@5\"].append(rec_5)\n",
    "#                 rec_10 = len(set(pred[:10]).intersection(set(label))) / len(label)\n",
    "#                 metrics[f\"head_{node_types_i}_tail_{tail_type}_rec@10\"].append(rec_10)\n",
    "#                 rec_20 = len(set(pred[:20]).intersection(set(label))) / len(label)\n",
    "#                 metrics[f\"head_{node_types_i}_tail_{tail_type}_rec@20\"].append(rec_20)\n",
    "\n",
    "#     new_metrics = {k: np.mean(v) for k, v in metrics.items()}\n",
    "    \n",
    "#     return new_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = biobridge_data.get_node_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from biobridge.trainer import BindingTrainer\n",
    "from biobridge.collator import TrainCollator, ValCollator\n",
    "\n",
    "# build trainer\n",
    "trainer = BindingTrainer(\n",
    "    args=train_args,\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=TrainCollator(embedding_dict),\n",
    "    test_data_collator=ValCollator(embedding_dict),\n",
    "    compute_metrics=compute_metrics,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandDB API Key\n",
    "# abee8b0cb03cd169a5bfc6bb2f5e9dd483980f4e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1831' max='34290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1831/34290 1:07:37 < 20:00:13, 0.45 it/s, Epoch 0.53/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Head 1 Tail 5 Rec@5</th>\n",
       "      <th>Head 1 Tail 5 Rec@10</th>\n",
       "      <th>Head 1 Tail 5 Rec@20</th>\n",
       "      <th>Head 1 Tail 7 Rec@5</th>\n",
       "      <th>Head 1 Tail 7 Rec@10</th>\n",
       "      <th>Head 1 Tail 7 Rec@20</th>\n",
       "      <th>Head 1 Tail 0 Rec@5</th>\n",
       "      <th>Head 1 Tail 0 Rec@10</th>\n",
       "      <th>Head 1 Tail 0 Rec@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.769500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.406749</td>\n",
       "      <td>0.432175</td>\n",
       "      <td>0.534897</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>0.051285</td>\n",
       "      <td>0.084021</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.017347</td>\n",
       "      <td>0.037576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.759100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.460967</td>\n",
       "      <td>0.512326</td>\n",
       "      <td>0.549922</td>\n",
       "      <td>0.013132</td>\n",
       "      <td>0.052904</td>\n",
       "      <td>0.236511</td>\n",
       "      <td>0.009102</td>\n",
       "      <td>0.029819</td>\n",
       "      <td>0.046011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.725300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.435522</td>\n",
       "      <td>0.531744</td>\n",
       "      <td>0.552096</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>0.179308</td>\n",
       "      <td>0.409008</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.019328</td>\n",
       "      <td>0.058344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.702600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.439060</td>\n",
       "      <td>0.532080</td>\n",
       "      <td>0.553004</td>\n",
       "      <td>0.054861</td>\n",
       "      <td>0.188183</td>\n",
       "      <td>0.412271</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.022202</td>\n",
       "      <td>0.054238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.677200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.440259</td>\n",
       "      <td>0.487042</td>\n",
       "      <td>0.552985</td>\n",
       "      <td>0.107789</td>\n",
       "      <td>0.209164</td>\n",
       "      <td>0.471282</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>0.018103</td>\n",
       "      <td>0.056348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.655200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.441084</td>\n",
       "      <td>0.488120</td>\n",
       "      <td>0.552985</td>\n",
       "      <td>0.159105</td>\n",
       "      <td>0.214983</td>\n",
       "      <td>0.475639</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.019454</td>\n",
       "      <td>0.051394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.643000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.436280</td>\n",
       "      <td>0.489048</td>\n",
       "      <td>0.556655</td>\n",
       "      <td>0.171552</td>\n",
       "      <td>0.376764</td>\n",
       "      <td>0.417422</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.030969</td>\n",
       "      <td>0.051612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.631100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.436280</td>\n",
       "      <td>0.526593</td>\n",
       "      <td>0.554914</td>\n",
       "      <td>0.291318</td>\n",
       "      <td>0.380528</td>\n",
       "      <td>0.425163</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>0.025164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.611700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.434846</td>\n",
       "      <td>0.526593</td>\n",
       "      <td>0.554827</td>\n",
       "      <td>0.291318</td>\n",
       "      <td>0.388260</td>\n",
       "      <td>0.584831</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>0.033112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.605800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.435891</td>\n",
       "      <td>0.526593</td>\n",
       "      <td>0.555132</td>\n",
       "      <td>0.250192</td>\n",
       "      <td>0.443707</td>\n",
       "      <td>0.584473</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.017768</td>\n",
       "      <td>0.036017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.594500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.477678</td>\n",
       "      <td>0.526593</td>\n",
       "      <td>0.564527</td>\n",
       "      <td>0.261448</td>\n",
       "      <td>0.515663</td>\n",
       "      <td>0.587457</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>0.048931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.561100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.434359</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.563988</td>\n",
       "      <td>0.282102</td>\n",
       "      <td>0.517153</td>\n",
       "      <td>0.582292</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.014775</td>\n",
       "      <td>0.050597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.552300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.407859</td>\n",
       "      <td>0.521889</td>\n",
       "      <td>0.582135</td>\n",
       "      <td>0.370067</td>\n",
       "      <td>0.411388</td>\n",
       "      <td>0.592838</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.059653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.551400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.412489</td>\n",
       "      <td>0.510458</td>\n",
       "      <td>0.577555</td>\n",
       "      <td>0.370018</td>\n",
       "      <td>0.471567</td>\n",
       "      <td>0.603001</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.028471</td>\n",
       "      <td>0.074345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.528600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.453463</td>\n",
       "      <td>0.482108</td>\n",
       "      <td>0.575512</td>\n",
       "      <td>0.370018</td>\n",
       "      <td>0.558102</td>\n",
       "      <td>0.600590</td>\n",
       "      <td>0.018019</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>0.063720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.507000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.454854</td>\n",
       "      <td>0.509167</td>\n",
       "      <td>0.576768</td>\n",
       "      <td>0.370601</td>\n",
       "      <td>0.489851</td>\n",
       "      <td>0.592958</td>\n",
       "      <td>0.065181</td>\n",
       "      <td>0.094764</td>\n",
       "      <td>0.124988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.497300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.407682</td>\n",
       "      <td>0.505311</td>\n",
       "      <td>0.584681</td>\n",
       "      <td>0.368808</td>\n",
       "      <td>0.483809</td>\n",
       "      <td>0.610852</td>\n",
       "      <td>0.082484</td>\n",
       "      <td>0.114073</td>\n",
       "      <td>0.147559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.489500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.428311</td>\n",
       "      <td>0.490072</td>\n",
       "      <td>0.575689</td>\n",
       "      <td>0.387030</td>\n",
       "      <td>0.524640</td>\n",
       "      <td>0.617434</td>\n",
       "      <td>0.032327</td>\n",
       "      <td>0.048663</td>\n",
       "      <td>0.111387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.483500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.454231</td>\n",
       "      <td>0.490832</td>\n",
       "      <td>0.595142</td>\n",
       "      <td>0.361703</td>\n",
       "      <td>0.521515</td>\n",
       "      <td>0.664605</td>\n",
       "      <td>0.061172</td>\n",
       "      <td>0.083303</td>\n",
       "      <td>0.118955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.466800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.454792</td>\n",
       "      <td>0.513778</td>\n",
       "      <td>0.629854</td>\n",
       "      <td>0.358373</td>\n",
       "      <td>0.512789</td>\n",
       "      <td>0.650433</td>\n",
       "      <td>0.097872</td>\n",
       "      <td>0.117923</td>\n",
       "      <td>0.139202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.464900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.459456</td>\n",
       "      <td>0.535335</td>\n",
       "      <td>0.625534</td>\n",
       "      <td>0.418026</td>\n",
       "      <td>0.559659</td>\n",
       "      <td>0.636253</td>\n",
       "      <td>0.077654</td>\n",
       "      <td>0.099624</td>\n",
       "      <td>0.150099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.465300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.474572</td>\n",
       "      <td>0.553759</td>\n",
       "      <td>0.646348</td>\n",
       "      <td>0.430696</td>\n",
       "      <td>0.541036</td>\n",
       "      <td>0.641730</td>\n",
       "      <td>0.079590</td>\n",
       "      <td>0.110726</td>\n",
       "      <td>0.155878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.457500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.451814</td>\n",
       "      <td>0.526238</td>\n",
       "      <td>0.618087</td>\n",
       "      <td>0.379317</td>\n",
       "      <td>0.534542</td>\n",
       "      <td>0.634939</td>\n",
       "      <td>0.054578</td>\n",
       "      <td>0.085484</td>\n",
       "      <td>0.139882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.431400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.439205</td>\n",
       "      <td>0.508162</td>\n",
       "      <td>0.618548</td>\n",
       "      <td>0.397449</td>\n",
       "      <td>0.542926</td>\n",
       "      <td>0.628438</td>\n",
       "      <td>0.063202</td>\n",
       "      <td>0.097960</td>\n",
       "      <td>0.141272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.451500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.445477</td>\n",
       "      <td>0.550777</td>\n",
       "      <td>0.626531</td>\n",
       "      <td>0.416210</td>\n",
       "      <td>0.575023</td>\n",
       "      <td>0.665973</td>\n",
       "      <td>0.076998</td>\n",
       "      <td>0.101452</td>\n",
       "      <td>0.148028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.432500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.445376</td>\n",
       "      <td>0.532383</td>\n",
       "      <td>0.623808</td>\n",
       "      <td>0.440598</td>\n",
       "      <td>0.559700</td>\n",
       "      <td>0.665760</td>\n",
       "      <td>0.105875</td>\n",
       "      <td>0.129946</td>\n",
       "      <td>0.173214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.427300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.475083</td>\n",
       "      <td>0.557072</td>\n",
       "      <td>0.627372</td>\n",
       "      <td>0.438920</td>\n",
       "      <td>0.524321</td>\n",
       "      <td>0.654343</td>\n",
       "      <td>0.106388</td>\n",
       "      <td>0.130989</td>\n",
       "      <td>0.179932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.428100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.487159</td>\n",
       "      <td>0.546530</td>\n",
       "      <td>0.653777</td>\n",
       "      <td>0.432589</td>\n",
       "      <td>0.568962</td>\n",
       "      <td>0.647695</td>\n",
       "      <td>0.094718</td>\n",
       "      <td>0.126345</td>\n",
       "      <td>0.172102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.437200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.495985</td>\n",
       "      <td>0.573830</td>\n",
       "      <td>0.668648</td>\n",
       "      <td>0.455001</td>\n",
       "      <td>0.559249</td>\n",
       "      <td>0.654284</td>\n",
       "      <td>0.096851</td>\n",
       "      <td>0.112400</td>\n",
       "      <td>0.167937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.425400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.454714</td>\n",
       "      <td>0.560644</td>\n",
       "      <td>0.654120</td>\n",
       "      <td>0.447362</td>\n",
       "      <td>0.585479</td>\n",
       "      <td>0.676955</td>\n",
       "      <td>0.103625</td>\n",
       "      <td>0.134815</td>\n",
       "      <td>0.175734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.392100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.515621</td>\n",
       "      <td>0.586422</td>\n",
       "      <td>0.664451</td>\n",
       "      <td>0.452593</td>\n",
       "      <td>0.586724</td>\n",
       "      <td>0.678902</td>\n",
       "      <td>0.105345</td>\n",
       "      <td>0.137184</td>\n",
       "      <td>0.189383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.393400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.483526</td>\n",
       "      <td>0.574486</td>\n",
       "      <td>0.664141</td>\n",
       "      <td>0.480512</td>\n",
       "      <td>0.589255</td>\n",
       "      <td>0.673167</td>\n",
       "      <td>0.134629</td>\n",
       "      <td>0.162753</td>\n",
       "      <td>0.210953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.387400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.495485</td>\n",
       "      <td>0.570394</td>\n",
       "      <td>0.659034</td>\n",
       "      <td>0.488027</td>\n",
       "      <td>0.584844</td>\n",
       "      <td>0.662413</td>\n",
       "      <td>0.106635</td>\n",
       "      <td>0.130286</td>\n",
       "      <td>0.171734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.391600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.395861</td>\n",
       "      <td>0.503420</td>\n",
       "      <td>0.613781</td>\n",
       "      <td>0.454053</td>\n",
       "      <td>0.562808</td>\n",
       "      <td>0.661856</td>\n",
       "      <td>0.122089</td>\n",
       "      <td>0.149795</td>\n",
       "      <td>0.195340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.385000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.458982</td>\n",
       "      <td>0.579086</td>\n",
       "      <td>0.665218</td>\n",
       "      <td>0.476049</td>\n",
       "      <td>0.565612</td>\n",
       "      <td>0.688772</td>\n",
       "      <td>0.104029</td>\n",
       "      <td>0.146048</td>\n",
       "      <td>0.203170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.384400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.446365</td>\n",
       "      <td>0.552750</td>\n",
       "      <td>0.673659</td>\n",
       "      <td>0.459380</td>\n",
       "      <td>0.581014</td>\n",
       "      <td>0.684087</td>\n",
       "      <td>0.147885</td>\n",
       "      <td>0.186956</td>\n",
       "      <td>0.234319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.361600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.514535</td>\n",
       "      <td>0.592618</td>\n",
       "      <td>0.684567</td>\n",
       "      <td>0.461142</td>\n",
       "      <td>0.587125</td>\n",
       "      <td>0.682511</td>\n",
       "      <td>0.119433</td>\n",
       "      <td>0.157220</td>\n",
       "      <td>0.203667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.353400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.498615</td>\n",
       "      <td>0.588226</td>\n",
       "      <td>0.678072</td>\n",
       "      <td>0.455042</td>\n",
       "      <td>0.589420</td>\n",
       "      <td>0.682842</td>\n",
       "      <td>0.103559</td>\n",
       "      <td>0.132781</td>\n",
       "      <td>0.181956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.343700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.497742</td>\n",
       "      <td>0.588162</td>\n",
       "      <td>0.683911</td>\n",
       "      <td>0.429925</td>\n",
       "      <td>0.594333</td>\n",
       "      <td>0.675019</td>\n",
       "      <td>0.108722</td>\n",
       "      <td>0.137770</td>\n",
       "      <td>0.198708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.360300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.499208</td>\n",
       "      <td>0.589761</td>\n",
       "      <td>0.697583</td>\n",
       "      <td>0.457441</td>\n",
       "      <td>0.592168</td>\n",
       "      <td>0.690428</td>\n",
       "      <td>0.114770</td>\n",
       "      <td>0.160449</td>\n",
       "      <td>0.222126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.352000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.522164</td>\n",
       "      <td>0.592360</td>\n",
       "      <td>0.680845</td>\n",
       "      <td>0.487515</td>\n",
       "      <td>0.587894</td>\n",
       "      <td>0.692673</td>\n",
       "      <td>0.116996</td>\n",
       "      <td>0.154316</td>\n",
       "      <td>0.212517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.329300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.513520</td>\n",
       "      <td>0.591219</td>\n",
       "      <td>0.681999</td>\n",
       "      <td>0.473490</td>\n",
       "      <td>0.582245</td>\n",
       "      <td>0.698672</td>\n",
       "      <td>0.117053</td>\n",
       "      <td>0.157928</td>\n",
       "      <td>0.214169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.344500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.473992</td>\n",
       "      <td>0.598197</td>\n",
       "      <td>0.707534</td>\n",
       "      <td>0.456419</td>\n",
       "      <td>0.571631</td>\n",
       "      <td>0.679739</td>\n",
       "      <td>0.138082</td>\n",
       "      <td>0.175869</td>\n",
       "      <td>0.233712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.328800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.521537</td>\n",
       "      <td>0.599085</td>\n",
       "      <td>0.694530</td>\n",
       "      <td>0.377971</td>\n",
       "      <td>0.537538</td>\n",
       "      <td>0.635370</td>\n",
       "      <td>0.140729</td>\n",
       "      <td>0.181310</td>\n",
       "      <td>0.244139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.328700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.459299</td>\n",
       "      <td>0.585653</td>\n",
       "      <td>0.684886</td>\n",
       "      <td>0.432491</td>\n",
       "      <td>0.558600</td>\n",
       "      <td>0.660289</td>\n",
       "      <td>0.122785</td>\n",
       "      <td>0.148298</td>\n",
       "      <td>0.195560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.330900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.573165</td>\n",
       "      <td>0.672363</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.585409</td>\n",
       "      <td>0.679854</td>\n",
       "      <td>0.110113</td>\n",
       "      <td>0.162031</td>\n",
       "      <td>0.228651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.307300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.499039</td>\n",
       "      <td>0.594370</td>\n",
       "      <td>0.692587</td>\n",
       "      <td>0.381111</td>\n",
       "      <td>0.522146</td>\n",
       "      <td>0.648924</td>\n",
       "      <td>0.135467</td>\n",
       "      <td>0.182978</td>\n",
       "      <td>0.240604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.318300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.477993</td>\n",
       "      <td>0.586873</td>\n",
       "      <td>0.693491</td>\n",
       "      <td>0.386272</td>\n",
       "      <td>0.535608</td>\n",
       "      <td>0.669449</td>\n",
       "      <td>0.110541</td>\n",
       "      <td>0.150021</td>\n",
       "      <td>0.214181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.320300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.493578</td>\n",
       "      <td>0.568853</td>\n",
       "      <td>0.680047</td>\n",
       "      <td>0.433639</td>\n",
       "      <td>0.591174</td>\n",
       "      <td>0.697332</td>\n",
       "      <td>0.134432</td>\n",
       "      <td>0.187120</td>\n",
       "      <td>0.254363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.287400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.495945</td>\n",
       "      <td>0.590190</td>\n",
       "      <td>0.675599</td>\n",
       "      <td>0.478954</td>\n",
       "      <td>0.607921</td>\n",
       "      <td>0.695002</td>\n",
       "      <td>0.158424</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.275894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.297900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.507226</td>\n",
       "      <td>0.587507</td>\n",
       "      <td>0.674727</td>\n",
       "      <td>0.464309</td>\n",
       "      <td>0.598846</td>\n",
       "      <td>0.703655</td>\n",
       "      <td>0.133156</td>\n",
       "      <td>0.182546</td>\n",
       "      <td>0.249286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.282100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.366822</td>\n",
       "      <td>0.485692</td>\n",
       "      <td>0.634197</td>\n",
       "      <td>0.495270</td>\n",
       "      <td>0.569109</td>\n",
       "      <td>0.670049</td>\n",
       "      <td>0.146736</td>\n",
       "      <td>0.189192</td>\n",
       "      <td>0.248465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.276400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.476951</td>\n",
       "      <td>0.562775</td>\n",
       "      <td>0.668078</td>\n",
       "      <td>0.488504</td>\n",
       "      <td>0.591873</td>\n",
       "      <td>0.686018</td>\n",
       "      <td>0.154061</td>\n",
       "      <td>0.197501</td>\n",
       "      <td>0.263762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.282500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.494864</td>\n",
       "      <td>0.588614</td>\n",
       "      <td>0.688547</td>\n",
       "      <td>0.501981</td>\n",
       "      <td>0.599647</td>\n",
       "      <td>0.689796</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.209727</td>\n",
       "      <td>0.279294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.293500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.498573</td>\n",
       "      <td>0.566231</td>\n",
       "      <td>0.688144</td>\n",
       "      <td>0.473621</td>\n",
       "      <td>0.602044</td>\n",
       "      <td>0.688237</td>\n",
       "      <td>0.136934</td>\n",
       "      <td>0.187963</td>\n",
       "      <td>0.260861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.270300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.487601</td>\n",
       "      <td>0.566208</td>\n",
       "      <td>0.680451</td>\n",
       "      <td>0.398542</td>\n",
       "      <td>0.548506</td>\n",
       "      <td>0.655135</td>\n",
       "      <td>0.144795</td>\n",
       "      <td>0.192799</td>\n",
       "      <td>0.255526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.285300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.497700</td>\n",
       "      <td>0.572378</td>\n",
       "      <td>0.680502</td>\n",
       "      <td>0.498105</td>\n",
       "      <td>0.616330</td>\n",
       "      <td>0.694907</td>\n",
       "      <td>0.134620</td>\n",
       "      <td>0.177230</td>\n",
       "      <td>0.230615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.279500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.595360</td>\n",
       "      <td>0.705885</td>\n",
       "      <td>0.501372</td>\n",
       "      <td>0.619772</td>\n",
       "      <td>0.707486</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.216174</td>\n",
       "      <td>0.291516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.272000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.497382</td>\n",
       "      <td>0.586830</td>\n",
       "      <td>0.710581</td>\n",
       "      <td>0.502320</td>\n",
       "      <td>0.605509</td>\n",
       "      <td>0.696865</td>\n",
       "      <td>0.179950</td>\n",
       "      <td>0.223505</td>\n",
       "      <td>0.295217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.276400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.520710</td>\n",
       "      <td>0.616372</td>\n",
       "      <td>0.713077</td>\n",
       "      <td>0.537803</td>\n",
       "      <td>0.617320</td>\n",
       "      <td>0.700363</td>\n",
       "      <td>0.166689</td>\n",
       "      <td>0.211599</td>\n",
       "      <td>0.274870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.265000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.500912</td>\n",
       "      <td>0.593657</td>\n",
       "      <td>0.690437</td>\n",
       "      <td>0.511853</td>\n",
       "      <td>0.612353</td>\n",
       "      <td>0.690936</td>\n",
       "      <td>0.147003</td>\n",
       "      <td>0.196466</td>\n",
       "      <td>0.260898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.260300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.490811</td>\n",
       "      <td>0.575544</td>\n",
       "      <td>0.701104</td>\n",
       "      <td>0.495282</td>\n",
       "      <td>0.613261</td>\n",
       "      <td>0.714031</td>\n",
       "      <td>0.164995</td>\n",
       "      <td>0.217864</td>\n",
       "      <td>0.273285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.249300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.512358</td>\n",
       "      <td>0.611879</td>\n",
       "      <td>0.720191</td>\n",
       "      <td>0.460944</td>\n",
       "      <td>0.571523</td>\n",
       "      <td>0.705601</td>\n",
       "      <td>0.147816</td>\n",
       "      <td>0.210548</td>\n",
       "      <td>0.284169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.243500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530025</td>\n",
       "      <td>0.617996</td>\n",
       "      <td>0.717204</td>\n",
       "      <td>0.467483</td>\n",
       "      <td>0.583423</td>\n",
       "      <td>0.691093</td>\n",
       "      <td>0.133128</td>\n",
       "      <td>0.176235</td>\n",
       "      <td>0.247631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.263600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.523794</td>\n",
       "      <td>0.611787</td>\n",
       "      <td>0.717640</td>\n",
       "      <td>0.500376</td>\n",
       "      <td>0.610227</td>\n",
       "      <td>0.704271</td>\n",
       "      <td>0.149169</td>\n",
       "      <td>0.205722</td>\n",
       "      <td>0.272376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.243200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.525495</td>\n",
       "      <td>0.622949</td>\n",
       "      <td>0.714737</td>\n",
       "      <td>0.507428</td>\n",
       "      <td>0.607352</td>\n",
       "      <td>0.694958</td>\n",
       "      <td>0.159623</td>\n",
       "      <td>0.204598</td>\n",
       "      <td>0.274610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.242700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.559358</td>\n",
       "      <td>0.632649</td>\n",
       "      <td>0.710635</td>\n",
       "      <td>0.498975</td>\n",
       "      <td>0.613519</td>\n",
       "      <td>0.704348</td>\n",
       "      <td>0.164509</td>\n",
       "      <td>0.221236</td>\n",
       "      <td>0.288651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.243700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.546854</td>\n",
       "      <td>0.616577</td>\n",
       "      <td>0.708659</td>\n",
       "      <td>0.522541</td>\n",
       "      <td>0.615634</td>\n",
       "      <td>0.704156</td>\n",
       "      <td>0.163367</td>\n",
       "      <td>0.199791</td>\n",
       "      <td>0.280140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.232300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.548899</td>\n",
       "      <td>0.647694</td>\n",
       "      <td>0.737706</td>\n",
       "      <td>0.511337</td>\n",
       "      <td>0.614427</td>\n",
       "      <td>0.705993</td>\n",
       "      <td>0.162762</td>\n",
       "      <td>0.224867</td>\n",
       "      <td>0.294541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.224600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.528021</td>\n",
       "      <td>0.625652</td>\n",
       "      <td>0.720281</td>\n",
       "      <td>0.486621</td>\n",
       "      <td>0.599257</td>\n",
       "      <td>0.699612</td>\n",
       "      <td>0.162172</td>\n",
       "      <td>0.222165</td>\n",
       "      <td>0.289188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.241200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.468469</td>\n",
       "      <td>0.580958</td>\n",
       "      <td>0.704137</td>\n",
       "      <td>0.484930</td>\n",
       "      <td>0.619045</td>\n",
       "      <td>0.720442</td>\n",
       "      <td>0.180280</td>\n",
       "      <td>0.233356</td>\n",
       "      <td>0.306990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.234100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.537038</td>\n",
       "      <td>0.620329</td>\n",
       "      <td>0.721151</td>\n",
       "      <td>0.492024</td>\n",
       "      <td>0.605899</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.170048</td>\n",
       "      <td>0.235681</td>\n",
       "      <td>0.311562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.210400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.540302</td>\n",
       "      <td>0.634305</td>\n",
       "      <td>0.721329</td>\n",
       "      <td>0.519587</td>\n",
       "      <td>0.612422</td>\n",
       "      <td>0.718088</td>\n",
       "      <td>0.191442</td>\n",
       "      <td>0.258603</td>\n",
       "      <td>0.331215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.224000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.545863</td>\n",
       "      <td>0.637915</td>\n",
       "      <td>0.727150</td>\n",
       "      <td>0.507287</td>\n",
       "      <td>0.604377</td>\n",
       "      <td>0.696831</td>\n",
       "      <td>0.177801</td>\n",
       "      <td>0.230158</td>\n",
       "      <td>0.300912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.214800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.544373</td>\n",
       "      <td>0.626773</td>\n",
       "      <td>0.728611</td>\n",
       "      <td>0.516694</td>\n",
       "      <td>0.629044</td>\n",
       "      <td>0.726706</td>\n",
       "      <td>0.189831</td>\n",
       "      <td>0.248536</td>\n",
       "      <td>0.317507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.225400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.505082</td>\n",
       "      <td>0.625909</td>\n",
       "      <td>0.719348</td>\n",
       "      <td>0.516861</td>\n",
       "      <td>0.630136</td>\n",
       "      <td>0.735922</td>\n",
       "      <td>0.169140</td>\n",
       "      <td>0.226103</td>\n",
       "      <td>0.297045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.226800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.520874</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.741444</td>\n",
       "      <td>0.481800</td>\n",
       "      <td>0.579341</td>\n",
       "      <td>0.686951</td>\n",
       "      <td>0.162360</td>\n",
       "      <td>0.219895</td>\n",
       "      <td>0.289374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.231800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.539656</td>\n",
       "      <td>0.639873</td>\n",
       "      <td>0.739114</td>\n",
       "      <td>0.480155</td>\n",
       "      <td>0.592314</td>\n",
       "      <td>0.695723</td>\n",
       "      <td>0.159370</td>\n",
       "      <td>0.205123</td>\n",
       "      <td>0.259605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.229400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.532083</td>\n",
       "      <td>0.604346</td>\n",
       "      <td>0.717794</td>\n",
       "      <td>0.532775</td>\n",
       "      <td>0.630693</td>\n",
       "      <td>0.722734</td>\n",
       "      <td>0.178641</td>\n",
       "      <td>0.242001</td>\n",
       "      <td>0.326242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.228600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.538810</td>\n",
       "      <td>0.636611</td>\n",
       "      <td>0.738841</td>\n",
       "      <td>0.508604</td>\n",
       "      <td>0.617462</td>\n",
       "      <td>0.717090</td>\n",
       "      <td>0.152857</td>\n",
       "      <td>0.206582</td>\n",
       "      <td>0.281439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.211500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.445173</td>\n",
       "      <td>0.530736</td>\n",
       "      <td>0.632796</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.621841</td>\n",
       "      <td>0.712180</td>\n",
       "      <td>0.166997</td>\n",
       "      <td>0.231545</td>\n",
       "      <td>0.307485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.190100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.535254</td>\n",
       "      <td>0.638414</td>\n",
       "      <td>0.744115</td>\n",
       "      <td>0.505673</td>\n",
       "      <td>0.618426</td>\n",
       "      <td>0.710254</td>\n",
       "      <td>0.195800</td>\n",
       "      <td>0.265405</td>\n",
       "      <td>0.343477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.196300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.545504</td>\n",
       "      <td>0.628687</td>\n",
       "      <td>0.733928</td>\n",
       "      <td>0.509508</td>\n",
       "      <td>0.618643</td>\n",
       "      <td>0.715345</td>\n",
       "      <td>0.185972</td>\n",
       "      <td>0.250135</td>\n",
       "      <td>0.340883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.181900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.545271</td>\n",
       "      <td>0.641950</td>\n",
       "      <td>0.736507</td>\n",
       "      <td>0.533429</td>\n",
       "      <td>0.618840</td>\n",
       "      <td>0.721267</td>\n",
       "      <td>0.171381</td>\n",
       "      <td>0.230060</td>\n",
       "      <td>0.303920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.199900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.572516</td>\n",
       "      <td>0.653715</td>\n",
       "      <td>0.737692</td>\n",
       "      <td>0.520996</td>\n",
       "      <td>0.616670</td>\n",
       "      <td>0.714440</td>\n",
       "      <td>0.158652</td>\n",
       "      <td>0.220293</td>\n",
       "      <td>0.303063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.579433</td>\n",
       "      <td>0.673503</td>\n",
       "      <td>0.752140</td>\n",
       "      <td>0.528807</td>\n",
       "      <td>0.612604</td>\n",
       "      <td>0.710704</td>\n",
       "      <td>0.191812</td>\n",
       "      <td>0.256399</td>\n",
       "      <td>0.338538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.181900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.499438</td>\n",
       "      <td>0.609074</td>\n",
       "      <td>0.737128</td>\n",
       "      <td>0.513094</td>\n",
       "      <td>0.601714</td>\n",
       "      <td>0.689725</td>\n",
       "      <td>0.187177</td>\n",
       "      <td>0.245888</td>\n",
       "      <td>0.316255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.180900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.550417</td>\n",
       "      <td>0.648763</td>\n",
       "      <td>0.739235</td>\n",
       "      <td>0.506413</td>\n",
       "      <td>0.604270</td>\n",
       "      <td>0.703019</td>\n",
       "      <td>0.188277</td>\n",
       "      <td>0.254069</td>\n",
       "      <td>0.324156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.180300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.531974</td>\n",
       "      <td>0.643178</td>\n",
       "      <td>0.746423</td>\n",
       "      <td>0.486774</td>\n",
       "      <td>0.590854</td>\n",
       "      <td>0.707533</td>\n",
       "      <td>0.187516</td>\n",
       "      <td>0.241134</td>\n",
       "      <td>0.314263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.187100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.560364</td>\n",
       "      <td>0.658300</td>\n",
       "      <td>0.748968</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.631346</td>\n",
       "      <td>0.723332</td>\n",
       "      <td>0.185001</td>\n",
       "      <td>0.233861</td>\n",
       "      <td>0.303555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.188000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.516563</td>\n",
       "      <td>0.631989</td>\n",
       "      <td>0.739079</td>\n",
       "      <td>0.526739</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.737328</td>\n",
       "      <td>0.185124</td>\n",
       "      <td>0.233831</td>\n",
       "      <td>0.314706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.189800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.537961</td>\n",
       "      <td>0.628550</td>\n",
       "      <td>0.734295</td>\n",
       "      <td>0.507736</td>\n",
       "      <td>0.621956</td>\n",
       "      <td>0.717279</td>\n",
       "      <td>0.170784</td>\n",
       "      <td>0.230930</td>\n",
       "      <td>0.298356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>1.176700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.539319</td>\n",
       "      <td>0.648557</td>\n",
       "      <td>0.755603</td>\n",
       "      <td>0.529814</td>\n",
       "      <td>0.642180</td>\n",
       "      <td>0.737916</td>\n",
       "      <td>0.192358</td>\n",
       "      <td>0.250096</td>\n",
       "      <td>0.333850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.179800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.526344</td>\n",
       "      <td>0.605136</td>\n",
       "      <td>0.718292</td>\n",
       "      <td>0.543523</td>\n",
       "      <td>0.642742</td>\n",
       "      <td>0.730393</td>\n",
       "      <td>0.184243</td>\n",
       "      <td>0.229828</td>\n",
       "      <td>0.294147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.182300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.519540</td>\n",
       "      <td>0.610058</td>\n",
       "      <td>0.734325</td>\n",
       "      <td>0.529062</td>\n",
       "      <td>0.635804</td>\n",
       "      <td>0.728597</td>\n",
       "      <td>0.200612</td>\n",
       "      <td>0.262883</td>\n",
       "      <td>0.338666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530950</td>\n",
       "      <td>0.619978</td>\n",
       "      <td>0.719137</td>\n",
       "      <td>0.527033</td>\n",
       "      <td>0.640407</td>\n",
       "      <td>0.734216</td>\n",
       "      <td>0.175237</td>\n",
       "      <td>0.235199</td>\n",
       "      <td>0.306619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>1.187500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.542835</td>\n",
       "      <td>0.648023</td>\n",
       "      <td>0.740507</td>\n",
       "      <td>0.503502</td>\n",
       "      <td>0.617886</td>\n",
       "      <td>0.716876</td>\n",
       "      <td>0.157782</td>\n",
       "      <td>0.210471</td>\n",
       "      <td>0.311726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.168700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.511421</td>\n",
       "      <td>0.620287</td>\n",
       "      <td>0.748617</td>\n",
       "      <td>0.549192</td>\n",
       "      <td>0.641354</td>\n",
       "      <td>0.732116</td>\n",
       "      <td>0.168694</td>\n",
       "      <td>0.218375</td>\n",
       "      <td>0.288475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.182000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.542492</td>\n",
       "      <td>0.646134</td>\n",
       "      <td>0.769706</td>\n",
       "      <td>0.531417</td>\n",
       "      <td>0.630941</td>\n",
       "      <td>0.723768</td>\n",
       "      <td>0.161881</td>\n",
       "      <td>0.214519</td>\n",
       "      <td>0.294117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.183700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.535288</td>\n",
       "      <td>0.643572</td>\n",
       "      <td>0.745848</td>\n",
       "      <td>0.522702</td>\n",
       "      <td>0.635248</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.173835</td>\n",
       "      <td>0.243985</td>\n",
       "      <td>0.321406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>1.176400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.526137</td>\n",
       "      <td>0.624691</td>\n",
       "      <td>0.733230</td>\n",
       "      <td>0.544162</td>\n",
       "      <td>0.640258</td>\n",
       "      <td>0.725823</td>\n",
       "      <td>0.191396</td>\n",
       "      <td>0.258832</td>\n",
       "      <td>0.333350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>1.168200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.559887</td>\n",
       "      <td>0.644120</td>\n",
       "      <td>0.741390</td>\n",
       "      <td>0.518453</td>\n",
       "      <td>0.630196</td>\n",
       "      <td>0.727499</td>\n",
       "      <td>0.173254</td>\n",
       "      <td>0.226882</td>\n",
       "      <td>0.312017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>1.192400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.536289</td>\n",
       "      <td>0.609648</td>\n",
       "      <td>0.719634</td>\n",
       "      <td>0.519675</td>\n",
       "      <td>0.617853</td>\n",
       "      <td>0.717473</td>\n",
       "      <td>0.177029</td>\n",
       "      <td>0.230245</td>\n",
       "      <td>0.307036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1.171600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.540310</td>\n",
       "      <td>0.625318</td>\n",
       "      <td>0.730453</td>\n",
       "      <td>0.558404</td>\n",
       "      <td>0.651851</td>\n",
       "      <td>0.732429</td>\n",
       "      <td>0.197528</td>\n",
       "      <td>0.242513</td>\n",
       "      <td>0.308744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.159400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.541389</td>\n",
       "      <td>0.636093</td>\n",
       "      <td>0.747504</td>\n",
       "      <td>0.547194</td>\n",
       "      <td>0.654486</td>\n",
       "      <td>0.731528</td>\n",
       "      <td>0.170568</td>\n",
       "      <td>0.232292</td>\n",
       "      <td>0.307544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.170100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.556766</td>\n",
       "      <td>0.644519</td>\n",
       "      <td>0.771411</td>\n",
       "      <td>0.537017</td>\n",
       "      <td>0.645328</td>\n",
       "      <td>0.723637</td>\n",
       "      <td>0.158850</td>\n",
       "      <td>0.219109</td>\n",
       "      <td>0.294498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>1.171900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.548537</td>\n",
       "      <td>0.654175</td>\n",
       "      <td>0.764900</td>\n",
       "      <td>0.542892</td>\n",
       "      <td>0.643511</td>\n",
       "      <td>0.725545</td>\n",
       "      <td>0.176887</td>\n",
       "      <td>0.230911</td>\n",
       "      <td>0.304685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1.154300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.547895</td>\n",
       "      <td>0.649583</td>\n",
       "      <td>0.772892</td>\n",
       "      <td>0.520303</td>\n",
       "      <td>0.643337</td>\n",
       "      <td>0.736604</td>\n",
       "      <td>0.195547</td>\n",
       "      <td>0.255581</td>\n",
       "      <td>0.323719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>1.154700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.498336</td>\n",
       "      <td>0.629655</td>\n",
       "      <td>0.733643</td>\n",
       "      <td>0.488331</td>\n",
       "      <td>0.614079</td>\n",
       "      <td>0.720005</td>\n",
       "      <td>0.163936</td>\n",
       "      <td>0.230521</td>\n",
       "      <td>0.317675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.175500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.544484</td>\n",
       "      <td>0.644912</td>\n",
       "      <td>0.743923</td>\n",
       "      <td>0.483127</td>\n",
       "      <td>0.603874</td>\n",
       "      <td>0.708809</td>\n",
       "      <td>0.216115</td>\n",
       "      <td>0.290561</td>\n",
       "      <td>0.362453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>1.159100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.518502</td>\n",
       "      <td>0.635988</td>\n",
       "      <td>0.750172</td>\n",
       "      <td>0.486210</td>\n",
       "      <td>0.603467</td>\n",
       "      <td>0.726425</td>\n",
       "      <td>0.196967</td>\n",
       "      <td>0.261788</td>\n",
       "      <td>0.348401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>1.160200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.557361</td>\n",
       "      <td>0.653112</td>\n",
       "      <td>0.758521</td>\n",
       "      <td>0.533722</td>\n",
       "      <td>0.641208</td>\n",
       "      <td>0.738561</td>\n",
       "      <td>0.208927</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.340803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>1.129500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.560107</td>\n",
       "      <td>0.642730</td>\n",
       "      <td>0.770893</td>\n",
       "      <td>0.534149</td>\n",
       "      <td>0.637103</td>\n",
       "      <td>0.732008</td>\n",
       "      <td>0.182107</td>\n",
       "      <td>0.250776</td>\n",
       "      <td>0.328904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>1.166500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.558581</td>\n",
       "      <td>0.654136</td>\n",
       "      <td>0.768484</td>\n",
       "      <td>0.549441</td>\n",
       "      <td>0.640360</td>\n",
       "      <td>0.727694</td>\n",
       "      <td>0.185323</td>\n",
       "      <td>0.252636</td>\n",
       "      <td>0.335197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.152400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.565848</td>\n",
       "      <td>0.653745</td>\n",
       "      <td>0.755362</td>\n",
       "      <td>0.535258</td>\n",
       "      <td>0.641225</td>\n",
       "      <td>0.742241</td>\n",
       "      <td>0.215377</td>\n",
       "      <td>0.280230</td>\n",
       "      <td>0.362053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>1.127300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.551529</td>\n",
       "      <td>0.639315</td>\n",
       "      <td>0.740066</td>\n",
       "      <td>0.502238</td>\n",
       "      <td>0.626211</td>\n",
       "      <td>0.727164</td>\n",
       "      <td>0.194423</td>\n",
       "      <td>0.251095</td>\n",
       "      <td>0.325993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>1.153200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.546310</td>\n",
       "      <td>0.644833</td>\n",
       "      <td>0.752675</td>\n",
       "      <td>0.473876</td>\n",
       "      <td>0.616619</td>\n",
       "      <td>0.723534</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>0.274031</td>\n",
       "      <td>0.359028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>1.153300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.545959</td>\n",
       "      <td>0.638557</td>\n",
       "      <td>0.752305</td>\n",
       "      <td>0.514790</td>\n",
       "      <td>0.623277</td>\n",
       "      <td>0.734035</td>\n",
       "      <td>0.202192</td>\n",
       "      <td>0.261921</td>\n",
       "      <td>0.333756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>1.162600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.572219</td>\n",
       "      <td>0.657706</td>\n",
       "      <td>0.755613</td>\n",
       "      <td>0.525706</td>\n",
       "      <td>0.624310</td>\n",
       "      <td>0.723288</td>\n",
       "      <td>0.199850</td>\n",
       "      <td>0.264492</td>\n",
       "      <td>0.345701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.158300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.568032</td>\n",
       "      <td>0.659586</td>\n",
       "      <td>0.760848</td>\n",
       "      <td>0.533650</td>\n",
       "      <td>0.640548</td>\n",
       "      <td>0.742330</td>\n",
       "      <td>0.200381</td>\n",
       "      <td>0.260085</td>\n",
       "      <td>0.343591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>1.147400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.537134</td>\n",
       "      <td>0.637156</td>\n",
       "      <td>0.750172</td>\n",
       "      <td>0.516630</td>\n",
       "      <td>0.633199</td>\n",
       "      <td>0.737692</td>\n",
       "      <td>0.222551</td>\n",
       "      <td>0.286367</td>\n",
       "      <td>0.363729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>1.152500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.520055</td>\n",
       "      <td>0.614866</td>\n",
       "      <td>0.745039</td>\n",
       "      <td>0.496392</td>\n",
       "      <td>0.616201</td>\n",
       "      <td>0.727445</td>\n",
       "      <td>0.164572</td>\n",
       "      <td>0.222753</td>\n",
       "      <td>0.298553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>1.143300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.517280</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0.737107</td>\n",
       "      <td>0.494134</td>\n",
       "      <td>0.611687</td>\n",
       "      <td>0.705912</td>\n",
       "      <td>0.195341</td>\n",
       "      <td>0.276037</td>\n",
       "      <td>0.345344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>1.148600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.511160</td>\n",
       "      <td>0.617092</td>\n",
       "      <td>0.739232</td>\n",
       "      <td>0.518733</td>\n",
       "      <td>0.631996</td>\n",
       "      <td>0.735037</td>\n",
       "      <td>0.200473</td>\n",
       "      <td>0.260059</td>\n",
       "      <td>0.352574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.149700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.482501</td>\n",
       "      <td>0.615368</td>\n",
       "      <td>0.747066</td>\n",
       "      <td>0.539246</td>\n",
       "      <td>0.641098</td>\n",
       "      <td>0.731800</td>\n",
       "      <td>0.203751</td>\n",
       "      <td>0.282272</td>\n",
       "      <td>0.372325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>1.142500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.517601</td>\n",
       "      <td>0.621608</td>\n",
       "      <td>0.742130</td>\n",
       "      <td>0.534465</td>\n",
       "      <td>0.630401</td>\n",
       "      <td>0.720619</td>\n",
       "      <td>0.179999</td>\n",
       "      <td>0.241229</td>\n",
       "      <td>0.325416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>1.142200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.505772</td>\n",
       "      <td>0.618372</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.548345</td>\n",
       "      <td>0.645137</td>\n",
       "      <td>0.737225</td>\n",
       "      <td>0.204965</td>\n",
       "      <td>0.277331</td>\n",
       "      <td>0.360074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>1.137900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.517119</td>\n",
       "      <td>0.635516</td>\n",
       "      <td>0.754892</td>\n",
       "      <td>0.513921</td>\n",
       "      <td>0.628689</td>\n",
       "      <td>0.742493</td>\n",
       "      <td>0.169808</td>\n",
       "      <td>0.226469</td>\n",
       "      <td>0.305178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>1.143000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.500133</td>\n",
       "      <td>0.624444</td>\n",
       "      <td>0.752200</td>\n",
       "      <td>0.507564</td>\n",
       "      <td>0.620955</td>\n",
       "      <td>0.724697</td>\n",
       "      <td>0.214646</td>\n",
       "      <td>0.277321</td>\n",
       "      <td>0.358409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.160500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.552400</td>\n",
       "      <td>0.637361</td>\n",
       "      <td>0.735489</td>\n",
       "      <td>0.500718</td>\n",
       "      <td>0.597474</td>\n",
       "      <td>0.708328</td>\n",
       "      <td>0.191931</td>\n",
       "      <td>0.253373</td>\n",
       "      <td>0.327222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>1.147800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.553284</td>\n",
       "      <td>0.669340</td>\n",
       "      <td>0.762826</td>\n",
       "      <td>0.527554</td>\n",
       "      <td>0.629011</td>\n",
       "      <td>0.716231</td>\n",
       "      <td>0.158741</td>\n",
       "      <td>0.226069</td>\n",
       "      <td>0.305014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>1.151200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.563050</td>\n",
       "      <td>0.667695</td>\n",
       "      <td>0.768658</td>\n",
       "      <td>0.507685</td>\n",
       "      <td>0.629253</td>\n",
       "      <td>0.719457</td>\n",
       "      <td>0.226305</td>\n",
       "      <td>0.296486</td>\n",
       "      <td>0.384526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>1.143400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.555823</td>\n",
       "      <td>0.645183</td>\n",
       "      <td>0.748834</td>\n",
       "      <td>0.524999</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.727747</td>\n",
       "      <td>0.191188</td>\n",
       "      <td>0.258998</td>\n",
       "      <td>0.337877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>1.130900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.526998</td>\n",
       "      <td>0.628339</td>\n",
       "      <td>0.753016</td>\n",
       "      <td>0.522483</td>\n",
       "      <td>0.639401</td>\n",
       "      <td>0.731890</td>\n",
       "      <td>0.203617</td>\n",
       "      <td>0.270113</td>\n",
       "      <td>0.356085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.138800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.499260</td>\n",
       "      <td>0.646788</td>\n",
       "      <td>0.770634</td>\n",
       "      <td>0.511495</td>\n",
       "      <td>0.617621</td>\n",
       "      <td>0.719130</td>\n",
       "      <td>0.201806</td>\n",
       "      <td>0.263810</td>\n",
       "      <td>0.337580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>1.127400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.548933</td>\n",
       "      <td>0.644075</td>\n",
       "      <td>0.752273</td>\n",
       "      <td>0.536733</td>\n",
       "      <td>0.628923</td>\n",
       "      <td>0.723386</td>\n",
       "      <td>0.195386</td>\n",
       "      <td>0.251957</td>\n",
       "      <td>0.334652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>1.132300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.555011</td>\n",
       "      <td>0.647135</td>\n",
       "      <td>0.760251</td>\n",
       "      <td>0.518089</td>\n",
       "      <td>0.622623</td>\n",
       "      <td>0.706484</td>\n",
       "      <td>0.191847</td>\n",
       "      <td>0.256506</td>\n",
       "      <td>0.328832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>1.142800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.535028</td>\n",
       "      <td>0.646951</td>\n",
       "      <td>0.742289</td>\n",
       "      <td>0.538380</td>\n",
       "      <td>0.637364</td>\n",
       "      <td>0.727198</td>\n",
       "      <td>0.209464</td>\n",
       "      <td>0.271674</td>\n",
       "      <td>0.347054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>1.123100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530274</td>\n",
       "      <td>0.645898</td>\n",
       "      <td>0.775381</td>\n",
       "      <td>0.531135</td>\n",
       "      <td>0.638923</td>\n",
       "      <td>0.724758</td>\n",
       "      <td>0.233070</td>\n",
       "      <td>0.307121</td>\n",
       "      <td>0.368457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.134900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.539730</td>\n",
       "      <td>0.634844</td>\n",
       "      <td>0.752293</td>\n",
       "      <td>0.525592</td>\n",
       "      <td>0.628787</td>\n",
       "      <td>0.723594</td>\n",
       "      <td>0.191575</td>\n",
       "      <td>0.260839</td>\n",
       "      <td>0.339442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>1.132300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.540166</td>\n",
       "      <td>0.644914</td>\n",
       "      <td>0.769313</td>\n",
       "      <td>0.533644</td>\n",
       "      <td>0.638755</td>\n",
       "      <td>0.728076</td>\n",
       "      <td>0.226222</td>\n",
       "      <td>0.281743</td>\n",
       "      <td>0.371741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>1.139300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.519177</td>\n",
       "      <td>0.623345</td>\n",
       "      <td>0.737177</td>\n",
       "      <td>0.524472</td>\n",
       "      <td>0.622035</td>\n",
       "      <td>0.729055</td>\n",
       "      <td>0.203780</td>\n",
       "      <td>0.287516</td>\n",
       "      <td>0.373396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>1.158200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.540012</td>\n",
       "      <td>0.663291</td>\n",
       "      <td>0.774028</td>\n",
       "      <td>0.536474</td>\n",
       "      <td>0.644158</td>\n",
       "      <td>0.727396</td>\n",
       "      <td>0.223044</td>\n",
       "      <td>0.293573</td>\n",
       "      <td>0.376935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>1.135200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.529859</td>\n",
       "      <td>0.628999</td>\n",
       "      <td>0.745549</td>\n",
       "      <td>0.511025</td>\n",
       "      <td>0.631556</td>\n",
       "      <td>0.722080</td>\n",
       "      <td>0.193774</td>\n",
       "      <td>0.261117</td>\n",
       "      <td>0.337209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>1.140500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.515104</td>\n",
       "      <td>0.632844</td>\n",
       "      <td>0.747849</td>\n",
       "      <td>0.512850</td>\n",
       "      <td>0.636488</td>\n",
       "      <td>0.720801</td>\n",
       "      <td>0.191260</td>\n",
       "      <td>0.239366</td>\n",
       "      <td>0.310786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>1.154200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.633798</td>\n",
       "      <td>0.757033</td>\n",
       "      <td>0.518562</td>\n",
       "      <td>0.636183</td>\n",
       "      <td>0.730865</td>\n",
       "      <td>0.196624</td>\n",
       "      <td>0.261690</td>\n",
       "      <td>0.346282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>1.158400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.531515</td>\n",
       "      <td>0.632508</td>\n",
       "      <td>0.756779</td>\n",
       "      <td>0.529417</td>\n",
       "      <td>0.627840</td>\n",
       "      <td>0.724134</td>\n",
       "      <td>0.221224</td>\n",
       "      <td>0.276593</td>\n",
       "      <td>0.353206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>1.126600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.536005</td>\n",
       "      <td>0.631633</td>\n",
       "      <td>0.742452</td>\n",
       "      <td>0.506659</td>\n",
       "      <td>0.620807</td>\n",
       "      <td>0.719824</td>\n",
       "      <td>0.174601</td>\n",
       "      <td>0.236092</td>\n",
       "      <td>0.323056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>1.146300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.495942</td>\n",
       "      <td>0.625464</td>\n",
       "      <td>0.753878</td>\n",
       "      <td>0.540493</td>\n",
       "      <td>0.645597</td>\n",
       "      <td>0.737240</td>\n",
       "      <td>0.219214</td>\n",
       "      <td>0.291208</td>\n",
       "      <td>0.372448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.139900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.536126</td>\n",
       "      <td>0.642692</td>\n",
       "      <td>0.757534</td>\n",
       "      <td>0.514744</td>\n",
       "      <td>0.629220</td>\n",
       "      <td>0.730394</td>\n",
       "      <td>0.183268</td>\n",
       "      <td>0.247220</td>\n",
       "      <td>0.334891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>1.134500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.526174</td>\n",
       "      <td>0.619255</td>\n",
       "      <td>0.722030</td>\n",
       "      <td>0.523013</td>\n",
       "      <td>0.634082</td>\n",
       "      <td>0.726333</td>\n",
       "      <td>0.157140</td>\n",
       "      <td>0.218973</td>\n",
       "      <td>0.312318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>1.140800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.553422</td>\n",
       "      <td>0.638885</td>\n",
       "      <td>0.744224</td>\n",
       "      <td>0.489169</td>\n",
       "      <td>0.631186</td>\n",
       "      <td>0.729438</td>\n",
       "      <td>0.183246</td>\n",
       "      <td>0.245431</td>\n",
       "      <td>0.330459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>1.139000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.524049</td>\n",
       "      <td>0.628539</td>\n",
       "      <td>0.750802</td>\n",
       "      <td>0.484693</td>\n",
       "      <td>0.607333</td>\n",
       "      <td>0.730432</td>\n",
       "      <td>0.195290</td>\n",
       "      <td>0.275775</td>\n",
       "      <td>0.368806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>1.125300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.546317</td>\n",
       "      <td>0.667041</td>\n",
       "      <td>0.767920</td>\n",
       "      <td>0.525740</td>\n",
       "      <td>0.628110</td>\n",
       "      <td>0.711044</td>\n",
       "      <td>0.180758</td>\n",
       "      <td>0.225830</td>\n",
       "      <td>0.292844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>1.140100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.497269</td>\n",
       "      <td>0.603110</td>\n",
       "      <td>0.715742</td>\n",
       "      <td>0.526884</td>\n",
       "      <td>0.640124</td>\n",
       "      <td>0.730162</td>\n",
       "      <td>0.192618</td>\n",
       "      <td>0.259756</td>\n",
       "      <td>0.332668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>1.135000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.491082</td>\n",
       "      <td>0.624583</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.496665</td>\n",
       "      <td>0.635573</td>\n",
       "      <td>0.725219</td>\n",
       "      <td>0.188955</td>\n",
       "      <td>0.260701</td>\n",
       "      <td>0.341707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>1.143800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530037</td>\n",
       "      <td>0.605544</td>\n",
       "      <td>0.728873</td>\n",
       "      <td>0.548370</td>\n",
       "      <td>0.634953</td>\n",
       "      <td>0.724592</td>\n",
       "      <td>0.152775</td>\n",
       "      <td>0.218641</td>\n",
       "      <td>0.303116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>1.131000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.494238</td>\n",
       "      <td>0.619582</td>\n",
       "      <td>0.750528</td>\n",
       "      <td>0.540254</td>\n",
       "      <td>0.641663</td>\n",
       "      <td>0.734887</td>\n",
       "      <td>0.194246</td>\n",
       "      <td>0.246685</td>\n",
       "      <td>0.329453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>1.160100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.507820</td>\n",
       "      <td>0.610228</td>\n",
       "      <td>0.725441</td>\n",
       "      <td>0.501397</td>\n",
       "      <td>0.610854</td>\n",
       "      <td>0.720843</td>\n",
       "      <td>0.193621</td>\n",
       "      <td>0.246659</td>\n",
       "      <td>0.317554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.142900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.540841</td>\n",
       "      <td>0.658368</td>\n",
       "      <td>0.742347</td>\n",
       "      <td>0.503477</td>\n",
       "      <td>0.623141</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>0.198878</td>\n",
       "      <td>0.261758</td>\n",
       "      <td>0.343157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>1.131700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.498797</td>\n",
       "      <td>0.609120</td>\n",
       "      <td>0.709001</td>\n",
       "      <td>0.468538</td>\n",
       "      <td>0.597618</td>\n",
       "      <td>0.724443</td>\n",
       "      <td>0.206952</td>\n",
       "      <td>0.257108</td>\n",
       "      <td>0.337000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>1.144200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.453621</td>\n",
       "      <td>0.607065</td>\n",
       "      <td>0.728313</td>\n",
       "      <td>0.508944</td>\n",
       "      <td>0.622000</td>\n",
       "      <td>0.718520</td>\n",
       "      <td>0.179122</td>\n",
       "      <td>0.244131</td>\n",
       "      <td>0.326945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>1.160400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.508014</td>\n",
       "      <td>0.572159</td>\n",
       "      <td>0.658758</td>\n",
       "      <td>0.507167</td>\n",
       "      <td>0.627946</td>\n",
       "      <td>0.717712</td>\n",
       "      <td>0.164795</td>\n",
       "      <td>0.214999</td>\n",
       "      <td>0.284833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>1.174500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.516051</td>\n",
       "      <td>0.603430</td>\n",
       "      <td>0.713205</td>\n",
       "      <td>0.494839</td>\n",
       "      <td>0.594723</td>\n",
       "      <td>0.697606</td>\n",
       "      <td>0.136683</td>\n",
       "      <td>0.177456</td>\n",
       "      <td>0.245364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>1.170700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.484835</td>\n",
       "      <td>0.561036</td>\n",
       "      <td>0.669671</td>\n",
       "      <td>0.532445</td>\n",
       "      <td>0.617049</td>\n",
       "      <td>0.704733</td>\n",
       "      <td>0.123021</td>\n",
       "      <td>0.177438</td>\n",
       "      <td>0.252554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>1.166300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.490195</td>\n",
       "      <td>0.579514</td>\n",
       "      <td>0.671756</td>\n",
       "      <td>0.518964</td>\n",
       "      <td>0.615357</td>\n",
       "      <td>0.705610</td>\n",
       "      <td>0.146894</td>\n",
       "      <td>0.220366</td>\n",
       "      <td>0.299989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>1.181000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.483838</td>\n",
       "      <td>0.563937</td>\n",
       "      <td>0.663261</td>\n",
       "      <td>0.504330</td>\n",
       "      <td>0.593896</td>\n",
       "      <td>0.697193</td>\n",
       "      <td>0.133662</td>\n",
       "      <td>0.175860</td>\n",
       "      <td>0.241778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>1.175400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.494759</td>\n",
       "      <td>0.573546</td>\n",
       "      <td>0.678166</td>\n",
       "      <td>0.447338</td>\n",
       "      <td>0.596575</td>\n",
       "      <td>0.708688</td>\n",
       "      <td>0.128945</td>\n",
       "      <td>0.187265</td>\n",
       "      <td>0.259254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>1.210800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.483213</td>\n",
       "      <td>0.558723</td>\n",
       "      <td>0.661380</td>\n",
       "      <td>0.482832</td>\n",
       "      <td>0.598123</td>\n",
       "      <td>0.685944</td>\n",
       "      <td>0.125282</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.254133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.212200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.487907</td>\n",
       "      <td>0.525109</td>\n",
       "      <td>0.616370</td>\n",
       "      <td>0.407974</td>\n",
       "      <td>0.575482</td>\n",
       "      <td>0.668990</td>\n",
       "      <td>0.077452</td>\n",
       "      <td>0.117550</td>\n",
       "      <td>0.172726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>1.202200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.478131</td>\n",
       "      <td>0.549589</td>\n",
       "      <td>0.639236</td>\n",
       "      <td>0.384251</td>\n",
       "      <td>0.580168</td>\n",
       "      <td>0.677241</td>\n",
       "      <td>0.058756</td>\n",
       "      <td>0.104169</td>\n",
       "      <td>0.169881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>1.248300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.461839</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.566719</td>\n",
       "      <td>0.450476</td>\n",
       "      <td>0.578364</td>\n",
       "      <td>0.673427</td>\n",
       "      <td>0.086140</td>\n",
       "      <td>0.126468</td>\n",
       "      <td>0.182004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>1.255000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.450191</td>\n",
       "      <td>0.533902</td>\n",
       "      <td>0.637192</td>\n",
       "      <td>0.430903</td>\n",
       "      <td>0.574310</td>\n",
       "      <td>0.674020</td>\n",
       "      <td>0.083519</td>\n",
       "      <td>0.108431</td>\n",
       "      <td>0.166941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>1.241900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.455217</td>\n",
       "      <td>0.536893</td>\n",
       "      <td>0.632438</td>\n",
       "      <td>0.475023</td>\n",
       "      <td>0.589701</td>\n",
       "      <td>0.684501</td>\n",
       "      <td>0.091594</td>\n",
       "      <td>0.118557</td>\n",
       "      <td>0.170943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>1.222000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.490647</td>\n",
       "      <td>0.562976</td>\n",
       "      <td>0.623100</td>\n",
       "      <td>0.442090</td>\n",
       "      <td>0.607482</td>\n",
       "      <td>0.696340</td>\n",
       "      <td>0.090682</td>\n",
       "      <td>0.139892</td>\n",
       "      <td>0.181095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>1.215900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.493019</td>\n",
       "      <td>0.553893</td>\n",
       "      <td>0.656248</td>\n",
       "      <td>0.478320</td>\n",
       "      <td>0.575498</td>\n",
       "      <td>0.693271</td>\n",
       "      <td>0.065592</td>\n",
       "      <td>0.096184</td>\n",
       "      <td>0.179679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>1.203800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.474979</td>\n",
       "      <td>0.556595</td>\n",
       "      <td>0.607401</td>\n",
       "      <td>0.469649</td>\n",
       "      <td>0.581425</td>\n",
       "      <td>0.692664</td>\n",
       "      <td>0.088661</td>\n",
       "      <td>0.113200</td>\n",
       "      <td>0.151657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>1.241100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.465135</td>\n",
       "      <td>0.506723</td>\n",
       "      <td>0.627545</td>\n",
       "      <td>0.435886</td>\n",
       "      <td>0.537294</td>\n",
       "      <td>0.675457</td>\n",
       "      <td>0.111036</td>\n",
       "      <td>0.147467</td>\n",
       "      <td>0.176402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>1.234100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.462138</td>\n",
       "      <td>0.524644</td>\n",
       "      <td>0.608183</td>\n",
       "      <td>0.474077</td>\n",
       "      <td>0.564096</td>\n",
       "      <td>0.677229</td>\n",
       "      <td>0.100092</td>\n",
       "      <td>0.140109</td>\n",
       "      <td>0.198115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.247100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.455308</td>\n",
       "      <td>0.560594</td>\n",
       "      <td>0.637751</td>\n",
       "      <td>0.406327</td>\n",
       "      <td>0.541738</td>\n",
       "      <td>0.631797</td>\n",
       "      <td>0.106135</td>\n",
       "      <td>0.146045</td>\n",
       "      <td>0.216032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>1.292900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.471361</td>\n",
       "      <td>0.533506</td>\n",
       "      <td>0.626338</td>\n",
       "      <td>0.284461</td>\n",
       "      <td>0.431167</td>\n",
       "      <td>0.628853</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>0.068532</td>\n",
       "      <td>0.116073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>1.330900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.441006</td>\n",
       "      <td>0.550010</td>\n",
       "      <td>0.612073</td>\n",
       "      <td>0.357222</td>\n",
       "      <td>0.569362</td>\n",
       "      <td>0.658165</td>\n",
       "      <td>0.023795</td>\n",
       "      <td>0.052277</td>\n",
       "      <td>0.124599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 70.47it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 66.82it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.55it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.22it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 65.89it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:10<00:00, 84.51it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 75.83it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.90it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:16<00:00, 53.99it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 82.87it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 65.26it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 62.93it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 69.75it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:10<00:00, 84.43it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.28it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 72.84it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.73it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 74.04it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 70.82it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 75.18it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 64.69it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 76.86it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 66.92it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:10<00:00, 84.00it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 77.61it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.32it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 66.05it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 81.60it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 72.15it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.73it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 65.17it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 75.19it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.73it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 63.31it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.83it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 79.81it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 65.55it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 65.13it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.82it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 63.93it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 71.25it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 76.67it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 62.43it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 63.43it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 72.35it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 76.04it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 74.08it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 79.51it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.21it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:15<00:00, 60.91it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 62.66it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 70.62it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 70.11it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:16<00:00, 54.44it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 71.34it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 79.79it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 74.07it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.51it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 65.86it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 76.32it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 73.31it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.19it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 65.32it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 72.74it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 65.42it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 75.34it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.34it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 65.05it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.44it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 77.33it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 70.89it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.01it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 69.82it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 69.33it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.18it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 83.26it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 69.19it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 77.24it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 63.91it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 73.20it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:10<00:00, 86.56it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:15<00:00, 58.75it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:09<00:00, 100.08it/s]\n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 69.78it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 76.21it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 76.33it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.87it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 66.06it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 70.02it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 78.23it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 66.12it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 76.26it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:09<00:00, 97.69it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 70.57it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 81.51it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 71.78it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 66.94it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 66.97it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 82.61it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 75.33it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 64.41it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 66.49it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 69.73it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 77.19it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 76.59it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 71.47it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 66.49it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 64.32it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:15<00:00, 59.91it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.20it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 64.41it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.80it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 81.38it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 71.72it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 70.11it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 63.91it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 75.95it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 72.50it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 64.96it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 63.95it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.12it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 63.76it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 81.06it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 71.14it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 70.24it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 64.71it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 76.30it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 74.29it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 65.99it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 71.52it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 77.50it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 70.61it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 79.74it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 66.24it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 70.57it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 66.00it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 80.44it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 74.88it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 65.48it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:15<00:00, 57.53it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 75.67it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.96it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.03it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 72.74it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 76.42it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 75.10it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 82.29it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 74.06it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 65.84it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 64.84it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 78.09it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.66it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.15it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.98it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 80.42it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 74.89it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 65.84it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 66.14it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 72.92it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 67.10it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 79.97it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 75.55it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 63.88it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 77.47it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 79.45it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 72.37it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 64.99it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.66it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:10<00:00, 87.79it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:16<00:00, 54.75it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:16<00:00, 56.98it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 65.50it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.37it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 76.01it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:12<00:00, 72.13it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 64.05it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 77.11it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:11<00:00, 77.14it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 63.71it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 70.15it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:14<00:00, 63.91it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction: 100%|██████████| 916/916 [00:13<00:00, 68.05it/s] \n",
      "INFO:biobridge.trainer:***** Running Node Encoding for Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 2677\n",
      "INFO:biobridge.trainer:***** Running Evaluation *****\n",
      "INFO:biobridge.trainer:  Num examples = 1832\n",
      "INFO:biobridge.trainer:  Batch size = 2\n",
      "Prediction:   5%|▌         | 48/916 [00:01<00:25, 34.58it/s]\n",
      "Exception in thread Thread-11 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 53, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 30, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 495, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^Exception in thread ^Thread-377 (_pin_memory_loop)^:\n",
      "^^Traceback (most recent call last):\n",
      "^\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    self.run()    \n",
      "with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "      _threading_Thread_run(self) \n",
      "    File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/threading.py\", line 1012, in run\n",
      "       self._target(*self._args, **self._kwargs) \n",
      "^^  File \"/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 53, in _pin_memory_loop\n",
      "^^    ^do_one_step()^\n",
      "^^  File \"/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 30, in do_one_step\n",
      "^^    ^r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)^\n",
      "^^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "^^    ^c = Client(address, authkey=process.current_process().authkey)^\n",
      "^^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "^^    ^return _ForkingPickler.loads(res)^\n",
      "^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^  File \"/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 495, in rebuild_storage_fd\n",
      "\n",
      "      File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/connection.py\", line 519, in Client\n",
      "fd = df.detach()\n",
      "    c = SocketClient(address) \n",
      "               ^ ^^^^^^^^^^^^^^^^^^^^\n",
      "^^  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "^^    ^with _resource_sharer.get_connection(self._id) as conn:^\n",
      "^^ ^ ^ ^ \n",
      "    File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/connection.py\", line 647, in SocketClient\n",
      "       s.connect(address)^\n",
      "^^FileNotFoundError^: ^[Errno 2] No such file or directory^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/connection.py\", line 525, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/connection.py\", line 962, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/home/linuxbrew/.linuxbrew/opt/python@3.12/lib/python3.12/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/transformers/trainer.py:2598\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2596\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2598\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\n\u001b[1;32m   2600\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2602\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/transformers/trainer.py:3071\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3069\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3070\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 3071\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3072\u001b[0m     is_new_best_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_best_metric(metrics\u001b[38;5;241m=\u001b[39mmetrics, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   3074\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST:\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/transformers/trainer.py:3025\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 3025\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   3028\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/docs/notebooks/talk2knowledgegraphs/biobridge/trainer.py:120\u001b[0m, in \u001b[0;36mBindingTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m    118\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    119\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m--> 120\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/docs/notebooks/talk2knowledgegraphs/biobridge/trainer.py:286\u001b[0m, in \u001b[0;36mBindingTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m    283\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# if predictions's keys are not in preds_host, add padding index to avoid error in nested_concat\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m tail_node_types:\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/docs/notebooks/talk2knowledgegraphs/biobridge/trainer.py:394\u001b[0m, in \u001b[0;36mBindingTrainer.prediction_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m    391\u001b[0m tail_type_ids \u001b[38;5;241m=\u001b[39m single_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtail_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    392\u001b[0m head_type_ids \u001b[38;5;241m=\u001b[39m single_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    393\u001b[0m outputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor([head_node_index]), \n\u001b[0;32m--> 394\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[43mhead_type_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]),\n\u001b[1;32m    395\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    396\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    397\u001b[0m            }\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tail_type_id \u001b[38;5;129;01min\u001b[39;00m tail_type_ids\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;66;03m# get the query node embedding\u001b[39;00m\n\u001b[1;32m    400\u001b[0m     tail_type_id \u001b[38;5;241m=\u001b[39m tail_type_id\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7827c81ae600>> (for post_run_cell), with arguments args (<ExecutionResult object at 7827a8d12750, execution_count=33 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 7827a8d12ed0, raw_cell=\"# train the model\n",
      "trainer.train()\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/home/awmulyadi/Repositories/temp/office2/AIAgents4Pharma/docs/notebooks/talk2knowledgegraphs/tutorial_biobridge_primekg_training.ipynb#X43sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:565\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/wandb/sdk/interface/interface.py:769\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py:289\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:174\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    172\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    173\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/temp/office2/AIAgents4Pharma/venv/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model    \n",
    "trainer.save_model(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
